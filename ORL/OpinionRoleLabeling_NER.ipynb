{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc5008da",
   "metadata": {},
   "source": [
    "## Opinion Role Labeling\n",
    "\n",
    "### Using the NER approach\n",
    "-------\n",
    "\n",
    "**Requirements**\n",
    "```\n",
    "!pip install transformers datasets evaluate seqeval\n",
    "```\n",
    "\n",
    "alternatively use the following command (on *anaconda*):\n",
    "```\n",
    "!conda install -y -c conda-forge transformers datasets evaluate seqeval\n",
    "```\n",
    "\n",
    "**Load a dataset in the following format**\n",
    "```\n",
    "[CLS] Das immer wieder mit dem Separatismus liebäugelnde französischsprachige Quebec wollte sich mit dem Verfassungskompromiss , TARGET die neun vorwiegend englischsprachigen HOLDER schliesslich zugestimmt hatten , nicht abfinden . [SEP] \n",
    "[CLS] Das immer wieder mit dem Separatismus liebäugelnde französischsprachige Quebec wollte sich mit dem Verfassungskompromiss , dem die neun vorwiegend englischsprachigen Provinzen schliesslich zugestimmt hatten , nicht abfinden . [SEP] \n",
    "[CLS] Von den beiden grossen Gewerkschaften hatte die HOLDER ( Unión General del Trabajo ) dieses TARGET unterstützt , während die Comisiones Obreras ( CCOO ) es im Vorfeld abgelehnt hatten , sich jetzt aber mit dem Resultat abfinden . [SEP] \n",
    "[CLS] Von den beiden grossen Gewerkschaften hatte die UGT ( Unión General del Trabajo ) dieses Vorhaben unterstützt , während die Comisiones Obreras ( CCOO ) es im Vorfeld abgelehnt hatten , sich jetzt aber mit dem Resultat abfinden . [SEP] \n",
    "[CLS] Der HOLDER hat keine TARGET verletzt . » Petkovic lehnt laut italienischen Medien auch ein Angebot ab , mit 30 Prozent der Summe abgefunden zu werden . [SEP] \n",
    "[CLS] Der Trainer hat keine Regeln verletzt . » Petkovic lehnt laut italienischen Medien auch ein Angebot ab , mit 30 Prozent der Summe abgefunden zu werden . [SEP] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4848b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG VARIABLES\n",
    "\n",
    "# DATASET_PATH=\"../../etl/data/raw/03_holder_target.txt\"\n",
    "\n",
    "TRAIN_DATASET_PATH=\"../../etl/data/processed/ORLConverter/01_train_orl.txt\"\n",
    "VAL_DATASET_PATH=\"../../etl/data/processed/ORLConverter/01_val_orl.txt\"\n",
    "TEST_DATASET_PATH=\"../../etl/data/processed/ORLConverter/01_test_orl.txt\"\n",
    "\n",
    "GENERATE_DATASET=True\n",
    "\n",
    "BASE_MODEL_NAME=\"distilbert-base-german-cased\"\n",
    "\n",
    "TRAINED_MODEL_NAME=\"./data/trained_model_german_bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "726ead96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the data: 8382\n",
      "Total rows in the data: 2406\n",
      "Total rows in the data: 2390\n"
     ]
    }
   ],
   "source": [
    "def read_sents(dataset_path):\n",
    "    sents = []\n",
    "\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for c, l in enumerate(f.readlines()):\n",
    "            if c < 100:\n",
    "                pass\n",
    "            sents.append(l.strip())\n",
    "\n",
    "    # Der Minister findet die Debatte langweilig.\n",
    "    real_sents = sents[1::2]\n",
    "\n",
    "    # Der HOLDER findet die TARGET langweilig.\n",
    "    masked_sents = sents[0::2]\n",
    "\n",
    "    assert len(real_sents) == len(masked_sents), \"Nr of masked and real sentences are not equal!\"\n",
    "\n",
    "    print(f\"Total rows in the data: {len(real_sents) + len(masked_sents)}\")\n",
    "    \n",
    "    return real_sents, masked_sents\n",
    "\n",
    "train_sents_real, train_sents_masked = read_sents(TRAIN_DATASET_PATH)\n",
    "val_sents_real, val_sents_masked = read_sents(VAL_DATASET_PATH)\n",
    "test_sents_real, test_sents_masked = read_sents(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b032c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max holders:  1 Max targets:  1 Max polar expressions:  1\n",
      "Max holders:  1 Max targets:  1 Max polar expressions:  1\n",
      "Max holders:  1 Max targets:  1 Max polar expressions:  1\n",
      "[{'id': 0, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0], 'tokens': ['Die', 'Beförderung', 'Lichtensteins', 'ist', 'auch', 'insofern', 'leicht', 'nachvollziehbar', ',', 'als', 'der', 'ehemalige', 'Investmentbanker', 'das', 'Vertrauen', 'der', 'Vertreter', 'von', 'Chem', 'China', 'nicht', 'erst', 'als', 'Chef', 'von', 'Adama', 'erworben', 'hat', '.']}, {'id': 1, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['In', '«', 'Tiere', 'der', 'Grossstadt', '»', 'tragen', 'surreale', 'Ansichten', 'und', 'Bilderrätsel', 'die', 'Handlung', ',', 'was', 'Zeit', 'lässt', 'für', 'den', 'Blick', 'hinter', 'die', 'Fassaden', ':', 'Eine', 'wunderbar', 'entrückte', 'Valery', 'Tscheplanowa', 'brilliert', 'hier', 'in', 'der', 'Rolle', 'der', 'Witwe', ',', 'die', 'der', 'Verlust', 'einer', 'Katze', 'mehr', 'zu', 'quälen', 'scheint', 'als', 'der', 'Tod', 'ihres', 'Ehemannes', '.']}, {'id': 2, 'ner_tags': [0, 1, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Meine', 'Passion', 'gilt', 'vollumfänglich', 'meinem', 'Unternehmen', ',', 'in', 'dem', 'ja', 'auch', 'der', 'Mensch', 'im', 'Mittelpunkt', 'steht', '.']}, {'id': 3, 'ner_tags': [1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], 'tokens': ['Vladica', 'Dicic', ',', 'die', 'serbisch-orthodoxe', 'Christin', ',', 'bedankt', 'sich', 'mit', 'Tränen', 'in', 'den', 'Augen', 'für', 'die', 'Hilfe', 'und', 'macht', 'das', 'Kreuzzeichen', '.']}, {'id': 4, 'ner_tags': [0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Nicht', 'nur', 'ihre', 'Kolleginnen', 'sorgen', 'sich', 'seitdem', 'um', 'die', 'chinesische', 'Tennisspielerin', ',', 'sogar', 'die', 'EU', 'schaltete', 'sich', 'vor', 'wenigen', 'Tagen', 'ein', 'und', 'forderte', 'von', 'China', '«', 'nachprüfbare', 'Beweise', '»', ',', 'dass', 'es', 'ihr', 'gut', 'gehe', '.']}, {'id': 5, 'ner_tags': [0, 0, 1, 3, 0, 0, 0, 2, 0], 'tokens': ['Doch', 'seine', 'Begeisterung', 'galt', 'nicht', 'nur', 'den', 'Helikoptern', '.']}, {'id': 6, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Alles', 'saust', 'gleich', 'an', 'die', 'Telephone', '.', '»', 'In', 'ganz', 'Deutschland', 'schwärmten', 'die', 'SA-Schergen', 'aus', ',', 'verwüsteten', 'und', 'plünderten', 'Tausende', 'von', 'jüdischen', 'Geschäften', 'und', 'Wohnungen', ',', 'fackelten', 'Hunderte', 'von', 'Bethäusern', 'und', 'Synagogen', 'ab', ',', 'verprügelten', 'und', 'verhafteten', 'jüdische', '\\xad', 'Mitbürger', '.']}, {'id': 7, 'ner_tags': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0], 'tokens': ['Der', 'Täter', ',', 'ein', '30-jähriger', 'Iraker', ',', 'hatte', 'mit', 'seinem', 'Auto', 'am', 'Dienstagabend', 'mehrfach', 'Fahrzeuge', 'gerammt', 'und', 'sechs', 'Menschen', 'verletzt', ',', 'drei', 'davon', 'schwer', '.']}, {'id': 8, 'ner_tags': [0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0], 'tokens': ['Ihre', 'Kandidatin', 'Regula', 'Rytz', 'hat', 'nicht', 'einmal', 'das', 'Potenzial', 'des', 'rot-grünen', 'Lagers', 'ausgeschöpft', '.']}, {'id': 9, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0], 'tokens': ['Roman', 'Müller', 'Prima', ',', 'dass', 'sich', 'jetzt', 'auch', 'der', 'Medienfuchs', 'Roger', 'Schawinski', 'für', 'ein', 'Nein', 'zu', 'No', 'Billag', 'einsetzt', '.']}]\n"
     ]
    }
   ],
   "source": [
    "NER_labels = [\"O\", \"HOLDER\", \"TARGET\", \"PEXP\"]\n",
    "\n",
    "test_sent = [\"Peter sowie Lucy mag Katzen sowie auch Hunde .\"]\n",
    "test_sent_masked = [\"HOLDER sowie HOLDER mag TARGET sowie auch TARGET .\"]\n",
    "\n",
    "def align_sentences(real_sentences, masked_sentences, NER_labels):\n",
    "    \"\"\"Given two sentences that have their word-level tokens delimited by a white-space, \n",
    "    create NER-tags for each sentence token.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    max_multiple_holders = 0\n",
    "    max_multiple_targets = 0\n",
    "    max_multiple_pexps = 0\n",
    "\n",
    "    for i, real_sentence, masked_sentence in zip(range(0,len(real_sentences)), real_sentences, masked_sentences):\n",
    "        ner_tags = []\n",
    "        real_sentence_split = real_sentence.split(\" \")\n",
    "        masked_sentence_split = masked_sentence.split(\" \")\n",
    "        \n",
    "        # target / holder counting\n",
    "        target_cnt = 0\n",
    "        holder_cnt = 0\n",
    "        pexp_cnt = 0\n",
    "\n",
    "        assert len(real_sentence_split) == len(masked_sentence_split), \"Misalignment of length of tokens in sentence.\" \\\n",
    "        + str(real_sentence_split) + str(masked_sentence_split) + str(i)\n",
    "\n",
    "        for real_token, masked_token in zip(real_sentence_split, masked_sentence_split):\n",
    "            if real_token == masked_token:\n",
    "                ner_tags.append(0)\n",
    "            elif masked_token == \"HOLDER\":\n",
    "                holder_cnt += 1\n",
    "                tag_index = NER_labels.index(masked_token)\n",
    "                ner_tags.append(tag_index)\n",
    "            elif masked_token == \"TARGET\":\n",
    "                target_cnt += 1\n",
    "                tag_index = NER_labels.index(masked_token)\n",
    "                ner_tags.append(tag_index)\n",
    "            elif masked_token == \"PEXP\":\n",
    "                pexp_cnt += 1\n",
    "                tag_index = NER_labels.index(masked_token)\n",
    "                ner_tags.append(tag_index)\n",
    "\n",
    "        dataset.append({\n",
    "            \"id\": i,\n",
    "            # remove the magic tokens from the sentences, \n",
    "            # since we will pass the sentences through the tokenizer again.\n",
    "            \"ner_tags\": ner_tags[1:-1],\n",
    "            \"tokens\": real_sentence_split[1:-1],\n",
    "        })\n",
    "    max_multiple_holders = max(max_multiple_holders, holder_cnt)\n",
    "    max_multiple_targets = max(max_multiple_targets, target_cnt)\n",
    "    max_multiple_pexps = max(max_multiple_pexps, pexp_cnt)\n",
    "\n",
    "    return dataset, max_multiple_holders, max_multiple_targets, max_multiple_pexps\n",
    "\n",
    "# align for training\n",
    "train_aligned_sents, mmh, mmt, mmp = align_sentences(train_sents_real, train_sents_masked, NER_labels)\n",
    "print(\"Max holders: \", mmh, \"Max targets: \", mmt, \"Max polar expressions: \", mmp)\n",
    "val_aligned_sents, mmh, mmt, mmp = align_sentences(val_sents_real, val_sents_masked, NER_labels)\n",
    "print(\"Max holders: \", mmh, \"Max targets: \", mmt, \"Max polar expressions: \", mmp)\n",
    "test_aligned_sents, mmh, mmt, mmp = align_sentences(test_sents_real, test_sents_masked, NER_labels)\n",
    "print(\"Max holders: \", mmh, \"Max targets: \", mmt, \"Max polar expressions: \", mmp)\n",
    "\n",
    "# UNCOMMENT FOR TEST\n",
    "# aligned_sents, mmh, mmt = align_sentences(test_sent, test_sent_masked, NER_labels)\n",
    "\n",
    "print(train_aligned_sents[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "023c5448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995243f136bc4e74b447f7a326e43f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f7a4054bdd4ad49e1854dfb689e2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346fc565a0dc4f3181c12958625d572c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'ner_tags', 'tokens'],\n",
      "        num_rows: 4191\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['id', 'ner_tags', 'tokens'],\n",
      "        num_rows: 1203\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'ner_tags', 'tokens'],\n",
      "        num_rows: 1195\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Make a huggingface dataset out of the record-based dataset\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "if GENERATE_DATASET:\n",
    "    train_dataset = Dataset.from_list(train_aligned_sents)\n",
    "    val_dataset = Dataset.from_list(val_aligned_sents)\n",
    "    test_dataset = Dataset.from_list(test_aligned_sents)\n",
    "\n",
    "    # randomly shuffle\n",
    "    train_dataset = train_dataset.shuffle(seed=42)\n",
    "    val_dataset = val_dataset.shuffle(seed=42)\n",
    "    test_dataset = test_dataset.shuffle(seed=42)\n",
    "\n",
    "    # dataset = dataset.train_test_split(test_size=0.2, shuffle=False)\n",
    "    # train_test_dataset = dataset.train_test_split(test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Split the 10% test + valid in half test, half valid\n",
    "    # test_valid = train_test_dataset['test'].train_test_split(test_size=0.4, shuffle=False)\n",
    "\n",
    "    # gather everyone if you want to have a single DatasetDict\n",
    "    dataset = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'valid': val_dataset,\n",
    "        'test': test_dataset})\n",
    "\n",
    "    dataset.save_to_disk(\"./data/split_dataset.hf\")\n",
    "else:\n",
    "    dataset = load_from_disk(\"./data/split_dataset.hf\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d954b73a",
   "metadata": {},
   "source": [
    "**Use DistilBERT tokenizer and embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8e9d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "890c8fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [102, 446, 746, 8565, 20614, 125, 4161, 2448, 1021, 386, 842, 1943, 566, 103], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'Auf', 'seiner', 'Flucht', 'verletzte', 'der', 'Deutsche', 'mehrere', 'Menschen', 'zum', 'Teil', 'schwer', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# tokenize input\n",
    "tokenized_input = tokenizer(dataset[\"train\"][0][\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "print(tokenized_input)\n",
    "\n",
    "# output subwords\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4df703bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "722fa1a3a7b5413a8336fc298b1067d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a216933772fe41c0b25d46dcb492a2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3903f9d989924a96a302ef4049497343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4191\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1195\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        \n",
    "        try:\n",
    "            for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                    label_ids.append(label[word_idx])\n",
    "                else:\n",
    "                    label_ids.append(-100)\n",
    "                previous_word_idx = word_idx\n",
    "            labels.append(label_ids)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping example due to the following: { str(e) }\")\n",
    "            print(\" \".join(examples[f\"tokens\"][i]))\n",
    "            print(label)\n",
    "            continue\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62e7a52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, 0, 0, 3, 0, 1, 0, 2, 0, 0, 0, 0, -100]\n",
      "['[CLS]', 'Auf', 'seiner', 'Flucht', 'verletzte', 'der', 'Deutsche', 'mehrere', 'Menschen', 'zum', 'Teil', 'schwer', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# check that the conversion worked.\n",
    "print(tokenized_dataset[\"train\"][0][\"labels\"])\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_dataset[\"train\"][0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e4c09",
   "metadata": {},
   "source": [
    "**Define a DataCollator (for efficient padding of the tokens)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e4221f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d270a0",
   "metadata": {},
   "source": [
    "**Download the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5b4930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-german-cased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "# num labels is 4 bcz of the -100 label\n",
    "model = AutoModelForTokenClassification.from_pretrained(BASE_MODEL_NAME, num_labels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9aabd",
   "metadata": {},
   "source": [
    "***Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53268329",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, ner_tags. If tokens, id, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 4191\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='786' max='786' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [786/786 28:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.216775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.230800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, ner_tags. If tokens, id, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1203\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./data/results/checkpoint-500\n",
      "Configuration saved in ./data/results/checkpoint-500/config.json\n",
      "Model weights saved in ./data/results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./data/results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./data/results/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, ner_tags. If tokens, id, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1203\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, id, ner_tags. If tokens, id, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1203\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./data/trained_model_german_bert\n",
      "Configuration saved in ./data/trained_model_german_bert/config.json\n",
      "Model weights saved in ./data/trained_model_german_bert/pytorch_model.bin\n",
      "tokenizer config file saved in ./data/trained_model_german_bert/tokenizer_config.json\n",
      "Special tokens file saved in ./data/trained_model_german_bert/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b235a88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file ./data/trained_model_german_bert/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./data/trained_model_german_bert\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file ./data/trained_model_german_bert/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
      "\n",
      "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at ./data/trained_model_german_bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# In case no model was loaded up until now.\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_path = TRAINED_MODEL_NAME\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2788c264",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_0',\n",
       "  'score': 0.99969065,\n",
       "  'index': 1,\n",
       "  'word': 'Er',\n",
       "  'start': 0,\n",
       "  'end': 2},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99962413,\n",
       "  'index': 2,\n",
       "  'word': 'sagt',\n",
       "  'start': 3,\n",
       "  'end': 7},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99936646,\n",
       "  'index': 3,\n",
       "  'word': ',',\n",
       "  'start': 7,\n",
       "  'end': 8},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9995933,\n",
       "  'index': 4,\n",
       "  'word': 'dass',\n",
       "  'start': 9,\n",
       "  'end': 13},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99962044,\n",
       "  'index': 5,\n",
       "  'word': 'der',\n",
       "  'start': 14,\n",
       "  'end': 17},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.99183625,\n",
       "  'index': 6,\n",
       "  'word': 'Präsident',\n",
       "  'start': 18,\n",
       "  'end': 27},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9996166,\n",
       "  'index': 7,\n",
       "  'word': 'dem',\n",
       "  'start': 28,\n",
       "  'end': 31},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.9307748,\n",
       "  'index': 8,\n",
       "  'word': 'Volk',\n",
       "  'start': 32,\n",
       "  'end': 36},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9917257,\n",
       "  'index': 9,\n",
       "  'word': 'etwas',\n",
       "  'start': 37,\n",
       "  'end': 42},\n",
       " {'entity': 'LABEL_3',\n",
       "  'score': 0.9075023,\n",
       "  'index': 10,\n",
       "  'word': 'vorge',\n",
       "  'start': 43,\n",
       "  'end': 48},\n",
       " {'entity': 'LABEL_3',\n",
       "  'score': 0.8573485,\n",
       "  'index': 11,\n",
       "  'word': '##macht',\n",
       "  'start': 48,\n",
       "  'end': 53},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9991491,\n",
       "  'index': 12,\n",
       "  'word': 'hat',\n",
       "  'start': 54,\n",
       "  'end': 57},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9995658,\n",
       "  'index': 13,\n",
       "  'word': '.',\n",
       "  'start': 57,\n",
       "  'end': 58}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"token-classification\",\n",
    "                # model=trainer.model, -- in case freshly trained\n",
    "                model=model,\n",
    "                tokenizer=tokenizer)\n",
    "\n",
    "pipe(\"Er sagt, dass der Präsident dem Volk etwas vorgemacht hat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0376f07d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_1',\n",
       "  'score': 0.94375,\n",
       "  'index': 1,\n",
       "  'word': 'Peter',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.967745,\n",
       "  'index': 2,\n",
       "  'word': 'hat',\n",
       "  'start': 6,\n",
       "  'end': 9},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.91697866,\n",
       "  'index': 3,\n",
       "  'word': 'etwas',\n",
       "  'start': 10,\n",
       "  'end': 15},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.85223156,\n",
       "  'index': 4,\n",
       "  'word': 'gegen',\n",
       "  'start': 16,\n",
       "  'end': 21},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.50546294,\n",
       "  'index': 5,\n",
       "  'word': 'Fritz',\n",
       "  'start': 22,\n",
       "  'end': 27},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.92054045,\n",
       "  'index': 6,\n",
       "  'word': '!',\n",
       "  'start': 27,\n",
       "  'end': 28}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Peter hat etwas gegen Fritz!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546aae9a",
   "metadata": {},
   "source": [
    "**Evaluation on the test / val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c3012d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c89f627f2141e7ba309a85771842fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1195 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269750b2de654244b5783281c7ce1765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1195 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenized dataset, convert numerical labels to labels ready for evaluation.\n",
    "\n",
    "def labelize(example):\n",
    "    labels1 = []\n",
    "    for label in example[\"labels\"]:\n",
    "        if label in [0, -100]:\n",
    "            labels1.append(\"LABEL_0\")\n",
    "        if label in [1]:\n",
    "            labels1.append(\"LABEL_1\")\n",
    "        if label in [2]:\n",
    "            labels1.append(\"LABEL_2\")\n",
    "        if label in [3]:\n",
    "            labels1.append(\"LABEL_3\")\n",
    "    example[\"labels\"] = labels1\n",
    "    return example\n",
    "\n",
    "def subword_ids_to_strings(example):\n",
    "    example[\"subword_tokens\"] = tokenizer.convert_ids_to_tokens(example[\"input_ids\"])\n",
    "    return example\n",
    "\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(labelize)\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(subword_ids_to_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05ad4612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aber es kam anders : Die beiden Frauen und die beiden Männer haben sich nicht nur freundschaftlich , sondern neugierig aufeinander eingelassen , ohne es an Niveau fehlen zu lassen .'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# verify\n",
    "tokenizer.decode(tokenized_dataset[\"test\"][0][\"input_ids\"])\n",
    "len(tokenized_dataset[\"test\"])\n",
    "\n",
    "small_ds = tokenized_dataset[\"test\"].select(range(8))\n",
    "\n",
    "len(small_ds)\n",
    "\n",
    "\" \".join(small_ds[0][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "704af230",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1195/1195 [00:38<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ABEL_0       0.53      0.44      0.48      4250\n",
      "      ABEL_1       0.74      0.75      0.75      1195\n",
      "      ABEL_2       0.61      0.35      0.45      1195\n",
      "      ABEL_3       0.83      0.56      0.67      1195\n",
      "\n",
      "   micro avg       0.62      0.49      0.55      7835\n",
      "   macro avg       0.68      0.53      0.59      7835\n",
      "weighted avg       0.62      0.49      0.55      7835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_total_pred = []\n",
    "y_total_true = []\n",
    "\n",
    "for e in tqdm(tokenized_dataset[\"test\"]):\n",
    "    pred = [x[\"entity\"] for x in pipe(\" \".join(e[\"tokens\"]))]\n",
    "    # print(\"Prediction length:\", len(pred))\n",
    "    # print(\"Subword length:\", len(e[\"subword_tokens\"][1:-1]))\n",
    "    # print(\"Labels length:\", len(e[\"labels\"][1:-1]))\n",
    "    # print(\"----\")\n",
    "    y_total_pred.append(pred)\n",
    "    true = e[\"labels\"]\n",
    "    y_total_true.append(true[1:-1])\n",
    "\n",
    "print(classification_report(y_total_true, y_total_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3095af48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_1',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_2',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_2',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_3',\n",
       " 'LABEL_0']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524161e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
