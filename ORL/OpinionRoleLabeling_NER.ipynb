{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b49046",
   "metadata": {},
   "source": [
    "## Opinion Role Labeling\n",
    "\n",
    "### Using the NER approach\n",
    "-------\n",
    "\n",
    "**Requirements**\n",
    "```\n",
    "pip install transformers datasets evaluate seqeval\n",
    "```\n",
    "\n",
    "**Load a dataset in the following format**\n",
    "```\n",
    "[CLS] Das immer wieder mit dem Separatismus liebäugelnde französischsprachige Quebec wollte sich mit dem Verfassungskompromiss , TARGET die neun vorwiegend englischsprachigen HOLDER schliesslich zugestimmt hatten , nicht abfinden . [SEP] \n",
    "[CLS] Das immer wieder mit dem Separatismus liebäugelnde französischsprachige Quebec wollte sich mit dem Verfassungskompromiss , dem die neun vorwiegend englischsprachigen Provinzen schliesslich zugestimmt hatten , nicht abfinden . [SEP] \n",
    "[CLS] Von den beiden grossen Gewerkschaften hatte die HOLDER ( Unión General del Trabajo ) dieses TARGET unterstützt , während die Comisiones Obreras ( CCOO ) es im Vorfeld abgelehnt hatten , sich jetzt aber mit dem Resultat abfinden . [SEP] \n",
    "[CLS] Von den beiden grossen Gewerkschaften hatte die UGT ( Unión General del Trabajo ) dieses Vorhaben unterstützt , während die Comisiones Obreras ( CCOO ) es im Vorfeld abgelehnt hatten , sich jetzt aber mit dem Resultat abfinden . [SEP] \n",
    "[CLS] Der HOLDER hat keine TARGET verletzt . » Petkovic lehnt laut italienischen Medien auch ein Angebot ab , mit 30 Prozent der Summe abgefunden zu werden . [SEP] \n",
    "[CLS] Der Trainer hat keine Regeln verletzt . » Petkovic lehnt laut italienischen Medien auch ein Angebot ab , mit 30 Prozent der Summe abgefunden zu werden . [SEP] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8ac9c23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the data: 130844\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH=\"data/silver_standard/holder_target.txt\"\n",
    "\n",
    "sents = []\n",
    "\n",
    "with open(DATASET_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for c, l in enumerate(f.readlines()):\n",
    "        if c < 100:\n",
    "            pass\n",
    "        sents.append(l.strip())\n",
    "\n",
    "# Der Minister findet die Debatte langweilig.\n",
    "real_sents = sents[1::2]\n",
    "\n",
    "# Der HOLDER findet die TARGET langweilig.\n",
    "masked_sents = sents[0::2]\n",
    "\n",
    "assert len(real_sents) == len(masked_sents), \"Nr of masked and real sentences are not equal!\"\n",
    "\n",
    "print(f\"Total rows in the data: {len(real_sents) + len(masked_sents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "427e3651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Das', 'immer', 'wieder', 'mit', 'dem', 'Separatismus', 'liebäugelnde', 'französischsprachige', 'Quebec', 'wollte', 'sich', 'mit', 'dem', 'Verfassungskompromiss', ',', 'dem', 'die', 'neun', 'vorwiegend', 'englischsprachigen', 'Provinzen', 'schliesslich', 'zugestimmt', 'hatten', ',', 'nicht', 'abfinden', '.']}, {'id': 1, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Von', 'den', 'beiden', 'grossen', 'Gewerkschaften', 'hatte', 'die', 'UGT', '(', 'Unión', 'General', 'del', 'Trabajo', ')', 'dieses', 'Vorhaben', 'unterstützt', ',', 'während', 'die', 'Comisiones', 'Obreras', '(', 'CCOO', ')', 'es', 'im', 'Vorfeld', 'abgelehnt', 'hatten', ',', 'sich', 'jetzt', 'aber', 'mit', 'dem', 'Resultat', 'abfinden', '.']}, {'id': 2, 'ner_tags': [0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Der', 'Trainer', 'hat', 'keine', 'Regeln', 'verletzt', '.', '»', 'Petkovic', 'lehnt', 'laut', 'italienischen', 'Medien', 'auch', 'ein', 'Angebot', 'ab', ',', 'mit', '30', 'Prozent', 'der', 'Summe', 'abgefunden', 'zu', 'werden', '.']}, {'id': 3, 'ner_tags': [0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Manche', 'Grüne', 'verdächtigen', 'die', 'Genossen', 'ihrerseits', ',', 'sich', 'insgeheim', 'schon', 'mit', 'einer', 'grossen', 'Koalition', 'abgefunden', 'zu', 'haben', '.']}, {'id': 4, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0], 'tokens': ['Auf', 'dem', 'Höhepunkt', 'dieser', 'Auseinandersetzung', 'hörte', 'es', 'sich', 'so', 'an', ',', 'als', 'würde', 'das', 'Kanzleramt', 'ungezogene', 'Schulbuben', 'abkanzeln', '.']}, {'id': 5, 'ner_tags': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], 'tokens': ['Ironischerweise', 'wurde', 'der', 'Heimatschützer', 'Fazio', 'letztlich', 'von', 'den', 'Mailänder', 'Staatsanwälten', 'gestürzt', ',', 'die', 'Berlusconi', 'gerne', 'als', 'verkappte', 'Kommunisten', 'abkanzelt', '.']}, {'id': 6, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Es', 'scheint', 'eher', ',', 'als', 'habe', 'ein', 'arroganter', 'Angehöriger', 'der', 'oberen', 'Klasse', 'einen', 'Polizisten', 'abkanzeln', 'wollen', 'und', 'dabei', 'alle', 'Register', 'gezogen', '.']}, {'id': 7, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Christoph', 'Blocher', 'ärgerte', 'sich', 'damals', 'dermassen', 'über', 'seinen', 'parteiinternen', 'Widersacher', ',', 'dass', 'er', 'ihn', 'öffentlich', 'als', '«', 'halben', 'SVP-Bundesrat', '»', 'abkanzelte', '.']}, {'id': 8, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Dabei', 'handelt', 'es', 'sich', 'um', 'Fakten', ',', 'die', 'die', 'SVP', 'nicht', 'wegdiskutieren', 'kann', '-', 'sosehr', 'sie', 'die', 'GPK', 'auch', 'als', 'Gremium', 'politisch', 'voreingenommener', 'Dilettanten', 'abkanzelt', ',', 'ihre', '«', 'Geheimplan', '»', '-These', 'verbreitet', 'und', 'auf', 'die', 'Unterstützung', 'der', '«', 'Weltwoche', '»', 'zählen', 'kann', '.']}, {'id': 9, 'ner_tags': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Es', 'kam', 'vor', ',', 'dass', 'ein', 'Lehman-Manager', 'einen', 'Raum', 'betrat', 'und', 'die', 'Anwesenden', 'erst', 'einmal', 'wie', 'dumme', 'Schulbuben', 'abkanzelte', '.']}]\n"
     ]
    }
   ],
   "source": [
    "NER_labels = [\"O\", \"HOLDER\", \"TARGET\"]\n",
    "\n",
    "def align_sentences(real_sentences, masked_sentences, NER_labels):\n",
    "    \"\"\"Given two sentences that have their word-level tokens delimited by a white-space, \n",
    "    create NER-tags for each sentence token.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    for i, real_sentence, masked_sentence in zip(range(0,len(real_sentences)), real_sentences, masked_sentences):\n",
    "        ner_tags = []\n",
    "        real_sentence_split = real_sentence.split(\" \")\n",
    "        masked_sentence_split = masked_sentence.split(\" \")\n",
    "        assert len(real_sentence_split) == len(masked_sentence_split), \"Misalignment of length of tokens in sentence.\"\n",
    "        for real_token, masked_token in zip(real_sentence_split, masked_sentence_split):\n",
    "            if real_token == masked_token:\n",
    "                ner_tags.append(0)\n",
    "            elif masked_token == \"HOLDER\":\n",
    "                tag_index = NER_labels.index(masked_token)\n",
    "                ner_tags.append(tag_index)\n",
    "            elif masked_token == \"TARGET\":\n",
    "                tag_index = NER_labels.index(masked_token)\n",
    "                ner_tags.append(tag_index)\n",
    "        dataset.append({\n",
    "            \"id\": i,\n",
    "            # remove the magic tokens from the sentences, \n",
    "            # since we will pass the sentences through the tokenizer again.\n",
    "            \"ner_tags\": ner_tags[1:-1],\n",
    "            \"tokens\": real_sentence_split[1:-1],\n",
    "        })\n",
    "    return dataset\n",
    "         \n",
    "    \n",
    "dataset = align_sentences(real_sents, masked_sents, NER_labels)\n",
    "\n",
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "67b54c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'ner_tags', 'tokens'],\n",
      "        num_rows: 52337\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'ner_tags', 'tokens'],\n",
      "        num_rows: 13085\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Make a huggingface dataset out of the record-based dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_list(dataset)\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.2, shuffle=False)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47449a2a",
   "metadata": {},
   "source": [
    "**Use DistilBERT tokenizer and embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "180de9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "04d78d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 9033, 2063, 4895, 7747, 8525, 5753, 2618, 16950, 16846, 2480, 27412, 1047, 29443, 11837, 24759, 20501, 2063, 6519, 2358, 18727, 13719, 17076, 4355, 5349, 2618, 6151, 2162, 6519, 3280, 21200, 14758, 5575, 4315, 8040, 21886, 6499, 12871, 8017, 19205, 2102, 1010, 3393, 7295, 2618, 7632, 15465, 6914, 27665, 2078, 1047, 5596, 4183, 6519, 2270, 10523, 6151, 13970, 7096, 3126, 22894, 7389, 2094, 4315, 9944, 5511, 11113, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'si', '##e', 'un', '##ters', '##tu', '##tz', '##te', 'zu', '##sat', '##z', '##liche', 'k', '##rip', '##pen', '##pl', '##atz', '##e', 'fur', 'st', '##adt', '##ische', 'ang', '##est', '##ell', '##te', 'und', 'war', 'fur', 'die', 'auf', '##stock', '##ung', 'der', 'sc', '##hul', '##so', '##zia', '##lar', '##bei', '##t', ',', 'le', '##hn', '##te', 'hi', '##nge', '##gen', 'eine', '##n', 'k', '##red', '##it', 'fur', 'public', 'viewing', 'und', 'ku', '##lt', '##ur', 'wah', '##ren', '##d', 'der', 'euro', '08', 'ab', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# tokenize input\n",
    "tokenized_input = tokenizer(dataset[\"train\"][0][\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "print(tokenized_input)\n",
    "\n",
    "# output subwords\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "66778d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c8a0af383f41d1be71fa166b734c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d78b405cab4e228b850a9e6f5f0f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 52337\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 13085\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e940e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 1, 0, -100, -100, 0, -100, 0, -100, -100, -100, -100, 0, 0, -100, 2, -100, 0, 0, -100, -100, 0, 0, 0, -100, 0, 0, 0, 0, -100, -100, -100, -100, 0, -100, 0, 0, 0, 0, -100, -100, 0, -100, -100, 0, -100, 0, -100, -100, 0, -100, -100, -100, 0, -100]\n",
      "['[CLS]', 'man', 'sol', '##lt', '##e', 'si', '##e', 'un', '##ters', '##tu', '##tze', '##n', ',', 'stat', '##t', 'si', '##e', 'zu', 'best', '##raf', '##en', '»', ',', 'sa', '##gt', 'martin', ',', 'dem', 'na', '##ch', '##ges', '##ag', '##t', 'wi', '##rd', ',', 'auf', 'die', 'hi', '##es', '##ige', 'reg', '##ier', '##ung', 'gross', '##en', 'ein', '##fl', '##uss', 'aus', '##zu', '##ub', '##en', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# check that the conversion worked.\n",
    "print(tokenized_dataset[\"train\"][0][\"labels\"])\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_dataset[\"train\"][0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef41b3",
   "metadata": {},
   "source": [
    "**Define a DataCollator (for efficient padding of the tokens)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28af22f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c09c73",
   "metadata": {},
   "source": [
    "**Download the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc38bd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 268M/268M [00:04<00:00, 61.9MB/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "# num labels is 4 bcz of the -100 label\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a282a",
   "metadata": {},
   "source": [
    "***Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0521ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/parallels/nbdev/lib64/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 52337\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9816\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9816' max='9816' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9816/9816 5:59:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.065323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.052069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-2000\n",
      "Configuration saved in ./results/checkpoint-2000/config.json\n",
      "Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-2500\n",
      "Configuration saved in ./results/checkpoint-2500/config.json\n",
      "Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-3000\n",
      "Configuration saved in ./results/checkpoint-3000/config.json\n",
      "Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13085\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./results/checkpoint-3500\n",
      "Configuration saved in ./results/checkpoint-3500/config.json\n",
      "Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-3500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-4000\n",
      "Configuration saved in ./results/checkpoint-4000/config.json\n",
      "Model weights saved in ./results/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-4500\n",
      "Configuration saved in ./results/checkpoint-4500/config.json\n",
      "Model weights saved in ./results/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-4500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-5000\n",
      "Configuration saved in ./results/checkpoint-5000/config.json\n",
      "Model weights saved in ./results/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-5500\n",
      "Configuration saved in ./results/checkpoint-5500/config.json\n",
      "Model weights saved in ./results/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-5500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-6000\n",
      "Configuration saved in ./results/checkpoint-6000/config.json\n",
      "Model weights saved in ./results/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-6500\n",
      "Configuration saved in ./results/checkpoint-6500/config.json\n",
      "Model weights saved in ./results/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-6500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13085\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to ./results/checkpoint-7000\n",
      "Configuration saved in ./results/checkpoint-7000/config.json\n",
      "Model weights saved in ./results/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-7500\n",
      "Configuration saved in ./results/checkpoint-7500/config.json\n",
      "Model weights saved in ./results/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-7500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-8000\n",
      "Configuration saved in ./results/checkpoint-8000/config.json\n",
      "Model weights saved in ./results/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-8500\n",
      "Configuration saved in ./results/checkpoint-8500/config.json\n",
      "Model weights saved in ./results/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-8500/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-9000\n",
      "Configuration saved in ./results/checkpoint-9000/config.json\n",
      "Model weights saved in ./results/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9000/special_tokens_map.json\n",
      "Saving model checkpoint to ./results/checkpoint-9500\n",
      "Configuration saved in ./results/checkpoint-9500/config.json\n",
      "Model weights saved in ./results/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-9500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13085\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, ner_tags, tokens. If id, ner_tags, tokens are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9816, training_loss=0.07171938918719178, metrics={'train_runtime': 21575.4297, 'train_samples_per_second': 7.277, 'train_steps_per_second': 0.455, 'total_flos': 4189931551985328.0, 'train_loss': 0.07171938918719178, 'epoch': 3.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"./models/ORL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "709f93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case no model was loaded up until now.\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_path = \"./trained_model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "186503f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_0',\n",
       "  'score': 0.9949757,\n",
       "  'index': 1,\n",
       "  'word': 'er',\n",
       "  'start': 0,\n",
       "  'end': 2},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99967515,\n",
       "  'index': 2,\n",
       "  'word': 'sa',\n",
       "  'start': 3,\n",
       "  'end': 5},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9995388,\n",
       "  'index': 3,\n",
       "  'word': '##gt',\n",
       "  'start': 5,\n",
       "  'end': 7},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9998976,\n",
       "  'index': 4,\n",
       "  'word': ',',\n",
       "  'start': 7,\n",
       "  'end': 8},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9997031,\n",
       "  'index': 5,\n",
       "  'word': 'das',\n",
       "  'start': 9,\n",
       "  'end': 12},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99986494,\n",
       "  'index': 6,\n",
       "  'word': '##s',\n",
       "  'start': 12,\n",
       "  'end': 13},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9998369,\n",
       "  'index': 7,\n",
       "  'word': 'der',\n",
       "  'start': 14,\n",
       "  'end': 17},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.9823893,\n",
       "  'index': 8,\n",
       "  'word': 'pr',\n",
       "  'start': 18,\n",
       "  'end': 20},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9886596,\n",
       "  'index': 9,\n",
       "  'word': '##asi',\n",
       "  'start': 20,\n",
       "  'end': 23},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9971238,\n",
       "  'index': 10,\n",
       "  'word': '##dent',\n",
       "  'start': 23,\n",
       "  'end': 27},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9999032,\n",
       "  'index': 11,\n",
       "  'word': 'dem',\n",
       "  'start': 28,\n",
       "  'end': 31},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.91569746,\n",
       "  'index': 12,\n",
       "  'word': 'vol',\n",
       "  'start': 32,\n",
       "  'end': 35},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9966948,\n",
       "  'index': 13,\n",
       "  'word': '##k',\n",
       "  'start': 35,\n",
       "  'end': 36},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9847339,\n",
       "  'index': 14,\n",
       "  'word': 'et',\n",
       "  'start': 37,\n",
       "  'end': 39},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99972147,\n",
       "  'index': 15,\n",
       "  'word': '##was',\n",
       "  'start': 39,\n",
       "  'end': 42},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9998586,\n",
       "  'index': 16,\n",
       "  'word': 'vo',\n",
       "  'start': 43,\n",
       "  'end': 45},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9998703,\n",
       "  'index': 17,\n",
       "  'word': '##rge',\n",
       "  'start': 45,\n",
       "  'end': 48},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9967866,\n",
       "  'index': 18,\n",
       "  'word': '##mac',\n",
       "  'start': 48,\n",
       "  'end': 51},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9998173,\n",
       "  'index': 19,\n",
       "  'word': '##ht',\n",
       "  'start': 51,\n",
       "  'end': 53},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.999925,\n",
       "  'index': 20,\n",
       "  'word': 'hat',\n",
       "  'start': 54,\n",
       "  'end': 57},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.999923,\n",
       "  'index': 21,\n",
       "  'word': '.',\n",
       "  'start': 57,\n",
       "  'end': 58}]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"token-classification\",\n",
    "                # model=trainer.model, -- in case freshly trained\n",
    "                model=model,\n",
    "                tokenizer=tokenizer)\n",
    "\n",
    "pipe(\"Er sagt, dass der Präsident dem Volk etwas vorgemacht hat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5c4ca7d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_1',\n",
       "  'score': 0.9838028,\n",
       "  'index': 1,\n",
       "  'word': 'peter',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9998976,\n",
       "  'index': 2,\n",
       "  'word': 'hat',\n",
       "  'start': 6,\n",
       "  'end': 9},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.66772044,\n",
       "  'index': 3,\n",
       "  'word': 'et',\n",
       "  'start': 10,\n",
       "  'end': 12},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9953389,\n",
       "  'index': 4,\n",
       "  'word': '##was',\n",
       "  'start': 12,\n",
       "  'end': 15},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9999118,\n",
       "  'index': 5,\n",
       "  'word': 'ge',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9997837,\n",
       "  'index': 6,\n",
       "  'word': '##gen',\n",
       "  'start': 18,\n",
       "  'end': 21},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.6101386,\n",
       "  'index': 7,\n",
       "  'word': 'fritz',\n",
       "  'start': 22,\n",
       "  'end': 27},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9999211,\n",
       "  'index': 8,\n",
       "  'word': '!',\n",
       "  'start': 27,\n",
       "  'end': 28}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Peter hat etwas gegen Fritz!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7acbeea",
   "metadata": {},
   "source": [
    "**Evaluation on the test / val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fd9b11cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c3385b123f460fb403c6729c9f5bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13085 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd1c219c37f46cfa2c648feb10dc0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13085 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenized dataset, convert numerical labels to labels ready for evaluation.\n",
    "\n",
    "def labelize(example):\n",
    "    labels1 = []\n",
    "    for label in example[\"labels\"]:\n",
    "        if label in [0, -100]:\n",
    "            labels1.append(\"LABEL_0\")\n",
    "        if label in [1]:\n",
    "            labels1.append(\"LABEL_1\")\n",
    "        if label in [2]:\n",
    "            labels1.append(\"LABEL_2\")\n",
    "    example[\"labels\"] = labels1\n",
    "    return example\n",
    "\n",
    "def subword_ids_to_strings(example):\n",
    "    example[\"subword_tokens\"] = tokenizer.convert_ids_to_tokens(example[\"input_ids\"])\n",
    "    return example\n",
    "\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(labelize)\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(subword_ids_to_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "bb65cff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "') , der 2001 schon im Kantonsrat sass und gegen Flughafen-Erweiterungen kämpfte , sagt : « Nach dem Grounding fühlten wir uns bestätigt , weil wir gegen die Mega-Hub-Phantasien gekämpft hatten .'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# verify\n",
    "tokenizer.decode(tokenized_dataset[\"test\"][0][\"input_ids\"])\n",
    "len(tokenized_dataset[\"test\"])\n",
    "\n",
    "small_ds = tokenized_dataset[\"test\"].select(range(8))\n",
    "\n",
    "len(small_ds)\n",
    "\n",
    "\" \".join(small_ds[0][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d26710",
   "metadata": {},
   "outputs": [],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6f558b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13085/13085 [12:03<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ABEL_0       0.89      0.90      0.90     36771\n",
      "      ABEL_1       0.90      0.94      0.92     13056\n",
      "      ABEL_2       0.90      0.91      0.91     12941\n",
      "\n",
      "   micro avg       0.90      0.91      0.90     62768\n",
      "   macro avg       0.90      0.92      0.91     62768\n",
      "weighted avg       0.90      0.91      0.90     62768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_total_pred = []\n",
    "y_total_true = []\n",
    "\n",
    "for e in tqdm(tokenized_dataset[\"test\"]):\n",
    "    pred = [x[\"entity\"] for x in pipe(\" \".join(e[\"tokens\"]))]\n",
    "    # print(\"Prediction length:\", len(pred))\n",
    "    # print(\"Subword length:\", len(e[\"subword_tokens\"][1:-1]))\n",
    "    # print(\"Labels length:\", len(e[\"labels\"][1:-1]))\n",
    "    # print(\"----\")\n",
    "    y_total_pred.append(pred)\n",
    "    true = e[\"labels\"]\n",
    "    y_total_true.append(true[1:-1])\n",
    "\n",
    "print(classification_report(y_total_true, y_total_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "feb9f6ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LABEL_0',\n",
       " 'LABEL_1',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_1',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_2',\n",
       " 'LABEL_0']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588aca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
