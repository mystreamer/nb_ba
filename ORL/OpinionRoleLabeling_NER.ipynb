{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ecbf02",
   "metadata": {},
   "source": [
    "## Opinion Role Labeling\n",
    "\n",
    "### Using the NER approach\n",
    "-------\n",
    "\n",
    "**Requirements**\n",
    "```\n",
    "!pip install transformers datasets evaluate seqeval\n",
    "```\n",
    "\n",
    "alternatively use the following command (on *anaconda*):\n",
    "```\n",
    "!conda install -y -c conda-forge transformers datasets evaluate seqeval\n",
    "```\n",
    "\n",
    "**Load a dataset in the following format**\n",
    "```\n",
    "[CLS] Das immer wieder mit dem Separatismus liebäugelnde französischsprachige Quebec wollte sich mit dem Verfassungskompromiss , TARGET die neun vorwiegend englischsprachigen HOLDER schliesslich zugestimmt hatten , nicht abfinden . [SEP] \n",
    "[CLS] Das immer wieder mit dem Separatismus liebäugelnde französischsprachige Quebec wollte sich mit dem Verfassungskompromiss , dem die neun vorwiegend englischsprachigen Provinzen schliesslich zugestimmt hatten , nicht abfinden . [SEP] \n",
    "[CLS] Von den beiden grossen Gewerkschaften hatte die HOLDER ( Unión General del Trabajo ) dieses TARGET unterstützt , während die Comisiones Obreras ( CCOO ) es im Vorfeld abgelehnt hatten , sich jetzt aber mit dem Resultat abfinden . [SEP] \n",
    "[CLS] Von den beiden grossen Gewerkschaften hatte die UGT ( Unión General del Trabajo ) dieses Vorhaben unterstützt , während die Comisiones Obreras ( CCOO ) es im Vorfeld abgelehnt hatten , sich jetzt aber mit dem Resultat abfinden . [SEP] \n",
    "[CLS] Der HOLDER hat keine TARGET verletzt . » Petkovic lehnt laut italienischen Medien auch ein Angebot ab , mit 30 Prozent der Summe abgefunden zu werden . [SEP] \n",
    "[CLS] Der Trainer hat keine Regeln verletzt . » Petkovic lehnt laut italienischen Medien auch ein Angebot ab , mit 30 Prozent der Summe abgefunden zu werden . [SEP] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe111bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG VARIABLES\n",
    "\n",
    "# DATASET_PATH=\"../../etl/data/raw/03_holder_target.txt\"\n",
    "\n",
    "TRAIN_DATASET_PATH=\"../../etl/data/processed/ORLConverter/01_train_orl.txt\"\n",
    "VAL_DATASET_PATH=\"../../etl/data/processed/ORLConverter/01_val_orl.txt\"\n",
    "TEST_DATASET_PATH=\"../../etl/data/processed/ORLConverter/01_test_orl.txt\"\n",
    "\n",
    "GENERATE_DATASET=True\n",
    "\n",
    "BASE_MODEL_NAME=\"distilbert-base-german-cased\"\n",
    "\n",
    "TRAINED_MODEL_NAME=\"./data/trained_model_german_bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbe029c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the data: 8622\n",
      "Total rows in the data: 1850\n",
      "Total rows in the data: 1866\n"
     ]
    }
   ],
   "source": [
    "def read_sents(dataset_path):\n",
    "    sents = []\n",
    "\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for c, l in enumerate(f.readlines()):\n",
    "            if c < 100:\n",
    "                pass\n",
    "            sents.append(l.strip())\n",
    "\n",
    "    # Der Minister findet die Debatte langweilig.\n",
    "    real_sents = sents[1::2]\n",
    "\n",
    "    # Der HOLDER findet die TARGET langweilig.\n",
    "    masked_sents = sents[0::2]\n",
    "\n",
    "    assert len(real_sents) == len(masked_sents), \"Nr of masked and real sentences are not equal!\"\n",
    "\n",
    "    print(f\"Total rows in the data: {len(real_sents) + len(masked_sents)}\")\n",
    "    \n",
    "    return real_sents, masked_sents\n",
    "\n",
    "train_sents_real, train_sents_masked = read_sents(TRAIN_DATASET_PATH)\n",
    "val_sents_real, val_sents_masked = read_sents(VAL_DATASET_PATH)\n",
    "test_sents_real, test_sents_masked = read_sents(TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd38cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max holders:  1 Max targets:  1 Max polar expressions:  1\n",
      "Max holders:  1 Max targets:  1 Max polar expressions:  1\n",
      "Max holders:  1 Max targets:  1 Max polar expressions:  1\n",
      "[{'id': 0, 'ner_tags': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Weil', 'BLICK', 'exklusiv', 'erfuhr', ':', 'Justizminister', 'Arnold', 'Koller', 'will', 'an', 'der', 'Bundesratssitzung', 'Lösungsvorschläge', 'einbringen', ',', 'um', 'der', 'Lage', 'Herr', 'zu', 'werden', '.']}, {'id': 1, 'ner_tags': [0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0], 'tokens': ['2018', 'gewann', 'Huggingface', 'auch', 'noch', 'den', 'ersten', 'Platz', 'in', 'einem', 'Wettbewerb', 'der', 'prestigeträchtigen', 'Neurips-Konferenz', 'für', 'maschinelles', 'Lernen', '.']}, {'id': 2, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0], 'tokens': ['In', 'den', 'Städten', ',', 'Kantonen', 'und', 'auf', 'Bundesebene', 'versuchen', 'Lobbygruppen', ',', 'die', 'Gesetze', 'im', 'Bereich', 'der', 'Ernährung', 'und', 'des', 'Tierschutzes', 'zu', 'verschärfen', '.']}, {'id': 3, 'ner_tags': [0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0], 'tokens': ['Am', 'Sonntag', 'bedankte', 'sich', 'die', 'Polizei', 'in', 'sozialen', 'Medien', 'für', 'die', 'Unterstützung', 'bei', 'der', 'Öffentlichkeit', '.']}, {'id': 4, 'ner_tags': [0, 1, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Weil', 'Sion', 'gegen', 'Servette', 'siegt', 'und', 'tags', 'zuvor', 'Vaduz', 'punktete', ',', 'rückt', 'das', 'Tabellenende', 'nun', 'immer', 'näher', 'zusammen', '.']}, {'id': 5, 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['«', 'Die', 'polnische', 'Wirtschaft', 'läuft', 'dank', 'Unterstützungsmassnahmen', 'der', 'EU', 'besser', ',', 'die', 'Leute', 'verdienen', 'unterdessen', 'im', 'eigenen', 'Land', 'genug', 'und', 'müssen', 'nicht', 'mehr', 'in', 'die', 'Schweiz', 'kommen', '.', '»', 'Zudem', 'seien', 'die', 'Löhne', 'in', 'der', 'Landwirtschaft', 'in', 'Ländern', 'wie', 'zum', 'Beispiel', 'Holland', 'gestiegen', ',', 'Osteuropäer', 'würden', 'daher', 'vermehrt', 'dort', 'arbeiten', '.']}, {'id': 6, 'ner_tags': [0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Der', 'Langzeit-SVP-Präsident', '(', '1996', 'bis', '2008', ')', 'gewann', 'mehr', 'als', 'jede', 'vierte', 'Volksabstimmung', 'gegen', 'die', '«', 'Classe', 'politique', '»', ':', 'acht', 'von', '29', 'Urnengängen', '.']}, {'id': 7, 'ner_tags': [0, 1, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Der', 'Vorsitzende', 'des', 'Verbands', 'warnte', 'die', 'Regierung', 'davor', ',', 'mit', 'einseitigen', 'Massnahmen', 'zur', 'Abänderung', 'des', '2019', 'mit', 'der', 'EU', 'vereinbarten', 'sogenannten', 'Nordirlands-Protokolls', 'die', 'Unsicherheiten', 'weiter', 'zu', 'erhöhen', '.']}, {'id': 8, 'ner_tags': [1, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['Benjamin', 'Kololli', 'bedankte', 'sich', 'mit', 'dem', 'Anschlusstreffer', 'zum', '2', ':', '3', 'via', 'Foulelfmeter', 'unmittelbar', 'vor', 'der', 'Pause', '.']}, {'id': 9, 'ner_tags': [1, 0, 0, 0, 0, 0, 0, 2, 3, 0], 'tokens': ['Brian', 'Acton', 'hatte', 'sich', 'für', 'ein', 'werbefreies', 'Netzwerk', 'eingesetzt', '.']}]\n"
     ]
    }
   ],
   "source": [
    "NER_labels = [\"O\", \"HOLDER\", \"TARGET\", \"PEXP\"]\n",
    "\n",
    "test_sent = [\"Peter sowie Lucy mag Katzen sowie auch Hunde .\"]\n",
    "test_sent_masked = [\"HOLDER sowie HOLDER mag TARGET sowie auch TARGET .\"]\n",
    "\n",
    "def align_sentences(real_sentences, masked_sentences, NER_labels):\n",
    "    \"\"\"Given two sentences that have their word-level tokens delimited by a white-space, \n",
    "    create NER-tags for each sentence token.\n",
    "    \"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    max_multiple_holders = 0\n",
    "    max_multiple_targets = 0\n",
    "    max_multiple_pexps = 0\n",
    "\n",
    "    for i, real_sentence, masked_sentence in zip(range(0,len(real_sentences)), real_sentences, masked_sentences):\n",
    "        ner_tags = []\n",
    "        real_sentence_split = real_sentence.split(\" \")\n",
    "        masked_sentence_split = masked_sentence.split(\" \")\n",
    "        \n",
    "        # target / holder counting\n",
    "        target_cnt = 0\n",
    "        holder_cnt = 0\n",
    "        pexp_cnt = 0\n",
    "\n",
    "        assert len(real_sentence_split) == len(masked_sentence_split), \"Misalignment of length of tokens in sentence.\" \\\n",
    "        + str(real_sentence_split) + str(masked_sentence_split) + str(i)\n",
    "\n",
    "        for real_token, masked_token in zip(real_sentence_split, masked_sentence_split):\n",
    "            if real_token == masked_token:\n",
    "                ner_tags.append(0)\n",
    "            elif masked_token == \"HOLDER\":\n",
    "                holder_cnt += 1\n",
    "                tag_index = NER_labels.index(masked_token)\n",
    "                ner_tags.append(tag_index)\n",
    "            elif masked_token == \"TARGET\":\n",
    "                target_cnt += 1\n",
    "                tag_index = NER_labels.index(masked_token)\n",
    "                ner_tags.append(tag_index)\n",
    "            elif masked_token == \"PEXP\":\n",
    "                pexp_cnt += 1\n",
    "                tag_index = NER_labels.index(masked_token)\n",
    "                ner_tags.append(tag_index)\n",
    "\n",
    "        dataset.append({\n",
    "            \"id\": i,\n",
    "            # remove the magic tokens from the sentences, \n",
    "            # since we will pass the sentences through the tokenizer again.\n",
    "            \"ner_tags\": ner_tags[1:-1],\n",
    "            \"tokens\": real_sentence_split[1:-1],\n",
    "        })\n",
    "    max_multiple_holders = max(max_multiple_holders, holder_cnt)\n",
    "    max_multiple_targets = max(max_multiple_targets, target_cnt)\n",
    "    max_multiple_pexps = max(max_multiple_pexps, pexp_cnt)\n",
    "\n",
    "    return dataset, max_multiple_holders, max_multiple_targets, max_multiple_pexps\n",
    "\n",
    "# align for training\n",
    "train_aligned_sents, mmh, mmt, mmp = align_sentences(train_sents_real, train_sents_masked, NER_labels)\n",
    "print(\"Max holders: \", mmh, \"Max targets: \", mmt, \"Max polar expressions: \", mmp)\n",
    "val_aligned_sents, mmh, mmt, mmp = align_sentences(val_sents_real, val_sents_masked, NER_labels)\n",
    "print(\"Max holders: \", mmh, \"Max targets: \", mmt, \"Max polar expressions: \", mmp)\n",
    "test_aligned_sents, mmh, mmt, mmp = align_sentences(test_sents_real, test_sents_masked, NER_labels)\n",
    "print(\"Max holders: \", mmh, \"Max targets: \", mmt, \"Max polar expressions: \", mmp)\n",
    "\n",
    "# UNCOMMENT FOR TEST\n",
    "# aligned_sents, mmh, mmt = align_sentences(test_sent, test_sent_masked, NER_labels)\n",
    "\n",
    "print(train_aligned_sents[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24033875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69618b114f9417b9d45d8ad01404b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07eb548413b4636aa2d6186ce22ce65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc4064c327f476f9499b6fcd79e222b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'ner_tags', 'tokens'],\n",
      "        num_rows: 4311\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['id', 'ner_tags', 'tokens'],\n",
      "        num_rows: 925\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'ner_tags', 'tokens'],\n",
      "        num_rows: 933\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Make a huggingface dataset out of the record-based dataset\n",
    "from datasets import Dataset, DatasetDict, load_from_disk\n",
    "\n",
    "if GENERATE_DATASET:\n",
    "    train_dataset = Dataset.from_list(train_aligned_sents)\n",
    "    val_dataset = Dataset.from_list(val_aligned_sents)\n",
    "    test_dataset = Dataset.from_list(test_aligned_sents)\n",
    "\n",
    "    # randomly shuffle\n",
    "    train_dataset = train_dataset.shuffle(seed=42)\n",
    "    val_dataset = val_dataset.shuffle(seed=42)\n",
    "    test_dataset = test_dataset.shuffle(seed=42)\n",
    "\n",
    "    # dataset = dataset.train_test_split(test_size=0.2, shuffle=False)\n",
    "    # train_test_dataset = dataset.train_test_split(test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Split the 10% test + valid in half test, half valid\n",
    "    # test_valid = train_test_dataset['test'].train_test_split(test_size=0.4, shuffle=False)\n",
    "\n",
    "    # gather everyone if you want to have a single DatasetDict\n",
    "    dataset = DatasetDict({\n",
    "        'train': train_dataset,\n",
    "        'valid': val_dataset,\n",
    "        'test': test_dataset})\n",
    "\n",
    "    dataset.save_to_disk(\"./data/split_dataset.hf\")\n",
    "else:\n",
    "    dataset = load_from_disk(\"./data/split_dataset.hf\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe90f4b",
   "metadata": {},
   "source": [
    "**Use DistilBERT tokenizer and embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac02eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53981c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [102, 13482, 15467, 2418, 146, 1120, 30555, 30913, 1330, 5451, 1552, 30887, 818, 208, 125, 10233, 334, 403, 326, 13197, 15118, 924, 223, 5636, 18526, 574, 6317, 566, 103], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'AL', '##EX', '##IS', 'M', '##EN', '##UG', '##E', 'Herr', 'Pan', '##enk', '##a', ',', 'an', 'der', 'EM', 'vor', 'einem', 'Jahr', 'scheiterte', 'Tschechien', 'erst', 'im', 'Viertel', '##final', 'gegen', 'Dänemark', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# tokenize input\n",
    "tokenized_input = tokenizer(dataset[\"train\"][0][\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "print(tokenized_input)\n",
    "\n",
    "# output subwords\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "005e2f43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b6e64ec72a4409b4fbd9f734aa9d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06ff2a682ba497abe139e45366df0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d511574d2d0485c986cf4bc49e9748b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4311\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 925\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 933\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    \n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        \n",
    "        try:\n",
    "            for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                    label_ids.append(label[word_idx])\n",
    "                else:\n",
    "                    label_ids.append(-100)\n",
    "                previous_word_idx = word_idx\n",
    "            labels.append(label_ids)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping example due to the following: { str(e) }\")\n",
    "            print(\" \".join(examples[f\"tokens\"][i]))\n",
    "            print(label)\n",
    "            continue\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57b33056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, -100, -100, 0, -100, -100, -100, 0, 0, -100, -100, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 2, -100, 0, 0, 0, -100]\n",
      "['[CLS]', 'AL', '##EX', '##IS', 'M', '##EN', '##UG', '##E', 'Herr', 'Pan', '##enk', '##a', ',', 'an', 'der', 'EM', 'vor', 'einem', 'Jahr', 'scheiterte', 'Tschechien', 'erst', 'im', 'Viertel', '##final', 'gegen', 'Dänemark', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# check that the conversion worked.\n",
    "print(tokenized_dataset[\"train\"][0][\"labels\"])\n",
    "print(tokenizer.convert_ids_to_tokens(tokenized_dataset[\"train\"][0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca79b234",
   "metadata": {},
   "source": [
    "**Define a DataCollator (for efficient padding of the tokens)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6470d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f37d16",
   "metadata": {},
   "source": [
    "**Download the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073f1432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-german-cased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "# num labels is 4 bcz of the -100 label\n",
    "model = AutoModelForTokenClassification.from_pretrained(BASE_MODEL_NAME, num_labels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc38168",
   "metadata": {},
   "source": [
    "***Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3cbd7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, ner_tags, id. If tokens, ner_tags, id are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/home/parallels/nbdev/lib64/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4311\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 810\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='810' max='810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [810/810 27:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.136171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.114677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.112271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, ner_tags, id. If tokens, ner_tags, id are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 925\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./data/results/checkpoint-500\n",
      "Configuration saved in ./data/results/checkpoint-500/config.json\n",
      "Model weights saved in ./data/results/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./data/results/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./data/results/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, ner_tags, id. If tokens, ner_tags, id are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 925\n",
      "  Batch size = 16\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: tokens, ner_tags, id. If tokens, ner_tags, id are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 925\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./data/trained_model_german_bert\n",
      "Configuration saved in ./data/trained_model_german_bert/config.json\n",
      "Model weights saved in ./data/trained_model_german_bert/pytorch_model.bin\n",
      "tokenizer config file saved in ./data/trained_model_german_bert/tokenizer_config.json\n",
      "Special tokens file saved in ./data/trained_model_german_bert/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./data/results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "091dd7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file ./data/trained_model_german_bert/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"./data/trained_model_german_bert\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file ./data/trained_model_german_bert/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
      "\n",
      "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at ./data/trained_model_german_bert.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# In case no model was loaded up until now.\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_path = TRAINED_MODEL_NAME\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a4f64c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_0',\n",
       "  'score': 0.99943393,\n",
       "  'index': 1,\n",
       "  'word': 'Er',\n",
       "  'start': 0,\n",
       "  'end': 2},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99932384,\n",
       "  'index': 2,\n",
       "  'word': 'sagt',\n",
       "  'start': 3,\n",
       "  'end': 7},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99940085,\n",
       "  'index': 3,\n",
       "  'word': ',',\n",
       "  'start': 7,\n",
       "  'end': 8},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99937755,\n",
       "  'index': 4,\n",
       "  'word': 'dass',\n",
       "  'start': 9,\n",
       "  'end': 13},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9993318,\n",
       "  'index': 5,\n",
       "  'word': 'der',\n",
       "  'start': 14,\n",
       "  'end': 17},\n",
       " {'entity': 'LABEL_1',\n",
       "  'score': 0.98201424,\n",
       "  'index': 6,\n",
       "  'word': 'Präsident',\n",
       "  'start': 18,\n",
       "  'end': 27},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9995322,\n",
       "  'index': 7,\n",
       "  'word': 'dem',\n",
       "  'start': 28,\n",
       "  'end': 31},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.8740551,\n",
       "  'index': 8,\n",
       "  'word': 'Volk',\n",
       "  'start': 32,\n",
       "  'end': 36},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.98325515,\n",
       "  'index': 9,\n",
       "  'word': 'etwas',\n",
       "  'start': 37,\n",
       "  'end': 42},\n",
       " {'entity': 'LABEL_3',\n",
       "  'score': 0.9126522,\n",
       "  'index': 10,\n",
       "  'word': 'vorge',\n",
       "  'start': 43,\n",
       "  'end': 48},\n",
       " {'entity': 'LABEL_3',\n",
       "  'score': 0.76627177,\n",
       "  'index': 11,\n",
       "  'word': '##macht',\n",
       "  'start': 48,\n",
       "  'end': 53},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9993148,\n",
       "  'index': 12,\n",
       "  'word': 'hat',\n",
       "  'start': 54,\n",
       "  'end': 57},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.99935335,\n",
       "  'index': 13,\n",
       "  'word': '.',\n",
       "  'start': 57,\n",
       "  'end': 58}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(task=\"token-classification\",\n",
    "                # model=trainer.model, -- in case freshly trained\n",
    "                model=model,\n",
    "                tokenizer=tokenizer)\n",
    "\n",
    "pipe(\"Er sagt, dass der Präsident dem Volk etwas vorgemacht hat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ef91e33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'LABEL_1',\n",
       "  'score': 0.9424176,\n",
       "  'index': 1,\n",
       "  'word': 'Peter',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9950648,\n",
       "  'index': 2,\n",
       "  'word': 'hat',\n",
       "  'start': 6,\n",
       "  'end': 9},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9327351,\n",
       "  'index': 3,\n",
       "  'word': 'etwas',\n",
       "  'start': 10,\n",
       "  'end': 15},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9905109,\n",
       "  'index': 4,\n",
       "  'word': 'gegen',\n",
       "  'start': 16,\n",
       "  'end': 21},\n",
       " {'entity': 'LABEL_2',\n",
       "  'score': 0.8834155,\n",
       "  'index': 5,\n",
       "  'word': 'Fritz',\n",
       "  'start': 22,\n",
       "  'end': 27},\n",
       " {'entity': 'LABEL_0',\n",
       "  'score': 0.9602219,\n",
       "  'index': 6,\n",
       "  'word': '!',\n",
       "  'start': 27,\n",
       "  'end': 28}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Peter hat etwas gegen Fritz!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2cf615",
   "metadata": {},
   "source": [
    "**Evaluation on the test / val set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "113c1218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d68f2c8385b41b48d4e2eb7d8d853c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/933 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c3a28dad33430d8a7a949eaaf96df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/933 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenized dataset, convert numerical labels to labels ready for evaluation.\n",
    "\n",
    "def labelize(example):\n",
    "    labels1 = []\n",
    "    for label in example[\"labels\"]:\n",
    "        if label in [0, -100]:\n",
    "            labels1.append(\"LABEL_0\")\n",
    "        if label in [1]:\n",
    "            labels1.append(\"LABEL_1\")\n",
    "        if label in [2]:\n",
    "            labels1.append(\"LABEL_2\")\n",
    "        if label in [3]:\n",
    "            labels1.append(\"LABEL_3\")\n",
    "    example[\"labels\"] = labels1\n",
    "    return example\n",
    "\n",
    "def subword_ids_to_strings(example):\n",
    "    example[\"subword_tokens\"] = tokenizer.convert_ids_to_tokens(example[\"input_ids\"])\n",
    "    return example\n",
    "\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(labelize)\n",
    "tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].map(subword_ids_to_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c986161f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vor allem der berüchtigten « Hölle des Nordens » von Paris nach Roubaix ( 17. April ) gilt seine Liebe .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# verify\n",
    "tokenizer.decode(tokenized_dataset[\"test\"][0][\"input_ids\"])\n",
    "len(tokenized_dataset[\"test\"])\n",
    "\n",
    "small_ds = tokenized_dataset[\"test\"].select(range(8))\n",
    "\n",
    "len(small_ds)\n",
    "\n",
    "\" \".join(small_ds[0][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc46aa04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 933/933 [00:30<00:00, 30.88it/s]\n",
      "/home/parallels/nbdev/lib64/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LABEL_0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/parallels/nbdev/lib64/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LABEL_2 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/parallels/nbdev/lib64/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LABEL_3 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/parallels/nbdev/lib64/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: LABEL_1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ABEL_0       0.66      0.69      0.68      3310\n",
      "      ABEL_1       0.73      0.82      0.77       933\n",
      "      ABEL_2       0.67      0.66      0.66       932\n",
      "      ABEL_3       0.83      0.88      0.86       933\n",
      "\n",
      "   micro avg       0.70      0.73      0.72      6108\n",
      "   macro avg       0.72      0.76      0.74      6108\n",
      "weighted avg       0.70      0.73      0.72      6108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "y_total_pred = []\n",
    "y_total_true = []\n",
    "\n",
    "for e in tqdm(tokenized_dataset[\"test\"]):\n",
    "    pred = [x[\"entity\"] for x in pipe(\" \".join(e[\"tokens\"]))]\n",
    "    # print(\"Prediction length:\", len(pred))\n",
    "    # print(\"Subword length:\", len(e[\"subword_tokens\"][1:-1]))\n",
    "    # print(\"Labels length:\", len(e[\"labels\"][1:-1]))\n",
    "    # print(\"----\")\n",
    "    y_total_pred.append(pred)\n",
    "    true = e[\"labels\"]\n",
    "    y_total_true.append(true[1:-1])\n",
    "\n",
    "print(classification_report(y_total_true, y_total_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19b514d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LABEL_0',\n",
       " 'LABEL_1',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_3',\n",
       " 'LABEL_0',\n",
       " 'LABEL_2',\n",
       " 'LABEL_2',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0',\n",
       " 'LABEL_0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe669a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
