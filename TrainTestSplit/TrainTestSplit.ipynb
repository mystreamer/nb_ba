{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7affb53a",
   "metadata": {},
   "source": [
    "## TrainTestSplit\n",
    "\n",
    "Create a train-test-split for the datasets found in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4e0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92e1a1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# makedirs if not exist\n",
    "os.makedirs(\"../../etl/data/intermediate/TrainTestSplit\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea40b93f",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "FULL_DATA_PATH=\"../../etl/data/raw/01_extract.csv\"\n",
    "TRAIN_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_train.csv\"\n",
    "TEST_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_test.csv\"\n",
    "VAL_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_val.csv\"\n",
    "\n",
    "# mode can be either \"CRITERIA_FREE\", \"DOC_SPLIT\", \"LEMMA_SPLIT\"\n",
    "SPLIT_MODE=\"LEMMA_SPLIT\"\n",
    "VERB_AGREEMENT_LEVEL = .6\n",
    "INCLUDE_SENTS_N_PAS = [1]\n",
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd8da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FULL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a8683e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e3...</td>\n",
       "      <td>abgestraft</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>abstrafen</td>\n",
       "      <td>Alexis Tsipras</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Alexis</td>\n",
       "      <td>...</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=...</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde , h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e3...</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>140</td>\n",
       "      <td>151</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>die neue Regierung</td>\n",
       "      <td>75</td>\n",
       "      <td>93</td>\n",
       "      <td>N</td>\n",
       "      <td>Regierung</td>\n",
       "      <td>...</td>\n",
       "      <td>die Hoffnungen auf einen spürbaren Aufschwung</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>N</td>\n",
       "      <td>Hoffnungen</td>\n",
       "      <td>98</td>\n",
       "      <td>108</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=...</td>\n",
       "      <td>Wenn die Kreditgeber Athen nicht zusätzlichen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e3...</td>\n",
       "      <td>beenden</td>\n",
       "      <td>119</td>\n",
       "      <td>126</td>\n",
       "      <td>beenden</td>\n",
       "      <td>Will er dem Land etwas Gutes tun</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>die politische Polarisierung beenden</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>Polarisierung</td>\n",
       "      <td>105</td>\n",
       "      <td>118</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=...</td>\n",
       "      <td>Will er dem Land etwas Gutes tun , dann sollte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb...</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>Pajtim Kasami</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>Pajtim</td>\n",
       "      <td>...</td>\n",
       "      <td>die Kurzarbeit nun doch</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>N</td>\n",
       "      <td>Kurzarbeit</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>pro</td>\n",
       "      <td>Predicate(type='pro', args=(Head(sentence=12, ...</td>\n",
       "      <td>Pajtim Kasami , Ermir Lenjani , Birama Ndoye u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb...</td>\n",
       "      <td>entliess</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>entlassen</td>\n",
       "      <td>der FC Sion</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>FC</td>\n",
       "      <td>...</td>\n",
       "      <td>Fussball Neun Spieler</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>Fussball</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=...</td>\n",
       "      <td>( dpa ) Fussball Neun Spieler entliess der FC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832168</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646...</td>\n",
       "      <td>äussert</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>äussern</td>\n",
       "      <td>Frau A</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Frau</td>\n",
       "      <td>...</td>\n",
       "      <td>massive Vorwürfe gegen ihre Vorgesetzten</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Vorwürfe</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=...</td>\n",
       "      <td>Dann äussert Frau A massive Vorwürfe gegen ihr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832169</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646...</td>\n",
       "      <td>stelle</td>\n",
       "      <td>184</td>\n",
       "      <td>190</td>\n",
       "      <td>stellen</td>\n",
       "      <td>das Kommando</td>\n",
       "      <td>171</td>\n",
       "      <td>183</td>\n",
       "      <td>N</td>\n",
       "      <td>Kommando</td>\n",
       "      <td>...</td>\n",
       "      <td>einen Antrag auf ihren Ausschluss</td>\n",
       "      <td>191</td>\n",
       "      <td>224</td>\n",
       "      <td>N</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>197</td>\n",
       "      <td>203</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=...</td>\n",
       "      <td>Am 5. Dezember stellt der Chef der Abteilung M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832170</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a...</td>\n",
       "      <td>ausgewiesen</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>ausweisen</td>\n",
       "      <td>Der Konzern</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>Konzern</td>\n",
       "      <td>...</td>\n",
       "      <td>eine Liquidität</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>N</td>\n",
       "      <td>Liquidität</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=19, ...</td>\n",
       "      <td>Der Konzern hatte im April noch eine Liquiditä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832171</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a...</td>\n",
       "      <td>belebt</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>beleben</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>...</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=25, ...</td>\n",
       "      <td>Seitdem belebt sich das Verkehrsaufkommen auf ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832172</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a...</td>\n",
       "      <td>halten</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>halten</td>\n",
       "      <td>Die Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>N</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>...</td>\n",
       "      <td>möglichst gering</td>\n",
       "      <td>108</td>\n",
       "      <td>124</td>\n",
       "      <td>ADV</td>\n",
       "      <td>gering</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=...</td>\n",
       "      <td>Die Lufthansa versucht verständlicherweise den...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832173 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   doc_id    verb_form  \\\n",
       "0       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e3...   abgestraft   \n",
       "1       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e3...  enttäuschen   \n",
       "2       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e3...      beenden   \n",
       "3       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb...  akzeptieren   \n",
       "4       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb...     entliess   \n",
       "...                                                   ...          ...   \n",
       "832168  9701f0c776430a365f0619836f34658459be788b9a6646...      äussert   \n",
       "832169  9701f0c776430a365f0619836f34658459be788b9a6646...       stelle   \n",
       "832170  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a...  ausgewiesen   \n",
       "832171  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a...       belebt   \n",
       "832172  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a...       halten   \n",
       "\n",
       "        verb_form_start  verb_form_end   verb_lemma  \\\n",
       "0                    26             36    abstrafen   \n",
       "1                   140            151  enttäuschen   \n",
       "2                   119            126      beenden   \n",
       "3                    69             80  akzeptieren   \n",
       "4                    30             38    entlassen   \n",
       "...                 ...            ...          ...   \n",
       "832168                5             12      äussern   \n",
       "832169              184            190      stellen   \n",
       "832170               77             88    ausweisen   \n",
       "832171                8             14      beleben   \n",
       "832172              128            134       halten   \n",
       "\n",
       "                                     arg1  arg1_start  arg1_end arg1_pos  \\\n",
       "0                          Alexis Tsipras           5        19        N   \n",
       "1                      die neue Regierung          75        93        N   \n",
       "2       Will er dem Land etwas Gutes tun            0        33       $.   \n",
       "3                          Pajtim Kasami            0        14        N   \n",
       "4                             der FC Sion          39        50        N   \n",
       "...                                   ...         ...       ...      ...   \n",
       "832168                             Frau A          13        19        N   \n",
       "832169                       das Kommando         171       183        N   \n",
       "832170                        Der Konzern           0        11        N   \n",
       "832171              das Verkehrsaufkommen          20        41        N   \n",
       "832172                      Die Lufthansa           0        13        N   \n",
       "\n",
       "                arg1_head  ...                                           arg2  \\\n",
       "0                  Alexis  ...    Dass Alexis Tsipras jetzt abgestraft wurde    \n",
       "1               Regierung  ...  die Hoffnungen auf einen spürbaren Aufschwung   \n",
       "2                       .  ...          die politische Polarisierung beenden    \n",
       "3                  Pajtim  ...                       die Kurzarbeit nun doch    \n",
       "4                      FC  ...                          Fussball Neun Spieler   \n",
       "...                   ...  ...                                            ...   \n",
       "832168               Frau  ...       massive Vorwürfe gegen ihre Vorgesetzten   \n",
       "832169           Kommando  ...              einen Antrag auf ihren Ausschluss   \n",
       "832170            Konzern  ...                                eine Liquidität   \n",
       "832171  Verkehrsaufkommen  ...                          das Verkehrsaufkommen   \n",
       "832172          Lufthansa  ...                               möglichst gering   \n",
       "\n",
       "        arg2_start arg2_end  arg2_pos          arg2_head arg2_head_start  \\\n",
       "0                0       43        $.                  .             143   \n",
       "1               94      139         N         Hoffnungen              98   \n",
       "2               90      127         N      Polarisierung             105   \n",
       "3               81      105         N         Kurzarbeit              85   \n",
       "4                8       29         N           Fussball               8   \n",
       "...            ...      ...       ...                ...             ...   \n",
       "832168          20       60         N           Vorwürfe              28   \n",
       "832169         191      224         N             Antrag             197   \n",
       "832170          32       47         N         Liquidität              37   \n",
       "832171          20       41         N  Verkehrsaufkommen              24   \n",
       "832172         108      124       ADV             gering             118   \n",
       "\n",
       "       arg2_head_end  rel_type  \\\n",
       "0                144   neutral   \n",
       "1                108   neutral   \n",
       "2                118   neutral   \n",
       "3                 95       pro   \n",
       "4                 16   neutral   \n",
       "...              ...       ...   \n",
       "832168            36   neutral   \n",
       "832169           203   neutral   \n",
       "832170            47       con   \n",
       "832171            41       con   \n",
       "832172           124   neutral   \n",
       "\n",
       "                                              pred_serial  \\\n",
       "0       Predicate(type='neutral', args=(Head(sentence=...   \n",
       "1       Predicate(type='neutral', args=(Head(sentence=...   \n",
       "2       Predicate(type='neutral', args=(Head(sentence=...   \n",
       "3       Predicate(type='pro', args=(Head(sentence=12, ...   \n",
       "4       Predicate(type='neutral', args=(Head(sentence=...   \n",
       "...                                                   ...   \n",
       "832168  Predicate(type='neutral', args=(Head(sentence=...   \n",
       "832169  Predicate(type='neutral', args=(Head(sentence=...   \n",
       "832170  Predicate(type='con', args=(Head(sentence=19, ...   \n",
       "832171  Predicate(type='con', args=(Head(sentence=25, ...   \n",
       "832172  Predicate(type='neutral', args=(Head(sentence=...   \n",
       "\n",
       "                                       full_sentence_text  \n",
       "0       Dass Alexis Tsipras jetzt abgestraft wurde , h...  \n",
       "1       Wenn die Kreditgeber Athen nicht zusätzlichen ...  \n",
       "2       Will er dem Land etwas Gutes tun , dann sollte...  \n",
       "3       Pajtim Kasami , Ermir Lenjani , Birama Ndoye u...  \n",
       "4       ( dpa ) Fussball Neun Spieler entliess der FC ...  \n",
       "...                                                   ...  \n",
       "832168  Dann äussert Frau A massive Vorwürfe gegen ihr...  \n",
       "832169  Am 5. Dezember stellt der Chef der Abteilung M...  \n",
       "832170  Der Konzern hatte im April noch eine Liquiditä...  \n",
       "832171  Seitdem belebt sich das Verkehrsaufkommen auf ...  \n",
       "832172  Die Lufthansa versucht verständlicherweise den...  \n",
       "\n",
       "[832173 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by sentences\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17861766",
   "metadata": {},
   "source": [
    "**How big is the problem with multi-PAS per sentence?**\n",
    "\n",
    "Which should not be split accross the dataset splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2a33f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rel_type  counts\n",
       "con       1          80668\n",
       "          2           8149\n",
       "          3            785\n",
       "          4             68\n",
       "          5              3\n",
       "neutral   1         569679\n",
       "          2          51984\n",
       "          3           3348\n",
       "          4            223\n",
       "          5             27\n",
       "          7              7\n",
       "          8              8\n",
       "pro       1         107311\n",
       "          2           9187\n",
       "          3            676\n",
       "          4             45\n",
       "          5              5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_occ = df.copy(deep=True)\n",
    "df_occ = df_occ.merge(df_occ.groupby([\"doc_id\", \"full_sentence_text\"]).size().reset_index(name=\"counts\"), on=[\"doc_id\", \"full_sentence_text\"])\n",
    "df_occ_freq = df_occ.groupby([\"rel_type\", \"counts\"]).size()\n",
    "df_occ_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a057fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter needed pas per sentence\n",
    "# 0 - exclude sents, which have more than N specified pas.\n",
    "mask = ~(df_occ[\"counts\"].isin(INCLUDE_SENTS_N_PAS))\n",
    "df_occ = df_occ[mask]\n",
    "n_pas_sents = df_occ[\"full_sentence_text\"].to_list()\n",
    "\n",
    "df = df[~df.full_sentence_text.isin(n_pas_sents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04671a8",
   "metadata": {},
   "source": [
    "### Complex sentences analysis\n",
    "\n",
    "**How do the multi-PAS sentences look**?\n",
    "\n",
    "Complexity and sentence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2764efa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>616300</th>\n",
       "      <td>086fbc038e6331ebb08719cfe0862c559619745be62c158b962269d0a3cd6d67</td>\n",
       "      <td>schützen</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>schützen</td>\n",
       "      <td>Israel</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>N</td>\n",
       "      <td>Israel</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>N</td>\n",
       "      <td>Religionsfreiheit</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>pro</td>\n",
       "      <td>Predicate(type='pro', args=(Head(sentence=19, token=0), Head(sentence=19, token=3)), strength=0, verb=6)</td>\n",
       "      <td>Israel müsse die Religionsfreiheit der Palästinenser schützen und dürfe die Heiligkeit der Al-Aksa-Moschee nicht verletzen , erklärte der emiratische Staatsminister für auswärtige Angelegenheiten , Khalifa al-Marar .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616301</th>\n",
       "      <td>086fbc038e6331ebb08719cfe0862c559619745be62c158b962269d0a3cd6d67</td>\n",
       "      <td>verletzen</td>\n",
       "      <td>113</td>\n",
       "      <td>122</td>\n",
       "      <td>verletzen</td>\n",
       "      <td>Israel müsse die Religionsfreiheit der Palästinenser schützen und dürfe die Heiligkeit der Al-Aksa-Moschee nicht verletzen</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>106</td>\n",
       "      <td>N</td>\n",
       "      <td>Heiligkeit</td>\n",
       "      <td>76</td>\n",
       "      <td>86</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=19, token=-1), Head(sentence=19, token=10)), strength=0, verb=14)</td>\n",
       "      <td>Israel müsse die Religionsfreiheit der Palästinenser schützen und dürfe die Heiligkeit der Al-Aksa-Moschee nicht verletzen , erklärte der emiratische Staatsminister für auswärtige Angelegenheiten , Khalifa al-Marar .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  doc_id  \\\n",
       "616300  086fbc038e6331ebb08719cfe0862c559619745be62c158b962269d0a3cd6d67   \n",
       "616301  086fbc038e6331ebb08719cfe0862c559619745be62c158b962269d0a3cd6d67   \n",
       "\n",
       "        verb_form  verb_form_start  verb_form_end verb_lemma  \\\n",
       "616300   schützen               53             61   schützen   \n",
       "616301  verletzen              113            122  verletzen   \n",
       "\n",
       "                                                                                                                               arg1  \\\n",
       "616300                                                                                                                       Israel   \n",
       "616301  Israel müsse die Religionsfreiheit der Palästinenser schützen und dürfe die Heiligkeit der Al-Aksa-Moschee nicht verletzen    \n",
       "\n",
       "        arg1_start  arg1_end arg1_pos arg1_head  ...  arg2_start  arg2_end  \\\n",
       "616300           0         6        N    Israel  ...          13        52   \n",
       "616301           0       123       $.         .  ...          72       106   \n",
       "\n",
       "       arg2_pos          arg2_head  arg2_head_start arg2_head_end rel_type  \\\n",
       "616300        N  Religionsfreiheit               17            34      pro   \n",
       "616301        N         Heiligkeit               76            86  neutral   \n",
       "\n",
       "                                                                                                            pred_serial  \\\n",
       "616300         Predicate(type='pro', args=(Head(sentence=19, token=0), Head(sentence=19, token=3)), strength=0, verb=6)   \n",
       "616301  Predicate(type='neutral', args=(Head(sentence=19, token=-1), Head(sentence=19, token=10)), strength=0, verb=14)   \n",
       "\n",
       "                                                                                                                                                                                                              full_sentence_text  \\\n",
       "616300  Israel müsse die Religionsfreiheit der Palästinenser schützen und dürfe die Heiligkeit der Al-Aksa-Moschee nicht verletzen , erklärte der emiratische Staatsminister für auswärtige Angelegenheiten , Khalifa al-Marar .   \n",
       "616301  Israel müsse die Religionsfreiheit der Palästinenser schützen und dürfe die Heiligkeit der Al-Aksa-Moschee nicht verletzen , erklärte der emiratische Staatsminister für auswärtige Angelegenheiten , Khalifa al-Marar .   \n",
       "\n",
       "       counts  \n",
       "616300      2  \n",
       "616301      2  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "s1 = df_occ[df_occ[\"counts\"] >= 2] \\\n",
    "    .sort_values([\"full_sentence_text\"]) \\\n",
    "    .sample(n=1)\n",
    "s1_val = s1[\"full_sentence_text\"].to_list()[0]\n",
    "df_occ[df_occ[\"full_sentence_text\"] == s1_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12305ffc",
   "metadata": {},
   "source": [
    "**Seeking for specific multi-PAS sentences:**\n",
    "\n",
    "Ones where:\n",
    "$MP^{arg_1}_1=MP^{arg_1}_2$ or  $MP^{arg_2}_1=MP^{arg_2}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "860d4a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all docIDs and sents where this hold and then filter by them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1db8f6",
   "metadata": {},
   "source": [
    "**Verb mixing**\n",
    "\n",
    "How large is the likelihood that a verb-mediated relation is positive, then negative.\n",
    "\n",
    "Potentially: try to remove this ambiguity.\n",
    "\n",
    "***Agreement metric:*** What are particularly ambiguous verbs, and can \"entity\" type restrictions be learned around them? What are not very ambigious words?\n",
    "\n",
    "=> Using a measure of [balance](https://stats.stackexchange.com/questions/239973/a-general-measure-of-data-set-imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa945afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(seq):\n",
    "    \"\"\"\n",
    "        Provides a measure of balancedness.\n",
    "        input: sequence of class counts\n",
    "        0 means unbalanced, which is better! more agreement!\n",
    "        1 means balanced\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    from numpy import log\n",
    "    \n",
    "    # define this as a high agreement\n",
    "    if len(seq) == 1:\n",
    "        # we'll define a single class as highly unbalanced\n",
    "        return 0.0\n",
    "    \n",
    "    # n = len(seq)\n",
    "    n = sum(seq)\n",
    "    # classes = [(clas,float(count)) for clas,count in Counter(seq).items()]\n",
    "    k = len(seq)\n",
    "    \n",
    "    H = -sum([ (count/n) * log((count/n)) for clas,count in enumerate(seq)]) #shannon entropy\n",
    "    return H/(log(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c9e5021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance([500, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd379ac8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>irren</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>mühen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>bewirken</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>nachgeben</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>beweisen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>runterputzen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>anwidern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>unterjubeln</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>einlullen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>bekehren</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       verb_lemma  balance\n",
       "578         irren      0.0\n",
       "674         mühen      0.0\n",
       "295      bewirken      0.0\n",
       "676     nachgeben      0.0\n",
       "293      beweisen      0.0\n",
       "..            ...      ...\n",
       "748  runterputzen      1.0\n",
       "106      anwidern      1.0\n",
       "860   unterjubeln      1.0\n",
       "367     einlullen      1.0\n",
       "228      bekehren      1.0\n",
       "\n",
       "[1157 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixing = df.copy(deep=True)\n",
    "df_mixing\n",
    "df_mixing = df_mixing.groupby([\"verb_lemma\", \"rel_type\"]).size().reset_index(name=\"counts\")\n",
    "df_mixing = df_mixing.groupby([\"verb_lemma\"]).apply(lambda x: balance(x[\"counts\"].to_list())).reset_index(name=\"balance\").dropna()\n",
    "df_mixing.sort_values(\"balance\")\n",
    "# df_mixing[df_mixing[\"verb_lemma\"] == \"verübeln\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baa055c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "629"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of the balancedness?\n",
    "df_mixing.balance.value_counts()\n",
    "# get all verbs with balance 0.0\n",
    "agreeable_verbs = df_mixing[df_mixing[\"balance\"] <= VERB_AGREEMENT_LEVEL][\"verb_lemma\"].to_list()\n",
    "len(agreeable_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "def55beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>nachgeben</td>\n",
       "      <td>neutral</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     verb_lemma rel_type  counts\n",
       "1451  nachgeben  neutral     422"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of verbs and their agreement\n",
    "df_analysis = df.copy(deep=True)\n",
    "df_analysis = df_analysis.groupby([\"verb_lemma\", \"rel_type\"]).size().reset_index(name=\"counts\")\n",
    "df_analysis[df_analysis[\"verb_lemma\"] == \"nachgeben\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0b3f0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>abgestraft</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>abstrafen</td>\n",
       "      <td>Alexis Tsipras</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Alexis</td>\n",
       "      <td>...</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>140</td>\n",
       "      <td>151</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>die neue Regierung</td>\n",
       "      <td>75</td>\n",
       "      <td>93</td>\n",
       "      <td>N</td>\n",
       "      <td>Regierung</td>\n",
       "      <td>...</td>\n",
       "      <td>die Hoffnungen auf einen spürbaren Aufschwung</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>N</td>\n",
       "      <td>Hoffnungen</td>\n",
       "      <td>98</td>\n",
       "      <td>108</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)</td>\n",
       "      <td>Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>beenden</td>\n",
       "      <td>119</td>\n",
       "      <td>126</td>\n",
       "      <td>beenden</td>\n",
       "      <td>Will er dem Land etwas Gutes tun</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>die politische Polarisierung beenden</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>Polarisierung</td>\n",
       "      <td>105</td>\n",
       "      <td>118</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)</td>\n",
       "      <td>Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>Pajtim Kasami</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>Pajtim</td>\n",
       "      <td>...</td>\n",
       "      <td>die Kurzarbeit nun doch</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>N</td>\n",
       "      <td>Kurzarbeit</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>pro</td>\n",
       "      <td>Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)</td>\n",
       "      <td>Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>entliess</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>entlassen</td>\n",
       "      <td>der FC Sion</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>FC</td>\n",
       "      <td>...</td>\n",
       "      <td>Fussball Neun Spieler</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>Fussball</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)</td>\n",
       "      <td>( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832168</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>äussert</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>äussern</td>\n",
       "      <td>Frau A</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Frau</td>\n",
       "      <td>...</td>\n",
       "      <td>massive Vorwürfe gegen ihre Vorgesetzten</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Vorwürfe</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)</td>\n",
       "      <td>Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832169</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>stelle</td>\n",
       "      <td>184</td>\n",
       "      <td>190</td>\n",
       "      <td>stellen</td>\n",
       "      <td>das Kommando</td>\n",
       "      <td>171</td>\n",
       "      <td>183</td>\n",
       "      <td>N</td>\n",
       "      <td>Kommando</td>\n",
       "      <td>...</td>\n",
       "      <td>einen Antrag auf ihren Ausschluss</td>\n",
       "      <td>191</td>\n",
       "      <td>224</td>\n",
       "      <td>N</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>197</td>\n",
       "      <td>203</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)</td>\n",
       "      <td>Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832170</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>ausgewiesen</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>ausweisen</td>\n",
       "      <td>Der Konzern</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>Konzern</td>\n",
       "      <td>...</td>\n",
       "      <td>eine Liquidität</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>N</td>\n",
       "      <td>Liquidität</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)</td>\n",
       "      <td>Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832171</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>belebt</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>beleben</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>...</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)</td>\n",
       "      <td>Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832172</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>halten</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>halten</td>\n",
       "      <td>Die Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>N</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>...</td>\n",
       "      <td>möglichst gering</td>\n",
       "      <td>108</td>\n",
       "      <td>124</td>\n",
       "      <td>ADV</td>\n",
       "      <td>gering</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)</td>\n",
       "      <td>Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757627 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  doc_id  \\\n",
       "0       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "1       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "2       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "3       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "4       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "...                                                                  ...   \n",
       "832168  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832169  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832170  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832171  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832172  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "\n",
       "          verb_form  verb_form_start  verb_form_end   verb_lemma  \\\n",
       "0        abgestraft               26             36    abstrafen   \n",
       "1       enttäuschen              140            151  enttäuschen   \n",
       "2           beenden              119            126      beenden   \n",
       "3       akzeptieren               69             80  akzeptieren   \n",
       "4          entliess               30             38    entlassen   \n",
       "...             ...              ...            ...          ...   \n",
       "832168      äussert                5             12      äussern   \n",
       "832169       stelle              184            190      stellen   \n",
       "832170  ausgewiesen               77             88    ausweisen   \n",
       "832171       belebt                8             14      beleben   \n",
       "832172       halten              128            134       halten   \n",
       "\n",
       "                                     arg1  arg1_start  arg1_end arg1_pos  \\\n",
       "0                          Alexis Tsipras           5        19        N   \n",
       "1                      die neue Regierung          75        93        N   \n",
       "2       Will er dem Land etwas Gutes tun            0        33       $.   \n",
       "3                          Pajtim Kasami            0        14        N   \n",
       "4                             der FC Sion          39        50        N   \n",
       "...                                   ...         ...       ...      ...   \n",
       "832168                             Frau A          13        19        N   \n",
       "832169                       das Kommando         171       183        N   \n",
       "832170                        Der Konzern           0        11        N   \n",
       "832171              das Verkehrsaufkommen          20        41        N   \n",
       "832172                      Die Lufthansa           0        13        N   \n",
       "\n",
       "                arg1_head  ...                                           arg2  \\\n",
       "0                  Alexis  ...    Dass Alexis Tsipras jetzt abgestraft wurde    \n",
       "1               Regierung  ...  die Hoffnungen auf einen spürbaren Aufschwung   \n",
       "2                       .  ...          die politische Polarisierung beenden    \n",
       "3                  Pajtim  ...                       die Kurzarbeit nun doch    \n",
       "4                      FC  ...                          Fussball Neun Spieler   \n",
       "...                   ...  ...                                            ...   \n",
       "832168               Frau  ...       massive Vorwürfe gegen ihre Vorgesetzten   \n",
       "832169           Kommando  ...              einen Antrag auf ihren Ausschluss   \n",
       "832170            Konzern  ...                                eine Liquidität   \n",
       "832171  Verkehrsaufkommen  ...                          das Verkehrsaufkommen   \n",
       "832172          Lufthansa  ...                               möglichst gering   \n",
       "\n",
       "        arg2_start arg2_end  arg2_pos          arg2_head arg2_head_start  \\\n",
       "0                0       43        $.                  .             143   \n",
       "1               94      139         N         Hoffnungen              98   \n",
       "2               90      127         N      Polarisierung             105   \n",
       "3               81      105         N         Kurzarbeit              85   \n",
       "4                8       29         N           Fussball               8   \n",
       "...            ...      ...       ...                ...             ...   \n",
       "832168          20       60         N           Vorwürfe              28   \n",
       "832169         191      224         N             Antrag             197   \n",
       "832170          32       47         N         Liquidität              37   \n",
       "832171          20       41         N  Verkehrsaufkommen              24   \n",
       "832172         108      124       ADV             gering             118   \n",
       "\n",
       "       arg2_head_end  rel_type  \\\n",
       "0                144   neutral   \n",
       "1                108   neutral   \n",
       "2                118   neutral   \n",
       "3                 95       pro   \n",
       "4                 16   neutral   \n",
       "...              ...       ...   \n",
       "832168            36   neutral   \n",
       "832169           203   neutral   \n",
       "832170            47       con   \n",
       "832171            41       con   \n",
       "832172           124   neutral   \n",
       "\n",
       "                                                                                                            pred_serial  \\\n",
       "0           Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)   \n",
       "1       Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)   \n",
       "2       Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)   \n",
       "3            Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)   \n",
       "4          Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)   \n",
       "...                                                                                                                 ...   \n",
       "832168     Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)   \n",
       "832169  Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)   \n",
       "832170        Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)   \n",
       "832171         Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)   \n",
       "832172   Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)   \n",
       "\n",
       "                                                                                                                                                                                                                        full_sentence_text  \n",
       "0                                                                                         Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .  \n",
       "1                                                                                Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .  \n",
       "2                                                Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .  \n",
       "3                                                    Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .  \n",
       "4                                                                                                                       ( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .  \n",
       "...                                                                                                                                                                                                                                    ...  \n",
       "832168                                                                                                                                                                      Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .  \n",
       "832169  Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .  \n",
       "832170                                                                                                                                          Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .  \n",
       "832171                                                                                                                                                       Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .  \n",
       "832172                                                                                            Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .  \n",
       "\n",
       "[757627 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64026628",
   "metadata": {},
   "source": [
    "**How big is the problem of -1 in first span or a \".\" in the data?**\n",
    "\n",
    "The -1 does not exist. No problem currently.\n",
    "\n",
    "The \".\" is quite prevalent and strangely only occurrs in the neutral case. That's why a cleaning step was introduced below (see solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a2c5f",
   "metadata": {},
   "source": [
    "**Clean dataset**\n",
    "\n",
    "1. As seen below we must remove the argument heads make sure we don't have any \".\" as arguments for the neutrals.\n",
    "2. We also want to remove the reflexive cases for the pronouns.\n",
    "3. Only include verbs that fulfill balancedness criteria, execute cell 17 & 18 for this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbaffbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pro        6107\n",
       "neutral    4871\n",
       "con        3383\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty = df.copy(deep=True)\n",
    "df_dirty[\n",
    "#(df_dirty[\"arg1_head\"] == \".\")\n",
    "#|(df_dirty[\"arg2_head\"] == \".\")\n",
    "#|(df_dirty[\"arg2\"] == \".\")\n",
    "#|(df_dirty[\"arg2\"] == \".\")\n",
    "#(df_dirty[\"arg1_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_head_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_head_start\"] == -1)\n",
    "(df_dirty[\"arg1\"] == df_dirty[\"arg2\"])\n",
    "& (df_dirty[\"full_sentence_text\"].str.contains(\"sich\")) # reflexive verbs, should be ignore?\n",
    "].rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "544cf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - include dotted (most likely with no target or other thing, or are these the -1 ones)\n",
    "mask = ~((df[\"arg1_head\"] == \".\")\n",
    "|(df[\"arg2_head\"] == \".\")\n",
    "|(df[\"arg2\"] == \".\")\n",
    "|(df[\"arg2\"] == \".\"))\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "\n",
    "# 2 - exclude reflexive\n",
    "mask = ~(df[\"arg1\"] == df[\"arg2\"])\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "# 3 - exclude balanced = ambiguous verbs.\n",
    "mask = (df[\"verb_lemma\"].isin(agreeable_verbs))\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "# 4 - exclude sents, where the arg1_head_start and arg2_head_start overlap (due to stancer data extraction)\n",
    "mask = ~(df[\"arg1_head_start\"] == df[\"arg2_head_start\"])\n",
    "\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e267c85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral    280596\n",
       "pro         15802\n",
       "con         11753\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(agreeable_verbs))\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738fad7",
   "metadata": {},
   "source": [
    "**Balance the dataset**\n",
    "\n",
    "Make sure that each class is represented equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9bf7f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        11753\n",
       "neutral    11753\n",
       "pro        11753\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('rel_type')\n",
    "df = df.apply(lambda x: x.sample(df.size().min(), random_state=RANDOM_STATE).reset_index(drop=True))\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b413939b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        11753\n",
       "neutral    11753\n",
       "pro        11753\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(level=0, drop=True)\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4d85ea",
   "metadata": {},
   "source": [
    "**Analyzing the verb distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ba736f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /home/parallels/nbdev/lib/python3.10/site-packages (5.13.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/parallels/nbdev/lib/python3.10/site-packages (from plotly) (8.2.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af3b4e4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        verb_lemma  counts\n",
      "334        stellen    3385\n",
      "28      ankündigen    1535\n",
      "209         freuen    1431\n",
      "47       aufnehmen    1171\n",
      "212         gelten    1046\n",
      "..             ...     ...\n",
      "46       auflehnen       1\n",
      "237        hungern       1\n",
      "239  ideologisiert       1\n",
      "450      zermürben       1\n",
      "51       ausbeuten       1\n",
      "\n",
      "[483 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def analyse_verb_frequency(df):\n",
    "    df_analysis = df.copy(deep=True)\n",
    "    df_analysis = df_analysis.groupby([\"verb_lemma\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "    # get a verb that is needed in the distribution\n",
    "    # print(df_analysis[df_analysis[\"counts\"] == 1][\"verb_lemma\"])\n",
    "    # the counts of the counts\n",
    "    # df_analysis = df_analysis.groupby([\"counts\"]).size().reset_index(name=\"count_counts\")\n",
    "    # print(len(df_analysis))\n",
    "\n",
    "    # generate a sufficient bin width\n",
    "    bin_width= 10\n",
    "    # here you can choose your rounding method, I've chosen math.ceil.\n",
    "    nbins = math.ceil((df_analysis[\"counts\"].max() - df_analysis[\"counts\"].min()) / bin_width)\n",
    "\n",
    "\n",
    "    fig = px.histogram(df_analysis, \n",
    "                       x=\"counts\", \n",
    "                       nbins=nbins,\n",
    "                       title=\"Verb Frequency over the number of verbs\", \n",
    "                       labels={'counts': 'Frequency of verbs'}\n",
    "                      ).update_layout(yaxis_title='Number of verbs')\n",
    "\n",
    "    # fig.show()\n",
    "\n",
    "    print(df_analysis.sort_values(by=\"counts\", ascending=False))\n",
    "    \n",
    "analyse_verb_frequency(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dabd997",
   "metadata": {},
   "source": [
    "**Option 1: Train-test-splitting**\n",
    "\n",
    "Only problem: We may have sentences within the same documents with multiple PAS that are split accross the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e0c85de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPLIT_MODE == \"CRITERIA_FREE\":\n",
    "    train, test_val = train_test_split(df, test_size=0.3, stratify=df[\"rel_type\"], random_state=RANDOM_STATE)\n",
    "    test, val = train_test_split(test_val, test_size=0.5, stratify=test_val[\"rel_type\"],random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ac2fc",
   "metadata": {},
   "source": [
    "**Option 2: Train-test-splitting**\n",
    "\n",
    "With respecting group distribution. Which means that all sentences $S_{1..N}$ from a document $A$ will either all be in the test set, all be in the validation set or all be in the training set. The reason for this is since it could happen that multiple PAS are detected within the same sentence and then the system is trained to one PAS and is evaluated on a completely different PAS, which is unfair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7d508ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPLIT_MODE==\"DOC_SPLIT\":\n",
    "    # preserve groups between sentences (in this case doc_id is safe enough)\n",
    "    splitter = GroupShuffleSplit(test_size=.30, n_splits=1, random_state=RANDOM_STATE)\n",
    "    split = splitter.split(df, groups=df['doc_id'])\n",
    "    train_inds, test_val_inds = next(split)\n",
    "\n",
    "    train = df.iloc[train_inds]\n",
    "    test_val = df.iloc[test_val_inds]\n",
    "\n",
    "    splitter = GroupShuffleSplit(test_size=.5, n_splits=1, random_state=RANDOM_STATE)\n",
    "    split = splitter.split(test_val, groups=test_val['doc_id'])\n",
    "    test_inds, val_inds = next(split)\n",
    "\n",
    "    test = test_val.iloc[test_inds]\n",
    "    val = test_val.iloc[val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0998610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "TRAIN: [1, 1, 3, 3, 3, 8, 8] TEST: [2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# a small test to see whether option no 2 achieves our goals.\n",
    "\n",
    "X = np.ones(shape=(10, 2))\n",
    "y = np.ones(shape=(10, 1))\n",
    "groups = np.array([1, 1, 2, 2, 2, 3, 3, 3, 8, 8])\n",
    "print(groups.shape)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=42)\n",
    "gss.get_n_splits()\n",
    "\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", [groups[i] for i in train_idx], \"TEST:\", [groups[i] for i in test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5440b6",
   "metadata": {},
   "source": [
    "## Hard-verb splitting\n",
    "\n",
    "To test generalisability we may want to split verbs by train and test set.\n",
    "\n",
    "**Solution**: We can simply use the group splitting argument on the verbs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c4dc3e",
   "metadata": {},
   "source": [
    "**Option 3: Train-test split with verb-splitting**\n",
    "\n",
    "This means that given a verb $V$, all sentences which contain that verb will either be in $T_{RAIN}$, $V_{ALID}$ or $T_{EST}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cea2cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPLIT_MODE == \"LEMMA_SPLIT\":\n",
    "    # preserve groups between sentences (in this case verbs)\n",
    "    splitter = GroupShuffleSplit(test_size=.30, n_splits=1, random_state=RANDOM_STATE)\n",
    "    split = splitter.split(df, groups=df['verb_lemma'])\n",
    "    train_inds, test_val_inds = next(split)\n",
    "\n",
    "    train = df.iloc[train_inds]\n",
    "    test_val = df.iloc[test_val_inds]\n",
    "\n",
    "    test, val = train_test_split(test_val, test_size=0.5, stratify=test_val[\"rel_type\"],random_state=RANDOM_STATE)\n",
    "\n",
    "    #splitter = GroupShuffleSplit(test_size=.5, n_splits=1, random_state=RANDOM_STATE)\n",
    "    #split = splitter.split(test_val, groups=test_val['verb_lemma'])\n",
    "    #test_inds, val_inds = next(split)\n",
    "\n",
    "    #test = test_val.iloc[test_inds]\n",
    "    #val = test_val.iloc[val_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8261758f",
   "metadata": {},
   "source": [
    "### Save to file\n",
    "\n",
    "Save the respective datasets to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ca72f76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE COUNTS: train\n",
      "neutral    8244\n",
      "con        7301\n",
      "pro        6248\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: test\n",
      "pro        2752\n",
      "con        2226\n",
      "neutral    1755\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: val\n",
      "pro        2753\n",
      "con        2226\n",
      "neutral    1754\n",
      "Name: rel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"VALUE COUNTS: train\")\n",
    "print(train.rel_type.value_counts())\n",
    "train.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: test\")\n",
    "print(test.rel_type.value_counts())\n",
    "test.to_csv(TEST_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: val\")\n",
    "print(val.rel_type.value_counts())\n",
    "val.to_csv(VAL_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aaa9f4",
   "metadata": {},
   "source": [
    "We verify that this worked using an overlap metric by checking whether the overlap is 0 with respect to all verbs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41d4af7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overlap /w regards to verbform\n",
    "train_verbs = train.verb_form.to_list()\n",
    "val_test_verbs = val.verb_form.to_list() + test.verb_form.to_list()\n",
    "list(set(train_verbs) & set(val_test_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8a1715d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overlap /w regards to lemma\n",
    "train_verbs = train.verb_lemma.to_list()\n",
    "val_test_verbs = val.verb_lemma.to_list() + test.verb_lemma.to_list()\n",
    "list(set(train_verbs) & set(val_test_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03a72617",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         verb_lemma  counts\n",
      "15       ankündigen    1535\n",
      "27        aufnehmen    1171\n",
      "147          gelten    1046\n",
      "235          sorgen     791\n",
      "138          finden     758\n",
      "..              ...     ...\n",
      "139       fingieren       1\n",
      "145        fremdeln       1\n",
      "304  vorverurteilen       1\n",
      "148       geniessen       1\n",
      "0         abdriften       1\n",
      "\n",
      "[338 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "analyse_verb_frequency(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fc79a46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       verb_lemma  counts\n",
      "85        stellen    1693\n",
      "56         freuen     728\n",
      "58       gewinnen     348\n",
      "125  zurückweisen     262\n",
      "51      erreichen     229\n",
      "..            ...     ...\n",
      "114     vorrücken       1\n",
      "121    zerreissen       1\n",
      "120    zerbrechen       1\n",
      "115    vorspielen       1\n",
      "35   beschliessen       1\n",
      "\n",
      "[134 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "analyse_verb_frequency(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad85388",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       verb_lemma  counts\n",
      "89        stellen    1692\n",
      "59         freuen     703\n",
      "61       gewinnen     338\n",
      "125  zurückweisen     257\n",
      "54      erreichen     216\n",
      "..            ...     ...\n",
      "48     entfremden       1\n",
      "51       ermatten       1\n",
      "83       schocken       1\n",
      "17      auflehnen       1\n",
      "11       anmahnen       1\n",
      "\n",
      "[134 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "analyse_verb_frequency(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0f742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
