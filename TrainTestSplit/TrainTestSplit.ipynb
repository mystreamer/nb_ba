{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc9d3a4",
   "metadata": {},
   "source": [
    "## TrainTestSplit\n",
    "\n",
    "Create a train-test-split for the datasets found in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9faae40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e5791107",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '../../etl/data/intermediate/TrainTestSplit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [272], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# makedirs if not exist\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../etl/data/intermediate/TrainTestSplit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '../../etl/data/intermediate/TrainTestSplit'"
     ]
    }
   ],
   "source": [
    "# makedirs if not exist\n",
    "os.makedirs(\"../../etl/data/intermediate/TrainTestSplit\", exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "d7dfea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "FULL_DATA_PATH=\"../../etl/data/raw/01_extract.csv\"\n",
    "TRAIN_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_train.csv\"\n",
    "TEST_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_test.csv\"\n",
    "VAL_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_val.csv\"\n",
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "3ad440aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FULL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "dabe118d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>abgestraft</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>abstrafen</td>\n",
       "      <td>Alexis Tsipras</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Alexis</td>\n",
       "      <td>...</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>140</td>\n",
       "      <td>151</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>die neue Regierung</td>\n",
       "      <td>75</td>\n",
       "      <td>93</td>\n",
       "      <td>N</td>\n",
       "      <td>Regierung</td>\n",
       "      <td>...</td>\n",
       "      <td>die Hoffnungen auf einen spürbaren Aufschwung</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>N</td>\n",
       "      <td>Hoffnungen</td>\n",
       "      <td>98</td>\n",
       "      <td>108</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)</td>\n",
       "      <td>Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>beenden</td>\n",
       "      <td>119</td>\n",
       "      <td>126</td>\n",
       "      <td>beenden</td>\n",
       "      <td>Will er dem Land etwas Gutes tun</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>die politische Polarisierung beenden</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>Polarisierung</td>\n",
       "      <td>105</td>\n",
       "      <td>118</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)</td>\n",
       "      <td>Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>Pajtim Kasami</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>Pajtim</td>\n",
       "      <td>...</td>\n",
       "      <td>die Kurzarbeit nun doch</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>N</td>\n",
       "      <td>Kurzarbeit</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>pro</td>\n",
       "      <td>Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)</td>\n",
       "      <td>Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>entliess</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>entlassen</td>\n",
       "      <td>der FC Sion</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>FC</td>\n",
       "      <td>...</td>\n",
       "      <td>Fussball Neun Spieler</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>Fussball</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)</td>\n",
       "      <td>( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832168</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>äussert</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>äussern</td>\n",
       "      <td>Frau A</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Frau</td>\n",
       "      <td>...</td>\n",
       "      <td>massive Vorwürfe gegen ihre Vorgesetzten</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Vorwürfe</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)</td>\n",
       "      <td>Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832169</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>stelle</td>\n",
       "      <td>184</td>\n",
       "      <td>190</td>\n",
       "      <td>stellen</td>\n",
       "      <td>das Kommando</td>\n",
       "      <td>171</td>\n",
       "      <td>183</td>\n",
       "      <td>N</td>\n",
       "      <td>Kommando</td>\n",
       "      <td>...</td>\n",
       "      <td>einen Antrag auf ihren Ausschluss</td>\n",
       "      <td>191</td>\n",
       "      <td>224</td>\n",
       "      <td>N</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>197</td>\n",
       "      <td>203</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)</td>\n",
       "      <td>Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832170</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>ausgewiesen</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>ausweisen</td>\n",
       "      <td>Der Konzern</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>Konzern</td>\n",
       "      <td>...</td>\n",
       "      <td>eine Liquidität</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>N</td>\n",
       "      <td>Liquidität</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)</td>\n",
       "      <td>Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832171</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>belebt</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>beleben</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>...</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)</td>\n",
       "      <td>Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832172</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>halten</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>halten</td>\n",
       "      <td>Die Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>N</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>...</td>\n",
       "      <td>möglichst gering</td>\n",
       "      <td>108</td>\n",
       "      <td>124</td>\n",
       "      <td>ADV</td>\n",
       "      <td>gering</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)</td>\n",
       "      <td>Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832173 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  doc_id  \\\n",
       "0       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "1       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "2       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "3       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "4       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "...                                                                  ...   \n",
       "832168  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832169  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832170  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832171  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832172  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "\n",
       "          verb_form  verb_form_start  verb_form_end   verb_lemma  \\\n",
       "0        abgestraft               26             36    abstrafen   \n",
       "1       enttäuschen              140            151  enttäuschen   \n",
       "2           beenden              119            126      beenden   \n",
       "3       akzeptieren               69             80  akzeptieren   \n",
       "4          entliess               30             38    entlassen   \n",
       "...             ...              ...            ...          ...   \n",
       "832168      äussert                5             12      äussern   \n",
       "832169       stelle              184            190      stellen   \n",
       "832170  ausgewiesen               77             88    ausweisen   \n",
       "832171       belebt                8             14      beleben   \n",
       "832172       halten              128            134       halten   \n",
       "\n",
       "                                     arg1  arg1_start  arg1_end arg1_pos  \\\n",
       "0                          Alexis Tsipras           5        19        N   \n",
       "1                      die neue Regierung          75        93        N   \n",
       "2       Will er dem Land etwas Gutes tun            0        33       $.   \n",
       "3                          Pajtim Kasami            0        14        N   \n",
       "4                             der FC Sion          39        50        N   \n",
       "...                                   ...         ...       ...      ...   \n",
       "832168                             Frau A          13        19        N   \n",
       "832169                       das Kommando         171       183        N   \n",
       "832170                        Der Konzern           0        11        N   \n",
       "832171              das Verkehrsaufkommen          20        41        N   \n",
       "832172                      Die Lufthansa           0        13        N   \n",
       "\n",
       "                arg1_head  ...                                           arg2  \\\n",
       "0                  Alexis  ...    Dass Alexis Tsipras jetzt abgestraft wurde    \n",
       "1               Regierung  ...  die Hoffnungen auf einen spürbaren Aufschwung   \n",
       "2                       .  ...          die politische Polarisierung beenden    \n",
       "3                  Pajtim  ...                       die Kurzarbeit nun doch    \n",
       "4                      FC  ...                          Fussball Neun Spieler   \n",
       "...                   ...  ...                                            ...   \n",
       "832168               Frau  ...       massive Vorwürfe gegen ihre Vorgesetzten   \n",
       "832169           Kommando  ...              einen Antrag auf ihren Ausschluss   \n",
       "832170            Konzern  ...                                eine Liquidität   \n",
       "832171  Verkehrsaufkommen  ...                          das Verkehrsaufkommen   \n",
       "832172          Lufthansa  ...                               möglichst gering   \n",
       "\n",
       "        arg2_start arg2_end  arg2_pos          arg2_head arg2_head_start  \\\n",
       "0                0       43        $.                  .             143   \n",
       "1               94      139         N         Hoffnungen              98   \n",
       "2               90      127         N      Polarisierung             105   \n",
       "3               81      105         N         Kurzarbeit              85   \n",
       "4                8       29         N           Fussball               8   \n",
       "...            ...      ...       ...                ...             ...   \n",
       "832168          20       60         N           Vorwürfe              28   \n",
       "832169         191      224         N             Antrag             197   \n",
       "832170          32       47         N         Liquidität              37   \n",
       "832171          20       41         N  Verkehrsaufkommen              24   \n",
       "832172         108      124       ADV             gering             118   \n",
       "\n",
       "       arg2_head_end  rel_type  \\\n",
       "0                144   neutral   \n",
       "1                108   neutral   \n",
       "2                118   neutral   \n",
       "3                 95       pro   \n",
       "4                 16   neutral   \n",
       "...              ...       ...   \n",
       "832168            36   neutral   \n",
       "832169           203   neutral   \n",
       "832170            47       con   \n",
       "832171            41       con   \n",
       "832172           124   neutral   \n",
       "\n",
       "                                                                                                            pred_serial  \\\n",
       "0           Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)   \n",
       "1       Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)   \n",
       "2       Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)   \n",
       "3            Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)   \n",
       "4          Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)   \n",
       "...                                                                                                                 ...   \n",
       "832168     Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)   \n",
       "832169  Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)   \n",
       "832170        Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)   \n",
       "832171         Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)   \n",
       "832172   Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)   \n",
       "\n",
       "                                                                                                                                                                                                                        full_sentence_text  \n",
       "0                                                                                         Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .  \n",
       "1                                                                                Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .  \n",
       "2                                                Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .  \n",
       "3                                                    Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .  \n",
       "4                                                                                                                       ( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .  \n",
       "...                                                                                                                                                                                                                                    ...  \n",
       "832168                                                                                                                                                                      Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .  \n",
       "832169  Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .  \n",
       "832170                                                                                                                                          Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .  \n",
       "832171                                                                                                                                                       Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .  \n",
       "832172                                                                                            Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .  \n",
       "\n",
       "[832173 rows x 22 columns]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by sentences\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c56fca",
   "metadata": {},
   "source": [
    "**Clean dataset**\n",
    "\n",
    "1. As seen below we must remove the argument heads make sure we don't have any \".\" as arguments for the neutrals.\n",
    "2. We also want to remove the reflexive cases for the pronouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "6a250d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - include dotted (most likely with no target or other thing, or are these the -1 ones)\n",
    "mask = ~((df[\"arg1_head\"] == \".\")\n",
    "|(df[\"arg2_head\"] == \".\")\n",
    "|(df[\"arg2\"] == \".\")\n",
    "|(df[\"arg2\"] == \".\"))\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "\n",
    "# 2 - include reflexive\n",
    "mask = ~(df[\"arg1\"] == df[\"arg2\"])\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "# 3 - only include verbs with balancedness below a certain threshold.\n",
    "mask = (df[\"verb_lemma\"].isin(agreeable_verbs))\n",
    "\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "f2c8ce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral    202865\n",
       "con         12713\n",
       "pro         11463\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(agreeable_verbs))\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7672a962",
   "metadata": {},
   "source": [
    "**Balance the dataset**\n",
    "\n",
    "Make sure that each class is represented equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "4dbceead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        11463\n",
       "neutral    11463\n",
       "pro        11463\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('rel_type')\n",
    "df = df.apply(lambda x: x.sample(df.size().min()).reset_index(drop=True))\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "8d2accec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        11463\n",
       "neutral    11463\n",
       "pro        11463\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(level=0, drop=True)\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d095d1e",
   "metadata": {},
   "source": [
    "**How big is the problem with multi-PAS per sentence?**\n",
    "\n",
    "Which should not be split accross the dataset splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "7c8f15df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "counts\n",
       "1    34242\n",
       "2      138\n",
       "3        9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_occ = df.copy(deep=True)\n",
    "df_occ = df_occ.merge(df_occ.groupby([\"doc_id\", \"full_sentence_text\"]).size().reset_index(name=\"counts\"), on=[\"doc_id\", \"full_sentence_text\"])\n",
    "df_occ_freq = df_occ.groupby([\"counts\"]).size()\n",
    "df_occ_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21215c1b",
   "metadata": {},
   "source": [
    "### Complex sentences analysis\n",
    "\n",
    "**How do the multi-PAS sentences look**?\n",
    "\n",
    "Complexity and sentence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "839f308c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3691</th>\n",
       "      <td>dd4016abc6b69e30be0631658c2b7768fe9fd4eba0fa19d3c5093813d6420955</td>\n",
       "      <td>distanzieren</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>distanzieren</td>\n",
       "      <td>die allermeisten Muslime</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Muslime</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "      <td>Islam</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=36, token=7), Head(sentence=36, token=2)), strength=0, verb=3)</td>\n",
       "      <td>Von diesem Islam distanzieren sich die allermeisten Muslime , wie sich auch die Christen von der einstigen gewaltsamen Christianisierung Südamerikas und Afrikas distanzieren .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>dd4016abc6b69e30be0631658c2b7768fe9fd4eba0fa19d3c5093813d6420955</td>\n",
       "      <td>distanzieren</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>distanzieren</td>\n",
       "      <td>die Christen</td>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>Christen</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>160</td>\n",
       "      <td>N</td>\n",
       "      <td>Christianisierung</td>\n",
       "      <td>119</td>\n",
       "      <td>136</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=36, token=13), Head(sentence=36, token=18)), strength=0, verb=22)</td>\n",
       "      <td>Von diesem Islam distanzieren sich die allermeisten Muslime , wie sich auch die Christen von der einstigen gewaltsamen Christianisierung Südamerikas und Afrikas distanzieren .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                doc_id  \\\n",
       "3691  dd4016abc6b69e30be0631658c2b7768fe9fd4eba0fa19d3c5093813d6420955   \n",
       "3692  dd4016abc6b69e30be0631658c2b7768fe9fd4eba0fa19d3c5093813d6420955   \n",
       "\n",
       "         verb_form  verb_form_start  verb_form_end    verb_lemma  \\\n",
       "3691  distanzieren               17             29  distanzieren   \n",
       "3692  distanzieren               17             29  distanzieren   \n",
       "\n",
       "                           arg1  arg1_start  arg1_end arg1_pos arg1_head  ...  \\\n",
       "3691  die allermeisten Muslime           35        60        N   Muslime  ...   \n",
       "3692               die Christen          76        88        N  Christen  ...   \n",
       "\n",
       "      arg2_start  arg2_end arg2_pos          arg2_head  arg2_head_start  \\\n",
       "3691           4        16        N              Islam               11   \n",
       "3692          93       160        N  Christianisierung              119   \n",
       "\n",
       "     arg2_head_end rel_type  \\\n",
       "3691            16      con   \n",
       "3692           136      con   \n",
       "\n",
       "                                                                                                      pred_serial  \\\n",
       "3691     Predicate(type='con', args=(Head(sentence=36, token=7), Head(sentence=36, token=2)), strength=0, verb=3)   \n",
       "3692  Predicate(type='con', args=(Head(sentence=36, token=13), Head(sentence=36, token=18)), strength=0, verb=22)   \n",
       "\n",
       "                                                                                                                                                                   full_sentence_text  \\\n",
       "3691  Von diesem Islam distanzieren sich die allermeisten Muslime , wie sich auch die Christen von der einstigen gewaltsamen Christianisierung Südamerikas und Afrikas distanzieren .   \n",
       "3692  Von diesem Islam distanzieren sich die allermeisten Muslime , wie sich auch die Christen von der einstigen gewaltsamen Christianisierung Südamerikas und Afrikas distanzieren .   \n",
       "\n",
       "     counts  \n",
       "3691      2  \n",
       "3692      2  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "s1 = df_occ[df_occ[\"counts\"] >= 2] \\\n",
    "    .sort_values([\"full_sentence_text\"]) \\\n",
    "    .sample(n=1)\n",
    "s1_val = s1[\"full_sentence_text\"].to_list()[0]\n",
    "df_occ[df_occ[\"full_sentence_text\"] == s1_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b45150",
   "metadata": {},
   "source": [
    "**Seeking for specific multi-PAS sentences:**\n",
    "\n",
    "Ones where:\n",
    "$MP^{arg_1}_1=MP^{arg_1}_2$ or  $MP^{arg_2}_1=MP^{arg_2}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "d1268ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all docIDs and sents where this hold and then filter by them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc8c5f",
   "metadata": {},
   "source": [
    "**Verb mixing**\n",
    "\n",
    "How large is the likelihood that a verb-mediated relation is positive, then negative.\n",
    "\n",
    "Potentially: try to remove this ambiguity.\n",
    "\n",
    "***Agreement metric:*** What are particularly ambiguous verbs, and can \"entity\" type restrictions be learned around them? What are not very ambigious words?\n",
    "\n",
    "=> Using a measure of [balance](https://stats.stackexchange.com/questions/239973/a-general-measure-of-data-set-imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "fde79d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(seq):\n",
    "    \"\"\"\n",
    "        Provides a measure of balancedness.\n",
    "        input: sequence of class counts\n",
    "        0 means unbalanced, which is better! more agreement!\n",
    "        1 means balanced\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    from numpy import log\n",
    "    \n",
    "    # define this as a high agreement\n",
    "    if len(seq) == 1:\n",
    "        # we'll define a single class as highly unbalanced\n",
    "        return 0.0\n",
    "    \n",
    "    # n = len(seq)\n",
    "    n = sum(seq)\n",
    "    # classes = [(clas,float(count)) for clas,count in Counter(seq).items()]\n",
    "    k = len(seq)\n",
    "    \n",
    "    H = -sum([ (count/n) * log((count/n)) for clas,count in enumerate(seq)]) #shannon entropy\n",
    "    return H/(log(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "27707ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance([500, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "26b41c99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abdriften</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>ramponieren</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>qualifizieren</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>punkten</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>prämieren</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>anlügen</td>\n",
       "      <td>0.811278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>harmonisieren</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>aufkündigen</td>\n",
       "      <td>0.918296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>anraunzen</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>berechtigen</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        verb_lemma   balance\n",
       "0        abdriften  0.000000\n",
       "262    ramponieren  0.000000\n",
       "261  qualifizieren  0.000000\n",
       "260        punkten  0.000000\n",
       "259      prämieren  0.000000\n",
       "..             ...       ...\n",
       "25         anlügen  0.811278\n",
       "194  harmonisieren  0.918296\n",
       "41     aufkündigen  0.918296\n",
       "28       anraunzen  1.000000\n",
       "91     berechtigen  1.000000\n",
       "\n",
       "[416 rows x 2 columns]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixing = df.copy(deep=True)\n",
    "df_mixing\n",
    "df_mixing = df_mixing.groupby([\"verb_lemma\", \"rel_type\"]).size().reset_index(name=\"counts\")\n",
    "df_mixing = df_mixing.groupby([\"verb_lemma\"]).apply(lambda x: balance(x[\"counts\"].to_list())).reset_index(name=\"balance\").dropna()\n",
    "df_mixing.sort_values(\"balance\")\n",
    "# df_mixing[df_mixing[\"verb_lemma\"] == \"verübeln\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "b156d1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of the balancedness?\n",
    "df_mixing.balance.value_counts()\n",
    "# get all verbs with balance 0.0\n",
    "agreeable_verbs = df_mixing[df_mixing[\"balance\"] <= .3][\"verb_lemma\"].to_list()\n",
    "len(agreeable_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "79032869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>nachgeben</td>\n",
       "      <td>neutral</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     verb_lemma rel_type  counts\n",
       "1322  nachgeben  neutral      81"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of verbs and their agreement\n",
    "df_analysis = df.copy(deep=True)\n",
    "df_analysis = df_analysis.groupby([\"verb_lemma\", \"rel_type\"]).size().reset_index(name=\"counts\")\n",
    "df_analysis[df_analysis[\"verb_lemma\"] == \"nachgeben\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb19de8",
   "metadata": {},
   "source": [
    "**How big is the problem of -1 in first span or a \".\" in the data?**\n",
    "\n",
    "The -1 does not exist. No problem currently.\n",
    "\n",
    "The \".\" is quite prevalent and strangely only occurrs in the neutral case. That's why a cleaning step was inroduced above (see solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "bc9439ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: rel_type, dtype: int64)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty = df.copy(deep=True)\n",
    "df_dirty[\n",
    "#(df_dirty[\"arg1_head\"] == \".\")\n",
    "#|(df_dirty[\"arg2_head\"] == \".\")\n",
    "#|(df_dirty[\"arg2\"] == \".\")\n",
    "#|(df_dirty[\"arg2\"] == \".\")\n",
    "#(df_dirty[\"arg1_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_head_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_head_start\"] == -1)\n",
    "(df_dirty[\"arg1\"] == df_dirty[\"arg2\"])\n",
    "& (df_dirty[\"full_sentence_text\"].str.contains(\"sich\")) # reflexive verbs, should be ignore?\n",
    "].rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c97520",
   "metadata": {},
   "source": [
    "## Hard-verb splitting\n",
    "\n",
    "To test generalisability we may want to split verbs by train and test set.\n",
    "\n",
    "TO-DO Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae97f4",
   "metadata": {},
   "source": [
    "**Option 1: Train-test-splitting**\n",
    "\n",
    "Only problem: We may have sentences within the same documents with multiple PAS that are split accross the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "1e8c6e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE COUNTS: train\n",
      "pro        8024\n",
      "neutral    8024\n",
      "con        8024\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: test\n",
      "con        1720\n",
      "neutral    1719\n",
      "pro        1719\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: val\n",
      "neutral    1720\n",
      "pro        1720\n",
      "con        1719\n",
      "Name: rel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train, test_val = train_test_split(df, test_size=0.3, stratify=df[\"rel_type\"], random_state=RANDOM_STATE)\n",
    "test, val = train_test_split(test_val, test_size=0.5, stratify=test_val[\"rel_type\"],random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"VALUE COUNTS: train\")\n",
    "print(train.rel_type.value_counts())\n",
    "train.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: test\")\n",
    "print(test.rel_type.value_counts())\n",
    "test.to_csv(TEST_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: val\")\n",
    "print(val.rel_type.value_counts())\n",
    "val.to_csv(VAL_DATA_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4880d13e",
   "metadata": {},
   "source": [
    "**Option 2: Train-test-splitting**\n",
    "\n",
    "With respecting group distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "21a71291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve groups between sentences (in this case doc_id is safe enough)\n",
    "splitter = GroupShuffleSplit(test_size=.30, n_splits=1, random_state=RANDOM_STATE)\n",
    "split = splitter.split(df, groups=df['doc_id'])\n",
    "train_inds, test_val_inds = next(split)\n",
    "\n",
    "train = df.iloc[train_inds]\n",
    "test_val = df.iloc[test_val_inds]\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=.5, n_splits=1, random_state=RANDOM_STATE)\n",
    "split = splitter.split(test_val, groups=test_val['doc_id'])\n",
    "test_inds, val_inds = next(split)\n",
    "\n",
    "test = test_val.iloc[test_inds]\n",
    "val = test_val.iloc[val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "b88d2f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE COUNTS: train\n",
      "con        8112\n",
      "pro        8051\n",
      "neutral    7901\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: test\n",
      "neutral    1770\n",
      "pro        1718\n",
      "con        1691\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: val\n",
      "neutral    1792\n",
      "pro        1694\n",
      "con        1660\n",
      "Name: rel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"VALUE COUNTS: train\")\n",
    "print(train.rel_type.value_counts())\n",
    "train.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: test\")\n",
    "print(test.rel_type.value_counts())\n",
    "test.to_csv(TEST_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: val\")\n",
    "print(val.rel_type.value_counts())\n",
    "val.to_csv(VAL_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d0f4f49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "TRAIN: [1, 1, 3, 3, 3, 8, 8] TEST: [2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# a small test to see whether option no 2 achieves our goals.\n",
    "\n",
    "X = np.ones(shape=(10, 2))\n",
    "y = np.ones(shape=(10, 1))\n",
    "groups = np.array([1, 1, 2, 2, 2, 3, 3, 3, 8, 8])\n",
    "print(groups.shape)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=42)\n",
    "gss.get_n_splits()\n",
    "\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", [groups[i] for i in train_idx], \"TEST:\", [groups[i] for i in test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf0cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
