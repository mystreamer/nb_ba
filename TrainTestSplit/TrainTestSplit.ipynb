{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a9ff45",
   "metadata": {},
   "source": [
    "## TrainTestSplit\n",
    "\n",
    "Create a train-test-split for the datasets found in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d3881a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c716a468",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '../../etl/data/intermediate/TrainTestSplit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [122], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# makedirs if not exist\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../etl/data/intermediate/TrainTestSplit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib64/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '../../etl/data/intermediate/TrainTestSplit'"
     ]
    }
   ],
   "source": [
    "# makedirs if not exist\n",
    "os.makedirs(\"../../etl/data/intermediate/TrainTestSplit\", exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "acfabafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "FULL_DATA_PATH=\"../../etl/data/raw/01_extract.csv\"\n",
    "TRAIN_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_train.csv\"\n",
    "TEST_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_test.csv\"\n",
    "VAL_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_val.csv\"\n",
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0044892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FULL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bce5075c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>abgestraft</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>abstrafen</td>\n",
       "      <td>Alexis Tsipras</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Alexis</td>\n",
       "      <td>...</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>140</td>\n",
       "      <td>151</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>die neue Regierung</td>\n",
       "      <td>75</td>\n",
       "      <td>93</td>\n",
       "      <td>N</td>\n",
       "      <td>Regierung</td>\n",
       "      <td>...</td>\n",
       "      <td>die Hoffnungen auf einen spürbaren Aufschwung</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>N</td>\n",
       "      <td>Hoffnungen</td>\n",
       "      <td>98</td>\n",
       "      <td>108</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)</td>\n",
       "      <td>Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>beenden</td>\n",
       "      <td>119</td>\n",
       "      <td>126</td>\n",
       "      <td>beenden</td>\n",
       "      <td>Will er dem Land etwas Gutes tun</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>die politische Polarisierung beenden</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>Polarisierung</td>\n",
       "      <td>105</td>\n",
       "      <td>118</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)</td>\n",
       "      <td>Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>Pajtim Kasami</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>Pajtim</td>\n",
       "      <td>...</td>\n",
       "      <td>die Kurzarbeit nun doch</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>N</td>\n",
       "      <td>Kurzarbeit</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>pro</td>\n",
       "      <td>Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)</td>\n",
       "      <td>Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>entliess</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>entlassen</td>\n",
       "      <td>der FC Sion</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>FC</td>\n",
       "      <td>...</td>\n",
       "      <td>Fussball Neun Spieler</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>Fussball</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)</td>\n",
       "      <td>( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832168</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>äussert</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>äussern</td>\n",
       "      <td>Frau A</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Frau</td>\n",
       "      <td>...</td>\n",
       "      <td>massive Vorwürfe gegen ihre Vorgesetzten</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Vorwürfe</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)</td>\n",
       "      <td>Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832169</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>stelle</td>\n",
       "      <td>184</td>\n",
       "      <td>190</td>\n",
       "      <td>stellen</td>\n",
       "      <td>das Kommando</td>\n",
       "      <td>171</td>\n",
       "      <td>183</td>\n",
       "      <td>N</td>\n",
       "      <td>Kommando</td>\n",
       "      <td>...</td>\n",
       "      <td>einen Antrag auf ihren Ausschluss</td>\n",
       "      <td>191</td>\n",
       "      <td>224</td>\n",
       "      <td>N</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>197</td>\n",
       "      <td>203</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)</td>\n",
       "      <td>Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832170</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>ausgewiesen</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>ausweisen</td>\n",
       "      <td>Der Konzern</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>Konzern</td>\n",
       "      <td>...</td>\n",
       "      <td>eine Liquidität</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>N</td>\n",
       "      <td>Liquidität</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)</td>\n",
       "      <td>Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832171</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>belebt</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>beleben</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>...</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)</td>\n",
       "      <td>Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832172</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>halten</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>halten</td>\n",
       "      <td>Die Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>N</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>...</td>\n",
       "      <td>möglichst gering</td>\n",
       "      <td>108</td>\n",
       "      <td>124</td>\n",
       "      <td>ADV</td>\n",
       "      <td>gering</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)</td>\n",
       "      <td>Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832173 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  doc_id  \\\n",
       "0       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "1       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "2       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "3       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "4       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "...                                                                  ...   \n",
       "832168  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832169  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832170  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832171  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832172  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "\n",
       "          verb_form  verb_form_start  verb_form_end   verb_lemma  \\\n",
       "0        abgestraft               26             36    abstrafen   \n",
       "1       enttäuschen              140            151  enttäuschen   \n",
       "2           beenden              119            126      beenden   \n",
       "3       akzeptieren               69             80  akzeptieren   \n",
       "4          entliess               30             38    entlassen   \n",
       "...             ...              ...            ...          ...   \n",
       "832168      äussert                5             12      äussern   \n",
       "832169       stelle              184            190      stellen   \n",
       "832170  ausgewiesen               77             88    ausweisen   \n",
       "832171       belebt                8             14      beleben   \n",
       "832172       halten              128            134       halten   \n",
       "\n",
       "                                     arg1  arg1_start  arg1_end arg1_pos  \\\n",
       "0                          Alexis Tsipras           5        19        N   \n",
       "1                      die neue Regierung          75        93        N   \n",
       "2       Will er dem Land etwas Gutes tun            0        33       $.   \n",
       "3                          Pajtim Kasami            0        14        N   \n",
       "4                             der FC Sion          39        50        N   \n",
       "...                                   ...         ...       ...      ...   \n",
       "832168                             Frau A          13        19        N   \n",
       "832169                       das Kommando         171       183        N   \n",
       "832170                        Der Konzern           0        11        N   \n",
       "832171              das Verkehrsaufkommen          20        41        N   \n",
       "832172                      Die Lufthansa           0        13        N   \n",
       "\n",
       "                arg1_head  ...                                           arg2  \\\n",
       "0                  Alexis  ...    Dass Alexis Tsipras jetzt abgestraft wurde    \n",
       "1               Regierung  ...  die Hoffnungen auf einen spürbaren Aufschwung   \n",
       "2                       .  ...          die politische Polarisierung beenden    \n",
       "3                  Pajtim  ...                       die Kurzarbeit nun doch    \n",
       "4                      FC  ...                          Fussball Neun Spieler   \n",
       "...                   ...  ...                                            ...   \n",
       "832168               Frau  ...       massive Vorwürfe gegen ihre Vorgesetzten   \n",
       "832169           Kommando  ...              einen Antrag auf ihren Ausschluss   \n",
       "832170            Konzern  ...                                eine Liquidität   \n",
       "832171  Verkehrsaufkommen  ...                          das Verkehrsaufkommen   \n",
       "832172          Lufthansa  ...                               möglichst gering   \n",
       "\n",
       "        arg2_start arg2_end  arg2_pos          arg2_head arg2_head_start  \\\n",
       "0                0       43        $.                  .             143   \n",
       "1               94      139         N         Hoffnungen              98   \n",
       "2               90      127         N      Polarisierung             105   \n",
       "3               81      105         N         Kurzarbeit              85   \n",
       "4                8       29         N           Fussball               8   \n",
       "...            ...      ...       ...                ...             ...   \n",
       "832168          20       60         N           Vorwürfe              28   \n",
       "832169         191      224         N             Antrag             197   \n",
       "832170          32       47         N         Liquidität              37   \n",
       "832171          20       41         N  Verkehrsaufkommen              24   \n",
       "832172         108      124       ADV             gering             118   \n",
       "\n",
       "       arg2_head_end  rel_type  \\\n",
       "0                144   neutral   \n",
       "1                108   neutral   \n",
       "2                118   neutral   \n",
       "3                 95       pro   \n",
       "4                 16   neutral   \n",
       "...              ...       ...   \n",
       "832168            36   neutral   \n",
       "832169           203   neutral   \n",
       "832170            47       con   \n",
       "832171            41       con   \n",
       "832172           124   neutral   \n",
       "\n",
       "                                                                                                            pred_serial  \\\n",
       "0           Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)   \n",
       "1       Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)   \n",
       "2       Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)   \n",
       "3            Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)   \n",
       "4          Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)   \n",
       "...                                                                                                                 ...   \n",
       "832168     Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)   \n",
       "832169  Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)   \n",
       "832170        Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)   \n",
       "832171         Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)   \n",
       "832172   Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)   \n",
       "\n",
       "                                                                                                                                                                                                                        full_sentence_text  \n",
       "0                                                                                         Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .  \n",
       "1                                                                                Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .  \n",
       "2                                                Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .  \n",
       "3                                                    Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .  \n",
       "4                                                                                                                       ( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .  \n",
       "...                                                                                                                                                                                                                                    ...  \n",
       "832168                                                                                                                                                                      Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .  \n",
       "832169  Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .  \n",
       "832170                                                                                                                                          Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .  \n",
       "832171                                                                                                                                                       Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .  \n",
       "832172                                                                                            Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .  \n",
       "\n",
       "[832173 rows x 22 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by sentences\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3cc819",
   "metadata": {},
   "source": [
    "**How big is the problem with multi-PAS per sentence?**\n",
    "\n",
    "Which should not be split accross the dataset splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4bbee94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "counts\n",
       "1    757658\n",
       "2     69320\n",
       "3      4809\n",
       "4       336\n",
       "5        35\n",
       "7         7\n",
       "8         8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_occ = df.copy(deep=True)\n",
    "df_occ = df_occ.merge(df_occ.groupby([\"doc_id\", \"full_sentence_text\"]).size().reset_index(name=\"counts\"), on=[\"doc_id\", \"full_sentence_text\"])\n",
    "df_occ_freq = df_occ.groupby([\"counts\"]).size()\n",
    "df_occ_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b199a7",
   "metadata": {},
   "source": [
    "### Complex sentences analysis\n",
    "\n",
    "**How do the multi-PAS sentences look**?\n",
    "\n",
    "Complexity and sentence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6023a821",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>667104</th>\n",
       "      <td>7021bf5b55d36232cddb8cdcbd336a137f28e58717fce85195ada8cd2a6c0dde</td>\n",
       "      <td>gebeten</td>\n",
       "      <td>110</td>\n",
       "      <td>117</td>\n",
       "      <td>bitten</td>\n",
       "      <td>Riad</td>\n",
       "      <td>94</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>Riad</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>PROAV</td>\n",
       "      <td>darum</td>\n",
       "      <td>104</td>\n",
       "      <td>109</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=67, token=16), Head(sentence=67, token=18)), strength=0, verb=19)</td>\n",
       "      <td>Auch Frankreich kündigte die Entsendung von Experten an , um bei den Ermittlungen zu helfen , Riad habe darum gebeten .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667105</th>\n",
       "      <td>7021bf5b55d36232cddb8cdcbd336a137f28e58717fce85195ada8cd2a6c0dde</td>\n",
       "      <td>helfen</td>\n",
       "      <td>85</td>\n",
       "      <td>91</td>\n",
       "      <td>helfen</td>\n",
       "      <td>Auch Frankreich</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "      <td>Frankreich</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>N</td>\n",
       "      <td>Ermittlungen</td>\n",
       "      <td>69</td>\n",
       "      <td>81</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=67, token=1), Head(sentence=67, token=12)), strength=0, verb=14)</td>\n",
       "      <td>Auch Frankreich kündigte die Entsendung von Experten an , um bei den Ermittlungen zu helfen , Riad habe darum gebeten .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667106</th>\n",
       "      <td>7021bf5b55d36232cddb8cdcbd336a137f28e58717fce85195ada8cd2a6c0dde</td>\n",
       "      <td>kündigte</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>kündigen</td>\n",
       "      <td>Auch Frankreich</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>N</td>\n",
       "      <td>Frankreich</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>N</td>\n",
       "      <td>Entsendung</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=67, token=1), Head(sentence=67, token=4)), strength=0, verb=2)</td>\n",
       "      <td>Auch Frankreich kündigte die Entsendung von Experten an , um bei den Ermittlungen zu helfen , Riad habe darum gebeten .</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  doc_id  \\\n",
       "667104  7021bf5b55d36232cddb8cdcbd336a137f28e58717fce85195ada8cd2a6c0dde   \n",
       "667105  7021bf5b55d36232cddb8cdcbd336a137f28e58717fce85195ada8cd2a6c0dde   \n",
       "667106  7021bf5b55d36232cddb8cdcbd336a137f28e58717fce85195ada8cd2a6c0dde   \n",
       "\n",
       "       verb_form  verb_form_start  verb_form_end verb_lemma             arg1  \\\n",
       "667104   gebeten              110            117     bitten             Riad   \n",
       "667105    helfen               85             91     helfen  Auch Frankreich   \n",
       "667106  kündigte               16             24   kündigen  Auch Frankreich   \n",
       "\n",
       "        arg1_start  arg1_end arg1_pos   arg1_head  ...  arg2_start  arg2_end  \\\n",
       "667104          94        98        N        Riad  ...         104       109   \n",
       "667105           0        15        N  Frankreich  ...          65        81   \n",
       "667106           0        15        N  Frankreich  ...          25        52   \n",
       "\n",
       "       arg2_pos     arg2_head  arg2_head_start arg2_head_end rel_type  \\\n",
       "667104    PROAV         darum              104           109  neutral   \n",
       "667105        N  Ermittlungen               69            81  neutral   \n",
       "667106        N    Entsendung               29            39  neutral   \n",
       "\n",
       "                                                                                                            pred_serial  \\\n",
       "667104  Predicate(type='neutral', args=(Head(sentence=67, token=16), Head(sentence=67, token=18)), strength=0, verb=19)   \n",
       "667105   Predicate(type='neutral', args=(Head(sentence=67, token=1), Head(sentence=67, token=12)), strength=0, verb=14)   \n",
       "667106     Predicate(type='neutral', args=(Head(sentence=67, token=1), Head(sentence=67, token=4)), strength=0, verb=2)   \n",
       "\n",
       "                                                                                                             full_sentence_text  \\\n",
       "667104  Auch Frankreich kündigte die Entsendung von Experten an , um bei den Ermittlungen zu helfen , Riad habe darum gebeten .   \n",
       "667105  Auch Frankreich kündigte die Entsendung von Experten an , um bei den Ermittlungen zu helfen , Riad habe darum gebeten .   \n",
       "667106  Auch Frankreich kündigte die Entsendung von Experten an , um bei den Ermittlungen zu helfen , Riad habe darum gebeten .   \n",
       "\n",
       "       counts  \n",
       "667104      3  \n",
       "667105      3  \n",
       "667106      3  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "s1 = df_occ[df_occ[\"counts\"] >= 2] \\\n",
    "    .sort_values([\"full_sentence_text\"]) \\\n",
    "    .sample(n=1)\n",
    "s1_val = s1[\"full_sentence_text\"].to_list()[0]\n",
    "df_occ[df_occ[\"full_sentence_text\"] == s1_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0ba9e4",
   "metadata": {},
   "source": [
    "**Seeking for specific multi-PAS sentences:**\n",
    "\n",
    "Ones where:\n",
    "$MP^{arg_1}_1=MP^{arg_1}_2$ or  $MP^{arg_2}_1=MP^{arg_2}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "18c97344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all docIDs and sents where this hold and then filter by them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b55a44",
   "metadata": {},
   "source": [
    "**Verb mixing**\n",
    "\n",
    "How large is the likelihood that a verb-mediated relation is positive, then negative.\n",
    "\n",
    "Potentially: try to remove this ambiguity.\n",
    "\n",
    "***Agreement metric:*** What are particularly ambiguous verbs, and can \"entity\" type restrictions be learned around them? What are not very ambigious words?\n",
    "\n",
    "=> Using a measure of [balance](https://stats.stackexchange.com/questions/239973/a-general-measure-of-data-set-imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f33a9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(seq):\n",
    "    \"\"\"\n",
    "        Provides a measure of balancedness.\n",
    "        input: sequence of class counts\n",
    "        0 means unbalanced, which is better! more agreement!\n",
    "        1 means balanced\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    from numpy import log\n",
    "    \n",
    "    # define this as a high agreement\n",
    "    if len(seq) == 1:\n",
    "        # we'll define a single class as highly unbalanced\n",
    "        return 0.0\n",
    "    \n",
    "    # n = len(seq)\n",
    "    n = sum(seq)\n",
    "    # classes = [(clas,float(count)) for clas,count in Counter(seq).items()]\n",
    "    k = len(seq)\n",
    "    \n",
    "    H = -sum([ (count/n) * log((count/n)) for clas,count in enumerate(seq)]) #shannon entropy\n",
    "    return H/(log(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c8069ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance([500, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "93fd3f84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>rechtfertigen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>verhungern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>nachtrauern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>verkraften</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>verkümmern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>herunterstufen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>herabwürdigen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>herbeizitieren</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>verschliessen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>erheitern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1159 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb_lemma  balance\n",
       "735   rechtfertigen      0.0\n",
       "935      verhungern      0.0\n",
       "680     nachtrauern      0.0\n",
       "943      verkraften      0.0\n",
       "944      verkümmern      0.0\n",
       "..              ...      ...\n",
       "543  herunterstufen      1.0\n",
       "537   herabwürdigen      1.0\n",
       "538  herbeizitieren      1.0\n",
       "981   verschliessen      1.0\n",
       "419       erheitern      1.0\n",
       "\n",
       "[1159 rows x 2 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixing = df.copy(deep=True)\n",
    "df_mixing\n",
    "df_mixing = df_mixing.groupby([\"verb_lemma\", \"rel_type\"]).size().reset_index(name=\"counts\")\n",
    "df_mixing = df_mixing.groupby([\"verb_lemma\"]).apply(lambda x: balance(x[\"counts\"].to_list())).reset_index(name=\"balance\").dropna()\n",
    "df_mixing.sort_values(\"balance\")\n",
    "# df_mixing[df_mixing[\"verb_lemma\"] == \"verübeln\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0bbe2c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of the balancedness?\n",
    "df_mixing.balance.value_counts()\n",
    "# get all verbs with balance 0.0\n",
    "agreeable_verbs = df_mixing[df_mixing[\"balance\"] <= .3][\"verb_lemma\"].to_list()\n",
    "len(agreeable_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fdff99cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>nachgeben</td>\n",
       "      <td>neutral</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     verb_lemma rel_type  counts\n",
       "1470  nachgeben  neutral     467"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of verbs and their agreement\n",
    "df_analysis = df.copy(deep=True)\n",
    "df_analysis = df_analysis.groupby([\"verb_lemma\", \"rel_type\"]).size().reset_index(name=\"counts\")\n",
    "df_analysis[df_analysis[\"verb_lemma\"] == \"nachgeben\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb37e5",
   "metadata": {},
   "source": [
    "**How big is the problem of -1 in first span or a \".\" in the data?**\n",
    "\n",
    "The -1 does not exist. No problem currently.\n",
    "\n",
    "The \".\" is quite prevalent and strangely only occurrs in the neutral case. That's why a cleaning step was introduced below (see solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee8f7b4",
   "metadata": {},
   "source": [
    "**Clean dataset**\n",
    "\n",
    "1. As seen below we must remove the argument heads make sure we don't have any \".\" as arguments for the neutrals.\n",
    "2. We also want to remove the reflexive cases for the pronouns.\n",
    "3. Only include verbs that fulfill balancedness criteria, execute cell 17 & 18 for this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "defb0a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pro        6611\n",
       "neutral    5343\n",
       "con        3666\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty = df.copy(deep=True)\n",
    "df_dirty[\n",
    "#(df_dirty[\"arg1_head\"] == \".\")\n",
    "#|(df_dirty[\"arg2_head\"] == \".\")\n",
    "#|(df_dirty[\"arg2\"] == \".\")\n",
    "#|(df_dirty[\"arg2\"] == \".\")\n",
    "#(df_dirty[\"arg1_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_head_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_head_start\"] == -1)\n",
    "(df_dirty[\"arg1\"] == df_dirty[\"arg2\"])\n",
    "& (df_dirty[\"full_sentence_text\"].str.contains(\"sich\")) # reflexive verbs, should be ignore?\n",
    "].rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b1db5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - include dotted (most likely with no target or other thing, or are these the -1 ones)\n",
    "mask = ~((df[\"arg1_head\"] == \".\")\n",
    "|(df[\"arg2_head\"] == \".\")\n",
    "|(df[\"arg2\"] == \".\")\n",
    "|(df[\"arg2\"] == \".\"))\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "\n",
    "# 2 - exclude reflexive\n",
    "mask = ~(df[\"arg1\"] == df[\"arg2\"])\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "# 3 - exclude balanced = ambiguous verbs.\n",
    "mask = (df[\"verb_lemma\"].isin(agreeable_verbs))\n",
    "\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0c0d839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral    270020\n",
       "pro          2547\n",
       "con          2242\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(agreeable_verbs))\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597a537",
   "metadata": {},
   "source": [
    "**Balance the dataset**\n",
    "\n",
    "Make sure that each class is represented equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bffd1263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        2242\n",
       "neutral    2242\n",
       "pro        2242\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('rel_type')\n",
    "df = df.apply(lambda x: x.sample(df.size().min(), random_state=RANDOM_STATE).reset_index(drop=True))\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a91e3581",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        2242\n",
       "neutral    2242\n",
       "pro        2242\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(level=0, drop=True)\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c305bc0",
   "metadata": {},
   "source": [
    "**Option 1: Train-test-splitting**\n",
    "\n",
    "Only problem: We may have sentences within the same documents with multiple PAS that are split accross the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "07f70683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE COUNTS: train\n",
      "con        1570\n",
      "pro        1569\n",
      "neutral    1569\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: test\n",
      "pro        337\n",
      "con        336\n",
      "neutral    336\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: val\n",
      "neutral    337\n",
      "pro        336\n",
      "con        336\n",
      "Name: rel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train, test_val = train_test_split(df, test_size=0.3, stratify=df[\"rel_type\"], random_state=RANDOM_STATE)\n",
    "test, val = train_test_split(test_val, test_size=0.5, stratify=test_val[\"rel_type\"],random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"VALUE COUNTS: train\")\n",
    "print(train.rel_type.value_counts())\n",
    "train.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: test\")\n",
    "print(test.rel_type.value_counts())\n",
    "test.to_csv(TEST_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: val\")\n",
    "print(val.rel_type.value_counts())\n",
    "val.to_csv(VAL_DATA_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca1b09a",
   "metadata": {},
   "source": [
    "**Option 2: Train-test-splitting**\n",
    "\n",
    "With respecting group distribution. Which means that all sentences $S_{1..N}$ from a document $A$ will either all be in the test set, all be in the validation set or all be in the training set. The reason for this is since it could happen that multiple PAS are detected within the same sentence and then the system is trained to one PAS and is evaluated on a completely different PAS, which is unfair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ad57a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve groups between sentences (in this case doc_id is safe enough)\n",
    "splitter = GroupShuffleSplit(test_size=.30, n_splits=1, random_state=RANDOM_STATE)\n",
    "split = splitter.split(df, groups=df['doc_id'])\n",
    "train_inds, test_val_inds = next(split)\n",
    "\n",
    "train = df.iloc[train_inds]\n",
    "test_val = df.iloc[test_val_inds]\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=.5, n_splits=1, random_state=RANDOM_STATE)\n",
    "split = splitter.split(test_val, groups=test_val['doc_id'])\n",
    "test_inds, val_inds = next(split)\n",
    "\n",
    "test = test_val.iloc[test_inds]\n",
    "val = test_val.iloc[val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "51fba292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE COUNTS: train\n",
      "con        1598\n",
      "pro        1576\n",
      "neutral    1537\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: test\n",
      "con        351\n",
      "neutral    338\n",
      "pro        314\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: val\n",
      "neutral    367\n",
      "pro        352\n",
      "con        293\n",
      "Name: rel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"VALUE COUNTS: train\")\n",
    "print(train.rel_type.value_counts())\n",
    "train.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: test\")\n",
    "print(test.rel_type.value_counts())\n",
    "test.to_csv(TEST_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: val\")\n",
    "print(val.rel_type.value_counts())\n",
    "val.to_csv(VAL_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "952ee774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "TRAIN: [1, 1, 3, 3, 3, 8, 8] TEST: [2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# a small test to see whether option no 2 achieves our goals.\n",
    "\n",
    "X = np.ones(shape=(10, 2))\n",
    "y = np.ones(shape=(10, 1))\n",
    "groups = np.array([1, 1, 2, 2, 2, 3, 3, 3, 8, 8])\n",
    "print(groups.shape)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=42)\n",
    "gss.get_n_splits()\n",
    "\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", [groups[i] for i in train_idx], \"TEST:\", [groups[i] for i in test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f49084",
   "metadata": {},
   "source": [
    "## Hard-verb splitting\n",
    "\n",
    "To test generalisability we may want to split verbs by train and test set.\n",
    "\n",
    "**Solution**: We can simply use the group splitting argument on the verbs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedd0ed",
   "metadata": {},
   "source": [
    "**Option 3: Train-test split with verb-splitting**\n",
    "\n",
    "This means that given a verb $V$, all sentences which contain that verb will either be in $T_{RAIN}$, $V_{ALID}$ or $T_{EST}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "39b08f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve groups between sentences (in this case doc_id is safe enough)\n",
    "splitter = GroupShuffleSplit(test_size=.30, n_splits=1, random_state=RANDOM_STATE)\n",
    "split = splitter.split(df, groups=df['verb_form'])\n",
    "train_inds, test_val_inds = next(split)\n",
    "\n",
    "train = df.iloc[train_inds]\n",
    "test_val = df.iloc[test_val_inds]\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=.5, n_splits=1, random_state=RANDOM_STATE)\n",
    "split = splitter.split(test_val, groups=test_val['verb_form'])\n",
    "test_inds, val_inds = next(split)\n",
    "\n",
    "test = test_val.iloc[test_inds]\n",
    "val = test_val.iloc[val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f2728d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE COUNTS: train\n",
      "con        1686\n",
      "pro        1423\n",
      "neutral    1413\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: test\n",
      "pro        533\n",
      "neutral    370\n",
      "con        206\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: val\n",
      "neutral    459\n",
      "con        350\n",
      "pro        286\n",
      "Name: rel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"VALUE COUNTS: train\")\n",
    "print(train.rel_type.value_counts())\n",
    "train.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: test\")\n",
    "print(test.rel_type.value_counts())\n",
    "test.to_csv(TEST_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: val\")\n",
    "print(val.rel_type.value_counts())\n",
    "val.to_csv(VAL_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31852b3d",
   "metadata": {},
   "source": [
    "We verify that this worked using an overlap metric by checking whether the overlap is 0 with respect to all verbs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8bb7de55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_verbs = train.verb_form.to_list()\n",
    "val_test_verbs = val.verb_form.to_list() + test.verb_form.to_list()\n",
    "list(set(train_verbs) & set(val_test_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fa0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
