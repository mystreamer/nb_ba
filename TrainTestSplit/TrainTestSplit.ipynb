{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8a35ca",
   "metadata": {},
   "source": [
    "## TrainTestSplit\n",
    "\n",
    "Create a train-test-split for the datasets found in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "90a146c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "513988fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# makedirs if not exist\n",
    "os.makedirs(\"../../etl/data/intermediate/TrainTestSplit\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "470708da",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "FULL_DATA_PATH=\"../../etl/data/raw/01_extract.csv\"\n",
    "TRAIN_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_train.csv\"\n",
    "TEST_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_test.csv\"\n",
    "VAL_DATA_PATH=\"../../etl/data/intermediate/TrainTestSplit/01_val.csv\"\n",
    "\n",
    "# mode can be either \"CRITERIA_FREE\", \"DOC_SPLIT\", \"LEMMA_SPLIT\", \"SYN_SPLIT\"\n",
    "SPLIT_MODE=\"DOC_SPLIT\"\n",
    "VERB_AGREEMENT_LEVEL = .6\n",
    "INCLUDE_SENTS_N_PAS = [1,2,3,4,5]\n",
    "RANDOM_STATE=42\n",
    "\n",
    "INCLUDE_MANUAL_ANNOTATION=False\n",
    "MANUAL_ANNOTATION_SIZE_PER_GROUP=70\n",
    "MANUAL_ANNOTATION_PATH=\"../../etl/data/intermediate/TrainTestSplit/manual_annotation.csv\"\n",
    "\n",
    "# fasttext embeddings path\n",
    "FASTTEXT_MODEL_BIN_PATH=\"../../external_repos/stancer_setup/models/cc.de.300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "045f213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FULL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bd9fa7b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>abgestraft</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>abstrafen</td>\n",
       "      <td>Alexis Tsipras</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Alexis</td>\n",
       "      <td>...</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>140</td>\n",
       "      <td>151</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>die neue Regierung</td>\n",
       "      <td>75</td>\n",
       "      <td>93</td>\n",
       "      <td>N</td>\n",
       "      <td>Regierung</td>\n",
       "      <td>...</td>\n",
       "      <td>die Hoffnungen auf einen spürbaren Aufschwung</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>N</td>\n",
       "      <td>Hoffnungen</td>\n",
       "      <td>98</td>\n",
       "      <td>108</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)</td>\n",
       "      <td>Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>beenden</td>\n",
       "      <td>119</td>\n",
       "      <td>126</td>\n",
       "      <td>beenden</td>\n",
       "      <td>Will er dem Land etwas Gutes tun</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>die politische Polarisierung beenden</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>Polarisierung</td>\n",
       "      <td>105</td>\n",
       "      <td>118</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)</td>\n",
       "      <td>Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>Pajtim Kasami</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>Pajtim</td>\n",
       "      <td>...</td>\n",
       "      <td>die Kurzarbeit nun doch</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>N</td>\n",
       "      <td>Kurzarbeit</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>pro</td>\n",
       "      <td>Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)</td>\n",
       "      <td>Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>entliess</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>entlassen</td>\n",
       "      <td>der FC Sion</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>FC</td>\n",
       "      <td>...</td>\n",
       "      <td>Fussball Neun Spieler</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>Fussball</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)</td>\n",
       "      <td>( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832168</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>äussert</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>äussern</td>\n",
       "      <td>Frau A</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Frau</td>\n",
       "      <td>...</td>\n",
       "      <td>massive Vorwürfe gegen ihre Vorgesetzten</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Vorwürfe</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)</td>\n",
       "      <td>Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832169</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>stelle</td>\n",
       "      <td>184</td>\n",
       "      <td>190</td>\n",
       "      <td>stellen</td>\n",
       "      <td>das Kommando</td>\n",
       "      <td>171</td>\n",
       "      <td>183</td>\n",
       "      <td>N</td>\n",
       "      <td>Kommando</td>\n",
       "      <td>...</td>\n",
       "      <td>einen Antrag auf ihren Ausschluss</td>\n",
       "      <td>191</td>\n",
       "      <td>224</td>\n",
       "      <td>N</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>197</td>\n",
       "      <td>203</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)</td>\n",
       "      <td>Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832170</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>ausgewiesen</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>ausweisen</td>\n",
       "      <td>Der Konzern</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>Konzern</td>\n",
       "      <td>...</td>\n",
       "      <td>eine Liquidität</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>N</td>\n",
       "      <td>Liquidität</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)</td>\n",
       "      <td>Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832171</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>belebt</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>beleben</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>...</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)</td>\n",
       "      <td>Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832172</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>halten</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>halten</td>\n",
       "      <td>Die Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>N</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>...</td>\n",
       "      <td>möglichst gering</td>\n",
       "      <td>108</td>\n",
       "      <td>124</td>\n",
       "      <td>ADV</td>\n",
       "      <td>gering</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)</td>\n",
       "      <td>Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832173 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  doc_id  \\\n",
       "0       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "1       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "2       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "3       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "4       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "...                                                                  ...   \n",
       "832168  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832169  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832170  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832171  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832172  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "\n",
       "          verb_form  verb_form_start  verb_form_end   verb_lemma  \\\n",
       "0        abgestraft               26             36    abstrafen   \n",
       "1       enttäuschen              140            151  enttäuschen   \n",
       "2           beenden              119            126      beenden   \n",
       "3       akzeptieren               69             80  akzeptieren   \n",
       "4          entliess               30             38    entlassen   \n",
       "...             ...              ...            ...          ...   \n",
       "832168      äussert                5             12      äussern   \n",
       "832169       stelle              184            190      stellen   \n",
       "832170  ausgewiesen               77             88    ausweisen   \n",
       "832171       belebt                8             14      beleben   \n",
       "832172       halten              128            134       halten   \n",
       "\n",
       "                                     arg1  arg1_start  arg1_end arg1_pos  \\\n",
       "0                          Alexis Tsipras           5        19        N   \n",
       "1                      die neue Regierung          75        93        N   \n",
       "2       Will er dem Land etwas Gutes tun            0        33       $.   \n",
       "3                          Pajtim Kasami            0        14        N   \n",
       "4                             der FC Sion          39        50        N   \n",
       "...                                   ...         ...       ...      ...   \n",
       "832168                             Frau A          13        19        N   \n",
       "832169                       das Kommando         171       183        N   \n",
       "832170                        Der Konzern           0        11        N   \n",
       "832171              das Verkehrsaufkommen          20        41        N   \n",
       "832172                      Die Lufthansa           0        13        N   \n",
       "\n",
       "                arg1_head  ...                                           arg2  \\\n",
       "0                  Alexis  ...    Dass Alexis Tsipras jetzt abgestraft wurde    \n",
       "1               Regierung  ...  die Hoffnungen auf einen spürbaren Aufschwung   \n",
       "2                       .  ...          die politische Polarisierung beenden    \n",
       "3                  Pajtim  ...                       die Kurzarbeit nun doch    \n",
       "4                      FC  ...                          Fussball Neun Spieler   \n",
       "...                   ...  ...                                            ...   \n",
       "832168               Frau  ...       massive Vorwürfe gegen ihre Vorgesetzten   \n",
       "832169           Kommando  ...              einen Antrag auf ihren Ausschluss   \n",
       "832170            Konzern  ...                                eine Liquidität   \n",
       "832171  Verkehrsaufkommen  ...                          das Verkehrsaufkommen   \n",
       "832172          Lufthansa  ...                               möglichst gering   \n",
       "\n",
       "        arg2_start arg2_end  arg2_pos          arg2_head arg2_head_start  \\\n",
       "0                0       43        $.                  .             143   \n",
       "1               94      139         N         Hoffnungen              98   \n",
       "2               90      127         N      Polarisierung             105   \n",
       "3               81      105         N         Kurzarbeit              85   \n",
       "4                8       29         N           Fussball               8   \n",
       "...            ...      ...       ...                ...             ...   \n",
       "832168          20       60         N           Vorwürfe              28   \n",
       "832169         191      224         N             Antrag             197   \n",
       "832170          32       47         N         Liquidität              37   \n",
       "832171          20       41         N  Verkehrsaufkommen              24   \n",
       "832172         108      124       ADV             gering             118   \n",
       "\n",
       "       arg2_head_end  rel_type  \\\n",
       "0                144   neutral   \n",
       "1                108   neutral   \n",
       "2                118   neutral   \n",
       "3                 95       pro   \n",
       "4                 16   neutral   \n",
       "...              ...       ...   \n",
       "832168            36   neutral   \n",
       "832169           203   neutral   \n",
       "832170            47       con   \n",
       "832171            41       con   \n",
       "832172           124   neutral   \n",
       "\n",
       "                                                                                                            pred_serial  \\\n",
       "0           Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)   \n",
       "1       Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)   \n",
       "2       Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)   \n",
       "3            Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)   \n",
       "4          Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)   \n",
       "...                                                                                                                 ...   \n",
       "832168     Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)   \n",
       "832169  Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)   \n",
       "832170        Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)   \n",
       "832171         Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)   \n",
       "832172   Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)   \n",
       "\n",
       "                                                                                                                                                                                                                        full_sentence_text  \n",
       "0                                                                                         Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .  \n",
       "1                                                                                Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .  \n",
       "2                                                Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .  \n",
       "3                                                    Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .  \n",
       "4                                                                                                                       ( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .  \n",
       "...                                                                                                                                                                                                                                    ...  \n",
       "832168                                                                                                                                                                      Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .  \n",
       "832169  Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .  \n",
       "832170                                                                                                                                          Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .  \n",
       "832171                                                                                                                                                       Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .  \n",
       "832172                                                                                            Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .  \n",
       "\n",
       "[832173 rows x 22 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by sentences\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3574e1b",
   "metadata": {},
   "source": [
    "**How big is the problem with multi-PAS per sentence?**\n",
    "\n",
    "Which should not be split accross the dataset splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fc553d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rel_type  counts\n",
       "con       1          80668\n",
       "          2           8149\n",
       "          3            785\n",
       "          4             68\n",
       "          5              3\n",
       "neutral   1         569679\n",
       "          2          51984\n",
       "          3           3348\n",
       "          4            223\n",
       "          5             27\n",
       "          7              7\n",
       "          8              8\n",
       "pro       1         107311\n",
       "          2           9187\n",
       "          3            676\n",
       "          4             45\n",
       "          5              5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_occ = df.copy(deep=True)\n",
    "df_occ = df_occ.merge(df_occ.groupby([\"doc_id\", \"full_sentence_text\"]).size().reset_index(name=\"counts\"), on=[\"doc_id\", \"full_sentence_text\"])\n",
    "df_occ_freq = df_occ.groupby([\"rel_type\", \"counts\"]).size()\n",
    "df_occ_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d753fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter needed pas per sentence\n",
    "# 0 - exclude sents, which have more than N specified pas.\n",
    "mask = ~(df_occ[\"counts\"].isin(INCLUDE_SENTS_N_PAS))\n",
    "df_occ = df_occ[mask]\n",
    "n_pas_sents = df_occ[\"full_sentence_text\"].to_list()\n",
    "\n",
    "df = df[~df.full_sentence_text.isin(n_pas_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6f05613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INCLUDE_SENTS_N_PAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7882957a",
   "metadata": {},
   "source": [
    "### Complex sentences analysis\n",
    "\n",
    "**How do the multi-PAS sentences look**?\n",
    "\n",
    "Complexity and sentence analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bc8839e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>484618</th>\n",
       "      <td>0b7a6650825ab759a34b8c17b1659cf6688f252ca725a4821968f0ed0b301f3b</td>\n",
       "      <td>ausgegangen</td>\n",
       "      <td>95</td>\n",
       "      <td>106</td>\n",
       "      <td>ausgehen</td>\n",
       "      <td>Bei beiden</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>PROAV</td>\n",
       "      <td>davon</td>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=22, token=-1), Head(sentence=22, token=17)), strength=0, verb=18)</td>\n",
       "      <td>Bei beiden , bei der « europäischen Normalität » und beim « skandinavischen Weg » , wird davon ausgegangen , dass sich die effektiven Souveränitätsverluste als geringer herausstellen würden denn befürchtet .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484619</th>\n",
       "      <td>0b7a6650825ab759a34b8c17b1659cf6688f252ca725a4821968f0ed0b301f3b</td>\n",
       "      <td>befürchtet</td>\n",
       "      <td>195</td>\n",
       "      <td>205</td>\n",
       "      <td>befürchten</td>\n",
       "      <td>die effektiven Souveränitätsverluste</td>\n",
       "      <td>119</td>\n",
       "      <td>155</td>\n",
       "      <td>N</td>\n",
       "      <td>Souveränitätsverluste</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=22, token=24), Head(sentence=22, token=-1)), strength=0, verb=30)</td>\n",
       "      <td>Bei beiden , bei der « europäischen Normalität » und beim « skandinavischen Weg » , wird davon ausgegangen , dass sich die effektiven Souveränitätsverluste als geringer herausstellen würden denn befürchtet .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  doc_id  \\\n",
       "484618  0b7a6650825ab759a34b8c17b1659cf6688f252ca725a4821968f0ed0b301f3b   \n",
       "484619  0b7a6650825ab759a34b8c17b1659cf6688f252ca725a4821968f0ed0b301f3b   \n",
       "\n",
       "          verb_form  verb_form_start  verb_form_end  verb_lemma  \\\n",
       "484618  ausgegangen               95            106    ausgehen   \n",
       "484619   befürchtet              195            205  befürchten   \n",
       "\n",
       "                                        arg1  arg1_start  arg1_end arg1_pos  \\\n",
       "484618                           Bei beiden            0        11       $.   \n",
       "484619  die effektiven Souveränitätsverluste         119       155        N   \n",
       "\n",
       "                    arg1_head  ...  arg2_start  arg2_end arg2_pos  arg2_head  \\\n",
       "484618                      .  ...          89        94    PROAV      davon   \n",
       "484619  Souveränitätsverluste  ...           0        11       $.          .   \n",
       "\n",
       "        arg2_head_start arg2_head_end rel_type  \\\n",
       "484618               89            94  neutral   \n",
       "484619              206           207  neutral   \n",
       "\n",
       "                                                                                                            pred_serial  \\\n",
       "484618  Predicate(type='neutral', args=(Head(sentence=22, token=-1), Head(sentence=22, token=17)), strength=0, verb=18)   \n",
       "484619  Predicate(type='neutral', args=(Head(sentence=22, token=24), Head(sentence=22, token=-1)), strength=0, verb=30)   \n",
       "\n",
       "                                                                                                                                                                                                     full_sentence_text  \\\n",
       "484618  Bei beiden , bei der « europäischen Normalität » und beim « skandinavischen Weg » , wird davon ausgegangen , dass sich die effektiven Souveränitätsverluste als geringer herausstellen würden denn befürchtet .   \n",
       "484619  Bei beiden , bei der « europäischen Normalität » und beim « skandinavischen Weg » , wird davon ausgegangen , dass sich die effektiven Souveränitätsverluste als geringer herausstellen würden denn befürchtet .   \n",
       "\n",
       "       counts  \n",
       "484618      2  \n",
       "484619      2  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_occ = df.copy(deep=True)\n",
    "df_occ = df_occ.merge(df_occ.groupby([\"doc_id\", \"full_sentence_text\"]).size().reset_index(name=\"counts\"), on=[\"doc_id\", \"full_sentence_text\"])\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "s1 = df_occ[df_occ[\"counts\"] >= 2] \\\n",
    "    .sort_values([\"full_sentence_text\"]) \\\n",
    "    .sample(n=1)\n",
    "s1_val = s1[\"full_sentence_text\"].to_list()[0]\n",
    "df_occ[df_occ[\"full_sentence_text\"] == s1_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207acebe",
   "metadata": {},
   "source": [
    "**Seeking for specific multi-PAS sentences:**\n",
    "\n",
    "Ones where:\n",
    "$MP^{arg_1}_1=MP^{arg_1}_2$ or  $MP^{arg_2}_1=MP^{arg_2}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9c402d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all docIDs and sents where this hold and then filter by them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8ed76",
   "metadata": {},
   "source": [
    "**Verb mixing**\n",
    "\n",
    "How large is the likelihood that a verb-mediated relation is positive, then negative.\n",
    "\n",
    "Potentially: try to remove this ambiguity.\n",
    "\n",
    "***Agreement metric:*** What are particularly ambiguous verbs, and can \"entity\" type restrictions be learned around them? What are not very ambigious words?\n",
    "\n",
    "=> Using a measure of [balance](https://stats.stackexchange.com/questions/239973/a-general-measure-of-data-set-imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0613df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(seq):\n",
    "    \"\"\"\n",
    "        Provides a measure of balancedness.\n",
    "        input: sequence of class counts\n",
    "        0 means unbalanced, which is better! more agreement!\n",
    "        1 means balanced\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    from numpy import log\n",
    "    \n",
    "    # define this as a high agreement\n",
    "    if len(seq) == 1:\n",
    "        # we'll define a single class as highly unbalanced\n",
    "        return 0.0\n",
    "    \n",
    "    # n = len(seq)\n",
    "    n = sum(seq)\n",
    "    # classes = [(clas,float(count)) for clas,count in Counter(seq).items()]\n",
    "    k = len(seq)\n",
    "    \n",
    "    H = -sum([ (count/n) * log((count/n)) for clas,count in enumerate(seq)]) #shannon entropy\n",
    "    return H/(log(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c6794e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance([500, 500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bd322e4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>rechtfertigen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>verhungern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>nachtrauern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>verkraften</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>verkümmern</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>herunterstufen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>herabwürdigen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>herbeizitieren</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>verschliessen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>erheitern</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1159 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb_lemma  balance\n",
       "735   rechtfertigen      0.0\n",
       "935      verhungern      0.0\n",
       "680     nachtrauern      0.0\n",
       "943      verkraften      0.0\n",
       "944      verkümmern      0.0\n",
       "..              ...      ...\n",
       "543  herunterstufen      1.0\n",
       "537   herabwürdigen      1.0\n",
       "538  herbeizitieren      1.0\n",
       "981   verschliessen      1.0\n",
       "419       erheitern      1.0\n",
       "\n",
       "[1159 rows x 2 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mixing = df.copy(deep=True)\n",
    "df_mixing\n",
    "df_mixing = df_mixing.groupby([\"verb_lemma\", \"rel_type\"]).size().reset_index(name=\"counts\")\n",
    "df_mixing = df_mixing.groupby([\"verb_lemma\"]).apply(lambda x: balance(x[\"counts\"].to_list())).reset_index(name=\"balance\").dropna()\n",
    "df_mixing.sort_values(\"balance\")\n",
    "# df_mixing[df_mixing[\"verb_lemma\"] == \"verübeln\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6e2ef178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "623"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of the balancedness?\n",
    "df_mixing.balance.value_counts()\n",
    "# get all verbs with balance 0.0\n",
    "agreeable_verbs = df_mixing[df_mixing[\"balance\"] <= VERB_AGREEMENT_LEVEL][\"verb_lemma\"].to_list()\n",
    "len(agreeable_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ba26d972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>nachgeben</td>\n",
       "      <td>neutral</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     verb_lemma rel_type  counts\n",
       "1470  nachgeben  neutral     467"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the distribution of verbs and their agreement\n",
    "df_analysis = df.copy(deep=True)\n",
    "df_analysis = df_analysis.groupby([\"verb_lemma\", \"rel_type\"]).size().reset_index(name=\"counts\")\n",
    "df_analysis[df_analysis[\"verb_lemma\"] == \"nachgeben\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cc989130",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>verb_form</th>\n",
       "      <th>verb_form_start</th>\n",
       "      <th>verb_form_end</th>\n",
       "      <th>verb_lemma</th>\n",
       "      <th>arg1</th>\n",
       "      <th>arg1_start</th>\n",
       "      <th>arg1_end</th>\n",
       "      <th>arg1_pos</th>\n",
       "      <th>arg1_head</th>\n",
       "      <th>...</th>\n",
       "      <th>arg2</th>\n",
       "      <th>arg2_start</th>\n",
       "      <th>arg2_end</th>\n",
       "      <th>arg2_pos</th>\n",
       "      <th>arg2_head</th>\n",
       "      <th>arg2_head_start</th>\n",
       "      <th>arg2_head_end</th>\n",
       "      <th>rel_type</th>\n",
       "      <th>pred_serial</th>\n",
       "      <th>full_sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>abgestraft</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>abstrafen</td>\n",
       "      <td>Alexis Tsipras</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Alexis</td>\n",
       "      <td>...</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)</td>\n",
       "      <td>Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>140</td>\n",
       "      <td>151</td>\n",
       "      <td>enttäuschen</td>\n",
       "      <td>die neue Regierung</td>\n",
       "      <td>75</td>\n",
       "      <td>93</td>\n",
       "      <td>N</td>\n",
       "      <td>Regierung</td>\n",
       "      <td>...</td>\n",
       "      <td>die Hoffnungen auf einen spürbaren Aufschwung</td>\n",
       "      <td>94</td>\n",
       "      <td>139</td>\n",
       "      <td>N</td>\n",
       "      <td>Hoffnungen</td>\n",
       "      <td>98</td>\n",
       "      <td>108</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)</td>\n",
       "      <td>Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc</td>\n",
       "      <td>beenden</td>\n",
       "      <td>119</td>\n",
       "      <td>126</td>\n",
       "      <td>beenden</td>\n",
       "      <td>Will er dem Land etwas Gutes tun</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>$.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>die politische Polarisierung beenden</td>\n",
       "      <td>90</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>Polarisierung</td>\n",
       "      <td>105</td>\n",
       "      <td>118</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)</td>\n",
       "      <td>Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>akzeptieren</td>\n",
       "      <td>Pajtim Kasami</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>N</td>\n",
       "      <td>Pajtim</td>\n",
       "      <td>...</td>\n",
       "      <td>die Kurzarbeit nun doch</td>\n",
       "      <td>81</td>\n",
       "      <td>105</td>\n",
       "      <td>N</td>\n",
       "      <td>Kurzarbeit</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>pro</td>\n",
       "      <td>Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)</td>\n",
       "      <td>Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac</td>\n",
       "      <td>entliess</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>entlassen</td>\n",
       "      <td>der FC Sion</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>N</td>\n",
       "      <td>FC</td>\n",
       "      <td>...</td>\n",
       "      <td>Fussball Neun Spieler</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>Fussball</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)</td>\n",
       "      <td>( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832168</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>äussert</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>äussern</td>\n",
       "      <td>Frau A</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>Frau</td>\n",
       "      <td>...</td>\n",
       "      <td>massive Vorwürfe gegen ihre Vorgesetzten</td>\n",
       "      <td>20</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Vorwürfe</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)</td>\n",
       "      <td>Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832169</th>\n",
       "      <td>9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4</td>\n",
       "      <td>stelle</td>\n",
       "      <td>184</td>\n",
       "      <td>190</td>\n",
       "      <td>stellen</td>\n",
       "      <td>das Kommando</td>\n",
       "      <td>171</td>\n",
       "      <td>183</td>\n",
       "      <td>N</td>\n",
       "      <td>Kommando</td>\n",
       "      <td>...</td>\n",
       "      <td>einen Antrag auf ihren Ausschluss</td>\n",
       "      <td>191</td>\n",
       "      <td>224</td>\n",
       "      <td>N</td>\n",
       "      <td>Antrag</td>\n",
       "      <td>197</td>\n",
       "      <td>203</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)</td>\n",
       "      <td>Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832170</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>ausgewiesen</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>ausweisen</td>\n",
       "      <td>Der Konzern</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "      <td>Konzern</td>\n",
       "      <td>...</td>\n",
       "      <td>eine Liquidität</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>N</td>\n",
       "      <td>Liquidität</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)</td>\n",
       "      <td>Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832171</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>belebt</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>beleben</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>...</td>\n",
       "      <td>das Verkehrsaufkommen</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>N</td>\n",
       "      <td>Verkehrsaufkommen</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>con</td>\n",
       "      <td>Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)</td>\n",
       "      <td>Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832172</th>\n",
       "      <td>d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf</td>\n",
       "      <td>halten</td>\n",
       "      <td>128</td>\n",
       "      <td>134</td>\n",
       "      <td>halten</td>\n",
       "      <td>Die Lufthansa</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>N</td>\n",
       "      <td>Lufthansa</td>\n",
       "      <td>...</td>\n",
       "      <td>möglichst gering</td>\n",
       "      <td>108</td>\n",
       "      <td>124</td>\n",
       "      <td>ADV</td>\n",
       "      <td>gering</td>\n",
       "      <td>118</td>\n",
       "      <td>124</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)</td>\n",
       "      <td>Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832158 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  doc_id  \\\n",
       "0       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "1       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "2       4bc8c13ddaa028e64a34ce08397157b846fb4de3ad26e34759aa57fdbeb50bcc   \n",
       "3       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "4       290f3971010f6d9385e896208f328948f5fb3f9bc0caeb9508b4f1acc63a35ac   \n",
       "...                                                                  ...   \n",
       "832168  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832169  9701f0c776430a365f0619836f34658459be788b9a6646e86c252c477ef565a4   \n",
       "832170  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832171  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "832172  d0fc434ce0021b0dff7b52157d352daaff8d1a65f4640a744651af0e992064bf   \n",
       "\n",
       "          verb_form  verb_form_start  verb_form_end   verb_lemma  \\\n",
       "0        abgestraft               26             36    abstrafen   \n",
       "1       enttäuschen              140            151  enttäuschen   \n",
       "2           beenden              119            126      beenden   \n",
       "3       akzeptieren               69             80  akzeptieren   \n",
       "4          entliess               30             38    entlassen   \n",
       "...             ...              ...            ...          ...   \n",
       "832168      äussert                5             12      äussern   \n",
       "832169       stelle              184            190      stellen   \n",
       "832170  ausgewiesen               77             88    ausweisen   \n",
       "832171       belebt                8             14      beleben   \n",
       "832172       halten              128            134       halten   \n",
       "\n",
       "                                     arg1  arg1_start  arg1_end arg1_pos  \\\n",
       "0                          Alexis Tsipras           5        19        N   \n",
       "1                      die neue Regierung          75        93        N   \n",
       "2       Will er dem Land etwas Gutes tun            0        33       $.   \n",
       "3                          Pajtim Kasami            0        14        N   \n",
       "4                             der FC Sion          39        50        N   \n",
       "...                                   ...         ...       ...      ...   \n",
       "832168                             Frau A          13        19        N   \n",
       "832169                       das Kommando         171       183        N   \n",
       "832170                        Der Konzern           0        11        N   \n",
       "832171              das Verkehrsaufkommen          20        41        N   \n",
       "832172                      Die Lufthansa           0        13        N   \n",
       "\n",
       "                arg1_head  ...                                           arg2  \\\n",
       "0                  Alexis  ...    Dass Alexis Tsipras jetzt abgestraft wurde    \n",
       "1               Regierung  ...  die Hoffnungen auf einen spürbaren Aufschwung   \n",
       "2                       .  ...          die politische Polarisierung beenden    \n",
       "3                  Pajtim  ...                       die Kurzarbeit nun doch    \n",
       "4                      FC  ...                          Fussball Neun Spieler   \n",
       "...                   ...  ...                                            ...   \n",
       "832168               Frau  ...       massive Vorwürfe gegen ihre Vorgesetzten   \n",
       "832169           Kommando  ...              einen Antrag auf ihren Ausschluss   \n",
       "832170            Konzern  ...                                eine Liquidität   \n",
       "832171  Verkehrsaufkommen  ...                          das Verkehrsaufkommen   \n",
       "832172          Lufthansa  ...                               möglichst gering   \n",
       "\n",
       "        arg2_start arg2_end  arg2_pos          arg2_head arg2_head_start  \\\n",
       "0                0       43        $.                  .             143   \n",
       "1               94      139         N         Hoffnungen              98   \n",
       "2               90      127         N      Polarisierung             105   \n",
       "3               81      105         N         Kurzarbeit              85   \n",
       "4                8       29         N           Fussball               8   \n",
       "...            ...      ...       ...                ...             ...   \n",
       "832168          20       60         N           Vorwürfe              28   \n",
       "832169         191      224         N             Antrag             197   \n",
       "832170          32       47         N         Liquidität              37   \n",
       "832171          20       41         N  Verkehrsaufkommen              24   \n",
       "832172         108      124       ADV             gering             118   \n",
       "\n",
       "       arg2_head_end  rel_type  \\\n",
       "0                144   neutral   \n",
       "1                108   neutral   \n",
       "2                118   neutral   \n",
       "3                 95       pro   \n",
       "4                 16   neutral   \n",
       "...              ...       ...   \n",
       "832168            36   neutral   \n",
       "832169           203   neutral   \n",
       "832170            47       con   \n",
       "832171            41       con   \n",
       "832172           124   neutral   \n",
       "\n",
       "                                                                                                            pred_serial  \\\n",
       "0           Predicate(type='neutral', args=(Head(sentence=6, token=1), Head(sentence=6, token=-1)), strength=0, verb=4)   \n",
       "1       Predicate(type='neutral', args=(Head(sentence=18, token=13), Head(sentence=18, token=15)), strength=0, verb=20)   \n",
       "2       Predicate(type='neutral', args=(Head(sentence=10, token=-1), Head(sentence=10, token=20)), strength=0, verb=21)   \n",
       "3            Predicate(type='pro', args=(Head(sentence=12, token=0), Head(sentence=12, token=13)), strength=0, verb=11)   \n",
       "4          Predicate(type='neutral', args=(Head(sentence=10, token=8), Head(sentence=10, token=3)), strength=0, verb=6)   \n",
       "...                                                                                                                 ...   \n",
       "832168     Predicate(type='neutral', args=(Head(sentence=13, token=2), Head(sentence=13, token=5)), strength=0, verb=1)   \n",
       "832169  Predicate(type='neutral', args=(Head(sentence=28, token=31), Head(sentence=28, token=34)), strength=0, verb=32)   \n",
       "832170        Predicate(type='con', args=(Head(sentence=19, token=1), Head(sentence=19, token=7)), strength=0, verb=13)   \n",
       "832171         Predicate(type='con', args=(Head(sentence=25, token=4), Head(sentence=25, token=4)), strength=0, verb=1)   \n",
       "832172   Predicate(type='neutral', args=(Head(sentence=13, token=1), Head(sentence=13, token=14)), strength=0, verb=16)   \n",
       "\n",
       "                                                                                                                                                                                                                        full_sentence_text  \n",
       "0                                                                                         Dass Alexis Tsipras jetzt abgestraft wurde , hat viel mit der angestauten Unzufriedenheit über die langen Jahre des Sparens und Darbens zu tun .  \n",
       "1                                                                                Wenn die Kreditgeber Athen nicht zusätzlichen Spielraum öffnen , wird auch die neue Regierung die Hoffnungen auf einen spürbaren Aufschwung enttäuschen .  \n",
       "2                                                Will er dem Land etwas Gutes tun , dann sollte er nicht nur Steuern senken , sondern auch die politische Polarisierung beenden , die das Klima in Griechenland zuletzt so vergiftet hat .  \n",
       "3                                                    Pajtim Kasami , Ermir Lenjani , Birama Ndoye und Mickael Facchinetti akzeptieren die Kurzarbeit nun doch , weshalb Sion-Präsident Christian Constantin die Entlassungen zurückzieht .  \n",
       "4                                                                                                                       ( dpa ) Fussball Neun Spieler entliess der FC Sion Mitte März , als die Corona-Krise den Schweizer Fussball traf .  \n",
       "...                                                                                                                                                                                                                                    ...  \n",
       "832168                                                                                                                                                                      Dann äussert Frau A massive Vorwürfe gegen ihre Vorgesetzten .  \n",
       "832169  Am 5. Dezember stellt der Chef der Abteilung Milizfeuerwehr und Zivilschutz Frau A vor die Wahl : Entweder trete sie per Ende des Jahres aus der Milizfeuerwehr aus , oder das Kommando stelle einen Antrag auf ihren Ausschluss .  \n",
       "832170                                                                                                                                          Der Konzern hatte im April noch eine Liquidität von gut vier Milliarden Euro ausgewiesen .  \n",
       "832171                                                                                                                                                       Seitdem belebt sich das Verkehrsaufkommen auf niedriger Basis jedoch wieder .  \n",
       "832172                                                                                            Die Lufthansa versucht verständlicherweise den Einfluss von Politikern und die damit einhergehenden Wünsche möglichst gering zu halten .  \n",
       "\n",
       "[832158 rows x 22 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3658cf",
   "metadata": {},
   "source": [
    "**How big is the problem of -1 in first span or a \".\" in the data?**\n",
    "\n",
    "The -1 does not exist. No problem currently.\n",
    "\n",
    "The \".\" is quite prevalent and strangely only occurrs in the neutral case. That's why a cleaning step was introduced below (see solution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d99919",
   "metadata": {},
   "source": [
    "**Clean dataset**\n",
    "\n",
    "1. As seen below we must remove the argument heads make sure we don't have any \".\" as arguments for the neutrals.\n",
    "2. We also want to remove the reflexive cases for the pronouns.\n",
    "3. Only include verbs that fulfill balancedness criteria, execute cell 17 & 18 for this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2448263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pro        6611\n",
       "neutral    5343\n",
       "con        3666\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dirty = df.copy(deep=True)\n",
    "df_dirty[\n",
    "#(df_dirty[\"arg1_head\"] == \".\")\n",
    "#|(df_dirty[\"arg2_head\"] == \".\")\n",
    "#|(df_dirty[\"arg2\"] == \".\")\n",
    "#|(df_dirty[\"arg2\"] == \".\")\n",
    "#(df_dirty[\"arg1_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_head_start\"] == -1)\n",
    "#|(df_dirty[\"arg2_head_start\"] == -1)\n",
    "(df_dirty[\"arg1\"] == df_dirty[\"arg2\"])\n",
    "& (df_dirty[\"full_sentence_text\"].str.contains(\"sich\")) # reflexive verbs, should be ignore?\n",
    "].rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cb4f9046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - include dotted (most likely with no target or other thing, or are these the -1 ones)\n",
    "mask = ~((df[\"arg1_head\"] == \".\")\n",
    "|(df[\"arg2_head\"] == \".\")\n",
    "|(df[\"arg2\"] == \".\")\n",
    "|(df[\"arg2\"] == \".\"))\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "\n",
    "# 2 - exclude reflexive\n",
    "mask = ~(df[\"arg1\"] == df[\"arg2\"])\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "# 3 - exclude balanced = ambiguous verbs.\n",
    "mask = (df[\"verb_lemma\"].isin(agreeable_verbs))\n",
    "\n",
    "df = df[mask]\n",
    "\n",
    "# 4 - exclude sents, where the arg1_head_start and arg2_head_start overlap (due to stancer data extraction)\n",
    "mask = ~(df[\"arg1_head_start\"] == df[\"arg2_head_start\"])\n",
    "\n",
    "df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9da3a49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral    304564\n",
       "pro         15049\n",
       "con         13386\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(agreeable_verbs))\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4841a",
   "metadata": {},
   "source": [
    "**Balance the dataset**\n",
    "\n",
    "Make sure that each class is represented equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2209164f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        13386\n",
       "neutral    13386\n",
       "pro        13386\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('rel_type')\n",
    "df = df.apply(lambda x: x.sample(df.size().min(), random_state=RANDOM_STATE).reset_index(drop=True))\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ca4beb17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        13386\n",
       "neutral    13386\n",
       "pro        13386\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(level=0, drop=True)\n",
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f0ceb",
   "metadata": {},
   "source": [
    "**Analyzing the verb distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "914c86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in /home/parallels/.local/lib/python3.10/site-packages (5.13.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/parallels/.local/lib/python3.10/site-packages (from plotly) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f8cbc8ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        verb_lemma  counts\n",
      "327        stellen    4213\n",
      "210         freuen    1758\n",
      "50       aufnehmen    1497\n",
      "213         gelten    1151\n",
      "322         sorgen    1003\n",
      "..             ...     ...\n",
      "316       schäumen       1\n",
      "289   phantasieren       1\n",
      "276      mutmassen       1\n",
      "273   missionieren       1\n",
      "238  ideologisiert       1\n",
      "\n",
      "[477 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def analyse_verb_frequency(df):\n",
    "    df_analysis = df.copy(deep=True)\n",
    "    df_analysis = df_analysis.groupby([\"verb_lemma\"]).size().reset_index(name=\"counts\")\n",
    "\n",
    "    # get a verb that is needed in the distribution\n",
    "    # print(df_analysis[df_analysis[\"counts\"] == 1][\"verb_lemma\"])\n",
    "    # the counts of the counts\n",
    "    # df_analysis = df_analysis.groupby([\"counts\"]).size().reset_index(name=\"count_counts\")\n",
    "    # print(len(df_analysis))\n",
    "\n",
    "    # generate a sufficient bin width\n",
    "    bin_width= 10\n",
    "    # here you can choose your rounding method, I've chosen math.ceil.\n",
    "    nbins = math.ceil((df_analysis[\"counts\"].max() - df_analysis[\"counts\"].min()) / bin_width)\n",
    "\n",
    "\n",
    "    fig = px.histogram(df_analysis, \n",
    "                       x=\"counts\", \n",
    "                       nbins=nbins,\n",
    "                       title=\"Verb Frequency over the number of verbs\", \n",
    "                       labels={'counts': 'Frequency of verbs'}\n",
    "                      ).update_layout(yaxis_title='Number of verbs')\n",
    "\n",
    "    # fig.show()\n",
    "\n",
    "    print(df_analysis.sort_values(by=\"counts\", ascending=False))\n",
    "    \n",
    "analyse_verb_frequency(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971464",
   "metadata": {},
   "source": [
    "**Option 1: Train-test-splitting**\n",
    "\n",
    "Only problem: We may have sentences within the same documents with multiple PAS that are split accross the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "95fb1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPLIT_MODE == \"CRITERIA_FREE\":\n",
    "    train, test_val = train_test_split(df, test_size=0.3, stratify=df[\"rel_type\"], random_state=RANDOM_STATE)\n",
    "    test, val = train_test_split(test_val, test_size=0.5, stratify=test_val[\"rel_type\"],random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df49ad4",
   "metadata": {},
   "source": [
    "**Option 2: Train-test-splitting**\n",
    "\n",
    "With respecting group distribution. Which means that all sentences $S_{1..N}$ from a document $A$ will either all be in the test set, all be in the validation set or all be in the training set. The reason for this is since it could happen that multiple PAS are detected within the same sentence and then the system is trained to one PAS and is evaluated on a completely different PAS, which is unfair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8b260e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPLIT_MODE==\"DOC_SPLIT\":\n",
    "    # preserve groups between sentences (in this case doc_id is safe enough)\n",
    "    splitter = GroupShuffleSplit(test_size=.30, n_splits=1, random_state=RANDOM_STATE)\n",
    "    split = splitter.split(df, groups=df['doc_id'])\n",
    "    train_inds, test_val_inds = next(split)\n",
    "\n",
    "    train = df.iloc[train_inds]\n",
    "    test_val = df.iloc[test_val_inds]\n",
    "\n",
    "    splitter = GroupShuffleSplit(test_size=.5, n_splits=1, random_state=RANDOM_STATE)\n",
    "    split = splitter.split(test_val, groups=test_val['doc_id'])\n",
    "    test_inds, val_inds = next(split)\n",
    "\n",
    "    test = test_val.iloc[test_inds]\n",
    "    val = test_val.iloc[val_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "860465d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "TRAIN: [1, 1, 3, 3, 3, 8, 8] TEST: [2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# a small test to see whether option no 2 achieves our goals.\n",
    "\n",
    "X = np.ones(shape=(10, 2))\n",
    "y = np.ones(shape=(10, 1))\n",
    "groups = np.array([1, 1, 2, 2, 2, 3, 3, 3, 8, 8])\n",
    "print(groups.shape)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=42)\n",
    "gss.get_n_splits()\n",
    "\n",
    "for train_idx, test_idx in gss.split(X, y, groups):\n",
    "    print(\"TRAIN:\", [groups[i] for i in train_idx], \"TEST:\", [groups[i] for i in test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b184a",
   "metadata": {},
   "source": [
    "## Hard-verb splitting\n",
    "\n",
    "To test generalisability we may want to split verbs by train and test set.\n",
    "\n",
    "**Solution**: We can simply use the group splitting argument on the verbs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708fcec",
   "metadata": {},
   "source": [
    "**Option 3: Train-test split with verb-splitting**\n",
    "\n",
    "This means that given a verb $V$, all sentences which contain that verb will either be in $T_{RAIN}$, $V_{ALID}$ or $T_{EST}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b97f4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SPLIT_MODE == \"LEMMA_SPLIT\":\n",
    "    # preserve groups between sentences (in this case verbs)\n",
    "    splitter = GroupShuffleSplit(test_size=.30, n_splits=1, random_state=RANDOM_STATE)\n",
    "    split = splitter.split(df, groups=df['verb_lemma'])\n",
    "    train_inds, test_val_inds = next(split)\n",
    "\n",
    "    train = df.iloc[train_inds]\n",
    "    test_val = df.iloc[test_val_inds]\n",
    "\n",
    "    test, val = train_test_split(test_val, test_size=0.5, stratify=test_val[\"rel_type\"],random_state=RANDOM_STATE)\n",
    "\n",
    "    #splitter = GroupShuffleSplit(test_size=.5, n_splits=1, random_state=RANDOM_STATE)\n",
    "    #split = splitter.split(test_val, groups=test_val['verb_lemma'])\n",
    "    #test_inds, val_inds = next(split)\n",
    "\n",
    "    #test = test_val.iloc[test_inds]\n",
    "    #val = test_val.iloc[val_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54f326",
   "metadata": {},
   "source": [
    "**Option 4: Split by synonymy**\n",
    "\n",
    "Possible idea: Maximally similar (homogenous) sets.\n",
    "E.g. [this](https://www.sciencedirect.com/science/article/abs/pii/S0925231209000046)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1c8a5e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = fasttext.load_model(FASTTEXT_MODEL_BIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ce5f06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def get_fasttext_word_embeddings(verbs):\n",
    "    # verb embeddings\n",
    "    vEmbs = [model[w] for w in verbs]\n",
    "    return vEmbs\n",
    "\n",
    "if SPLIT_MODE == \"SIMILARITY_SPLIT\":\n",
    "    rel_types = list(set(df.rel_type.to_list()))\n",
    "    for rt in rel_types[:1]:\n",
    "        sub_df = df[df.rel_type == rt].copy(deep=True)\n",
    "        print(len(sub_df))\n",
    "        verbs = list(set(sub_df.verb_lemma.to_list()))\n",
    "        verb_embeddings = get_fasttext_word_embeddings(verbs)\n",
    "        wd_arr = np.array(verb_embeddings).reshape(-1, 1)  # reshape to compute pairwise distance\n",
    "        distances = pairwise_distances(wd_arr, wd_arr, metric=\"euclidean\")  # pairwise distance matrix\n",
    "        print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c5aff8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0a23e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c18c9a",
   "metadata": {},
   "source": [
    "### Save to file\n",
    "\n",
    "Save the respective datasets to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "47ce16f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALUE COUNTS: train\n",
      "neutral    9407\n",
      "con        9385\n",
      "pro        9280\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: test\n",
      "pro        2071\n",
      "con        1967\n",
      "neutral    1966\n",
      "Name: rel_type, dtype: int64\n",
      "VALUE COUNTS: val\n",
      "pro        2035\n",
      "con        2034\n",
      "neutral    2013\n",
      "Name: rel_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"VALUE COUNTS: train\")\n",
    "print(train.rel_type.value_counts())\n",
    "train.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: test\")\n",
    "print(test.rel_type.value_counts())\n",
    "test.to_csv(TEST_DATA_PATH, index=False)\n",
    "\n",
    "print(\"VALUE COUNTS: val\")\n",
    "print(val.rel_type.value_counts())\n",
    "val.to_csv(VAL_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2915907",
   "metadata": {},
   "source": [
    "We verify that this worked using an overlap metric by checking whether the overlap is 0 with respect to all verbs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "51d5aaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fehlen',\n",
       " 'überschätzen',\n",
       " 'sträubte',\n",
       " 'abgewählt',\n",
       " 'widersetzte',\n",
       " 'bestraften',\n",
       " 'aufhören',\n",
       " 'kürte',\n",
       " 'versprechen',\n",
       " 'ausgetrickst',\n",
       " 'klaut',\n",
       " 'bittet',\n",
       " 'freuten',\n",
       " 'freut',\n",
       " 'benutzten',\n",
       " 'entschuldigten',\n",
       " 'verlieben',\n",
       " 'glänzen',\n",
       " 'geachtet',\n",
       " 'einhält',\n",
       " 'ermordet',\n",
       " 'tötet',\n",
       " 'erwerben',\n",
       " 'stöhnen',\n",
       " 'abzusehen',\n",
       " 'überzeugt',\n",
       " 'irritieren',\n",
       " 'beweise',\n",
       " 'weiss',\n",
       " 'verschärft',\n",
       " 'geworben',\n",
       " 'geniessen',\n",
       " 'haut',\n",
       " 'versprochen',\n",
       " 'überfiel',\n",
       " 'behinderte',\n",
       " 'gebrochen',\n",
       " 'aufhebt',\n",
       " 'verstand',\n",
       " 'korrigiert',\n",
       " 'raubte',\n",
       " 'brechen',\n",
       " 'bestraft',\n",
       " 'belügen',\n",
       " 'erntete',\n",
       " 'bedankt',\n",
       " 'darstelle',\n",
       " 'einschränke',\n",
       " 'behandeln',\n",
       " 'eingetreten',\n",
       " 'abzustrafen',\n",
       " 'umgeht',\n",
       " 'hetzte',\n",
       " 'übergehen',\n",
       " 'brillierte',\n",
       " 'bewirken',\n",
       " 'lügen',\n",
       " 'gequält',\n",
       " 'brilliert',\n",
       " 'aufnahm',\n",
       " 'propagiert',\n",
       " 'geschwärmt',\n",
       " 'loszuwerden',\n",
       " 'angepriesen',\n",
       " 'versucht',\n",
       " 'plädieren',\n",
       " 'steigern',\n",
       " 'vorschreiben',\n",
       " 'wehren',\n",
       " 'geniesst',\n",
       " 'rühmt',\n",
       " 'anpreist',\n",
       " 'benutze',\n",
       " 'verantworten',\n",
       " 'ergötzen',\n",
       " 'zittern',\n",
       " 'genutzt',\n",
       " 'entstehe',\n",
       " 'gestellt',\n",
       " 'erlitten',\n",
       " 'brach',\n",
       " 'entschuldigen',\n",
       " 'erzwingen',\n",
       " 'gesorgt',\n",
       " 'benutzte',\n",
       " 'solidarisieren',\n",
       " 'offenbaren',\n",
       " 'eingebracht',\n",
       " 'anprangert',\n",
       " 'triumphieren',\n",
       " 'erreichte',\n",
       " 'gewannen',\n",
       " 'beharrt',\n",
       " 'missfiel',\n",
       " 'eintraten',\n",
       " 'aufzugeben',\n",
       " 'bestreiten',\n",
       " 'belächelt',\n",
       " 'beherrschen',\n",
       " 'behandelte',\n",
       " 'ausgelöscht',\n",
       " 'pfeift',\n",
       " 'abwählen',\n",
       " 'missfällt',\n",
       " 'erzielen',\n",
       " 'klagen',\n",
       " 'irritierten',\n",
       " 'verzweifelte',\n",
       " 'ergötzte',\n",
       " 'irritierte',\n",
       " 'zurückzuweisen',\n",
       " 'besänftigen',\n",
       " 'verhaften',\n",
       " 'hauten',\n",
       " 'tötete',\n",
       " 'herunterzuspielen',\n",
       " 'sorgten',\n",
       " 'entschärft',\n",
       " 'möchte',\n",
       " 'wehrten',\n",
       " 'erkrankt',\n",
       " 'verantwortete',\n",
       " 'lahmgelegt',\n",
       " 'verschleiern',\n",
       " 'entfernte',\n",
       " 'verhaftet',\n",
       " 'auszutreten',\n",
       " 'überfallen',\n",
       " 'überzeugte',\n",
       " 'versperrte',\n",
       " 'verhafteten',\n",
       " 'anzeigten',\n",
       " 'entschädigen',\n",
       " 'warnen',\n",
       " 'bewahren',\n",
       " 'wagt',\n",
       " 'begangen',\n",
       " 'trickste',\n",
       " 'unternahm',\n",
       " 'aufgegeben',\n",
       " 'angezeigt',\n",
       " 'mag',\n",
       " 'ausgeht',\n",
       " 'feuern',\n",
       " 'widmete',\n",
       " 'gängeln',\n",
       " 'haute',\n",
       " 'sträubt',\n",
       " 'spuckt',\n",
       " 'darstellt',\n",
       " 'deportieren',\n",
       " 'unterliegen',\n",
       " 'abzuschirmen',\n",
       " 'schiesst',\n",
       " 'qualifiziert',\n",
       " 'abzuwählen',\n",
       " 'verhindere',\n",
       " 'heimsuchen',\n",
       " 'umzugehen',\n",
       " 'eingesetzt',\n",
       " 'wettmachen',\n",
       " 'einsetzt',\n",
       " 'widmet',\n",
       " 'schont',\n",
       " 'stritten',\n",
       " 'gewidmet',\n",
       " 'aufnehme',\n",
       " 'zurückweisen',\n",
       " 'entstand',\n",
       " 'verhinderten',\n",
       " 'begeht',\n",
       " 'verbündeten',\n",
       " 'angegeben',\n",
       " 'lernten',\n",
       " 'abzuzielen',\n",
       " 'stürzen',\n",
       " 'verpassen',\n",
       " 'verpassten',\n",
       " 'geniesse',\n",
       " 'befürchtet',\n",
       " 'beherrscht',\n",
       " 'dienen',\n",
       " 'birgt',\n",
       " 'gegönnt',\n",
       " 'jammern',\n",
       " 'kürt',\n",
       " 'siegte',\n",
       " 'verfüge',\n",
       " 'abnehmen',\n",
       " 'rechtfertigte',\n",
       " 'verbuchte',\n",
       " 'gescheitert',\n",
       " 'konsterniert',\n",
       " 'lahmzulegen',\n",
       " 'anzuklagen',\n",
       " 'besticht',\n",
       " 'bezeichneten',\n",
       " 'beitragen',\n",
       " 'plädiere',\n",
       " 'gefeuert',\n",
       " 'verüben',\n",
       " 'abstrafen',\n",
       " 'beschwerten',\n",
       " 'siegten',\n",
       " 'erobern',\n",
       " 'scheiterten',\n",
       " 'gelitten',\n",
       " 'festlegte',\n",
       " 'zulegen',\n",
       " 'entstehen',\n",
       " 'auszusprechen',\n",
       " 'entlassen',\n",
       " 'explodiert',\n",
       " 'anpassen',\n",
       " 'entwischt',\n",
       " 'wirbt',\n",
       " 'opfern',\n",
       " 'reklamierten',\n",
       " 'zutrauen',\n",
       " 'gewusst',\n",
       " 'verstehe',\n",
       " 'wagen',\n",
       " 'stürze',\n",
       " 'zugeben',\n",
       " 'avancierten',\n",
       " 'abzutun',\n",
       " 'gestatten',\n",
       " 'wiederzubeleben',\n",
       " 'drängt',\n",
       " 'nutzte',\n",
       " 'verlor',\n",
       " 'fingieren',\n",
       " 'abtat',\n",
       " 'prägte',\n",
       " 'zerstörte',\n",
       " 'diskreditieren',\n",
       " 'bewirkt',\n",
       " 'erbat',\n",
       " 'gefreut',\n",
       " 'anstrengen',\n",
       " 'stürzte',\n",
       " 'betrügt',\n",
       " 'benötige',\n",
       " 'bedanken',\n",
       " 'stellte',\n",
       " 'enttäuschen',\n",
       " 'überwachen',\n",
       " 'schwärmt',\n",
       " 'darbt',\n",
       " 'ausgezeichnet',\n",
       " 'explodieren',\n",
       " 'anzeigen',\n",
       " 'begingen',\n",
       " 'wundern',\n",
       " 'geklärt',\n",
       " 'verdammen',\n",
       " 'nachgewiesen',\n",
       " 'schonten',\n",
       " 'hetzt',\n",
       " 'vergeht',\n",
       " 'ausnutzen',\n",
       " 'nachgegeben',\n",
       " 'profitierten',\n",
       " 'verschweigen',\n",
       " 'sorge',\n",
       " 'vorschlagen',\n",
       " 'überrumpeln',\n",
       " 'unterdrückt',\n",
       " 'eingehalten',\n",
       " 'töte',\n",
       " 'bedankte',\n",
       " 'bitte',\n",
       " 'plädiert',\n",
       " 'verschlimmern',\n",
       " 'sehnten',\n",
       " 'verfehlen',\n",
       " 'übergangen',\n",
       " 'gesträubt',\n",
       " 'gelte',\n",
       " 'gekürt',\n",
       " 'benutzen',\n",
       " 'bezeichnete',\n",
       " 'bezeichnet',\n",
       " 'gewarnt',\n",
       " 'bricht',\n",
       " 'jubelten',\n",
       " 'verdiente',\n",
       " 'verfügten',\n",
       " 'beschützt',\n",
       " 'diffamieren',\n",
       " 'eskaliert',\n",
       " 'streitet',\n",
       " 'kümmert',\n",
       " 'verliere',\n",
       " 'pfiffen',\n",
       " 'überleben',\n",
       " 'aufgeklärt',\n",
       " 'krankt',\n",
       " 'beeindrucken',\n",
       " 'versichert',\n",
       " 'heimsuchte',\n",
       " 'bewältigt',\n",
       " 'unterdrücken',\n",
       " 'flüchtete',\n",
       " 'bergen',\n",
       " 'zurückhalten',\n",
       " 'verzweifelt',\n",
       " 'tobte',\n",
       " 'entfernten',\n",
       " 'überstrapaziert',\n",
       " 'einstehen',\n",
       " 'festzulegen',\n",
       " 'äussert',\n",
       " 'gewonnen',\n",
       " 'einlenken',\n",
       " 'versichern',\n",
       " 'einzuhalten',\n",
       " 'möge',\n",
       " 'gesiegt',\n",
       " 'beweist',\n",
       " 'ergattern',\n",
       " 'erschwere',\n",
       " 'jubeln',\n",
       " 'verlieren',\n",
       " 'klagte',\n",
       " 'kriminalisiert',\n",
       " 'brüsten',\n",
       " 'siegen',\n",
       " 'schiessen',\n",
       " 'benachteiligt',\n",
       " 'streiten',\n",
       " 'umsorgt',\n",
       " 'befürchteten',\n",
       " 'quälen',\n",
       " 'überzeugen',\n",
       " 'bestritt',\n",
       " 'sträuben',\n",
       " 'vorgeben',\n",
       " 'eroberte',\n",
       " 'dient',\n",
       " 'befrieden',\n",
       " 'bestaunt',\n",
       " 'lähmt',\n",
       " 'verliert',\n",
       " 'erreichten',\n",
       " 'totgeschwiegen',\n",
       " 'zugesichert',\n",
       " 'traue',\n",
       " 'einsetzen',\n",
       " 'gestehen',\n",
       " 'vergingen',\n",
       " 'abfertigen',\n",
       " 'gefürchtet',\n",
       " 'tobt',\n",
       " 'nutzen',\n",
       " 'zurückwies',\n",
       " 'abschaffte',\n",
       " 'verbrüdert',\n",
       " 'vergeben',\n",
       " 'klären',\n",
       " 'bewiesen',\n",
       " 'erreiche',\n",
       " 'beschimpft',\n",
       " 'warnten',\n",
       " 'abgenommen',\n",
       " 'töten',\n",
       " 'gälte',\n",
       " 'abtaten',\n",
       " 'überfällt',\n",
       " 'überlebte',\n",
       " 'ausharren',\n",
       " 'solidarisierte',\n",
       " 'bezeichnen',\n",
       " 'widmen',\n",
       " 'unterschätzt',\n",
       " 'diskreditiert',\n",
       " 'bestachen',\n",
       " 'beharrte',\n",
       " 'ausspielen',\n",
       " 'mahnten',\n",
       " 'unterschätzen',\n",
       " 'prägen',\n",
       " 'warnte',\n",
       " 'fänden',\n",
       " 'benutzt',\n",
       " 'angezweifelt',\n",
       " 'belohnt',\n",
       " 'anzupreisen',\n",
       " 'siegt',\n",
       " 'erfreute',\n",
       " 'verachtet',\n",
       " 'scheitert',\n",
       " 'ausgenutzt',\n",
       " 'triumphierten',\n",
       " 'kürten',\n",
       " 'verachten',\n",
       " 'anrichten',\n",
       " 'flüchten',\n",
       " 'freute',\n",
       " 'bewahrte',\n",
       " 'beibehalten',\n",
       " 'plädierten',\n",
       " 'verstanden',\n",
       " 'aufarbeiten',\n",
       " 'schiesse',\n",
       " 'fürchtete',\n",
       " 'belangt',\n",
       " 'diskriminiert',\n",
       " 'anheizen',\n",
       " 'feuerte',\n",
       " 'fehlt',\n",
       " 'zerbrechen',\n",
       " 'gejubelt',\n",
       " 'propagierte',\n",
       " 'vergessen',\n",
       " 'getötet',\n",
       " 'einsetzte',\n",
       " 'Ermordet',\n",
       " 'dargestellt',\n",
       " 'entsetzt',\n",
       " 'abgestraft',\n",
       " 'missfielen',\n",
       " 'aushöhlen',\n",
       " 'glänzt',\n",
       " 'appelliert',\n",
       " 'entschärfte',\n",
       " 'verletzten',\n",
       " 'anzufangen',\n",
       " 'feuert',\n",
       " 'verwarnen',\n",
       " 'mochten',\n",
       " 'verklagte',\n",
       " 'aufwiesen',\n",
       " 'hingenommen',\n",
       " 'bestrafe',\n",
       " 'verübt',\n",
       " 'gefunden',\n",
       " 'zurückgehalten',\n",
       " 'lösen',\n",
       " 'austrat',\n",
       " 'drängte',\n",
       " 'gelten',\n",
       " 'benötigen',\n",
       " 'wussten',\n",
       " 'fernhalten',\n",
       " 'aufzuarbeiten',\n",
       " 'schonte',\n",
       " 'überstrapaziere',\n",
       " 'verstören',\n",
       " 'einhalten',\n",
       " 'abgefertigt',\n",
       " 'verhindern',\n",
       " 'abgebrochen',\n",
       " 'erstarrt',\n",
       " 'saniert',\n",
       " 'wissen',\n",
       " 'erpresst',\n",
       " 'verdient',\n",
       " 'gezogen',\n",
       " 'ermordete',\n",
       " 'beschützen',\n",
       " 'vergehen',\n",
       " 'fernzuhalten',\n",
       " 'wirke',\n",
       " 'Abgesehen',\n",
       " 'widersetzten',\n",
       " 'rechtfertigt',\n",
       " 'standgehalten',\n",
       " 'jammerte',\n",
       " 'rühmten',\n",
       " 'ausbauen',\n",
       " 'enttäuscht',\n",
       " 'bekennt',\n",
       " 'eskalierten',\n",
       " 'entsteht',\n",
       " 'scheiterte',\n",
       " 'ermordeten',\n",
       " 'wettzumachen',\n",
       " 'geschont',\n",
       " 'verfügt',\n",
       " 'verzweifeln',\n",
       " 'überwinden',\n",
       " 'auszuhalten',\n",
       " 'erregten',\n",
       " 'profitierte',\n",
       " 'aushalten',\n",
       " 'verliebte',\n",
       " 'zerstöre',\n",
       " 'widme',\n",
       " 'solidarisierten',\n",
       " 'beschweren',\n",
       " 'verging',\n",
       " 'hinwegzusehen',\n",
       " 'stellt',\n",
       " 'kümmern',\n",
       " 'gehetzt',\n",
       " 'gönne',\n",
       " 'flüchteten',\n",
       " 'entliess',\n",
       " 'fürchte',\n",
       " 'sträubten',\n",
       " 'beschwerte',\n",
       " 'galten',\n",
       " 'bestochen',\n",
       " 'eintritt',\n",
       " 'haften',\n",
       " 'abgetan',\n",
       " 'verkraften',\n",
       " 'hetzen',\n",
       " 'wiederbeleben',\n",
       " 'erzielt',\n",
       " 'vorschreibt',\n",
       " 'aufgearbeitet',\n",
       " 'quält',\n",
       " 'ausbaut',\n",
       " 'überrumpelt',\n",
       " 'behindert',\n",
       " 'freuen',\n",
       " 'löste',\n",
       " 'zurückweise',\n",
       " 'erregt',\n",
       " 'spucken',\n",
       " 'widersetzt',\n",
       " 'gedient',\n",
       " 'versteht',\n",
       " 'beizubehalten',\n",
       " 'aufnimmt',\n",
       " 'profitiere',\n",
       " 'infiziert',\n",
       " 'überging',\n",
       " 'verpflichtet',\n",
       " 'unterstellte',\n",
       " 'verträgt',\n",
       " 'ergötzt',\n",
       " 'bestritten',\n",
       " 'inhaftiert',\n",
       " 'einschläfern',\n",
       " 'schockt',\n",
       " 'schwärmen',\n",
       " 'verbucht',\n",
       " 'entgegengekommen',\n",
       " 'heimgesucht',\n",
       " 'freue',\n",
       " 'übertreibt',\n",
       " 'behandelt',\n",
       " 'bereitet',\n",
       " 'wehrt',\n",
       " 'angeben',\n",
       " 'diskriminiere',\n",
       " 'verloren',\n",
       " 'steigert',\n",
       " 'jubelte',\n",
       " 'befördern',\n",
       " 'unterstellten',\n",
       " 'galt',\n",
       " 'erfreuten',\n",
       " 'befriedet',\n",
       " 'beeindruckt',\n",
       " 'finde',\n",
       " 'verwarnte',\n",
       " 'schonen',\n",
       " 'gönnte',\n",
       " 'aufnahmen',\n",
       " 'vorgeschrieben',\n",
       " 'zerstörten',\n",
       " 'behindere',\n",
       " 'auslöschte',\n",
       " 'benötigte',\n",
       " 'bürgt',\n",
       " 'erfreuen',\n",
       " 'solidarisiert',\n",
       " 'flohen',\n",
       " 'bestrafen',\n",
       " 'rechtfertigen',\n",
       " 'entschärfen',\n",
       " 'aufheben',\n",
       " 'unterliegt',\n",
       " 'entgegenzukommen',\n",
       " 'fehle',\n",
       " 'überwunden',\n",
       " 'erkranken',\n",
       " 'achtete',\n",
       " 'entfernen',\n",
       " 'getäuscht',\n",
       " 'sicherzustellen',\n",
       " 'verschlimmerten',\n",
       " 'klagten',\n",
       " 'wüten',\n",
       " 'werben',\n",
       " 'bereiteten',\n",
       " 'stellten',\n",
       " 'abbrach',\n",
       " 'propagieren',\n",
       " 'entliessen',\n",
       " 'suggeriert',\n",
       " 'dominieren',\n",
       " 'haftet',\n",
       " 'fürchteten',\n",
       " 'angefangen',\n",
       " 'zurückzuerobern',\n",
       " 'verbünden',\n",
       " 'besänftigt',\n",
       " 'Stellt',\n",
       " 'abgeschafft',\n",
       " 'verachteten',\n",
       " 'gratuliert',\n",
       " 'befriedigen',\n",
       " 'erzwang',\n",
       " 'entmachtete',\n",
       " 'nachgibt',\n",
       " 'bedankten',\n",
       " 'erziele',\n",
       " 'verletzt',\n",
       " 'wirkt',\n",
       " 'rühmte',\n",
       " 'gewinnt',\n",
       " 'erntet',\n",
       " 'unternimmt',\n",
       " 'auszubauen',\n",
       " 'löst',\n",
       " 'ausgrenzen',\n",
       " 'ertragen',\n",
       " 'verhindert',\n",
       " 'einhalte',\n",
       " 'übergeht',\n",
       " 'zöge',\n",
       " 'äusserst',\n",
       " 'verbuchen',\n",
       " 'abdriftet',\n",
       " 'gedrängt',\n",
       " 'triumphierte',\n",
       " 'konfrontiert',\n",
       " 'zugegeben',\n",
       " 'nachtrauern',\n",
       " 'Schiesst',\n",
       " 'anzuzeigen',\n",
       " 'dominierte',\n",
       " 'mahnte',\n",
       " 'darstellen',\n",
       " 'sehnte',\n",
       " 'befördert',\n",
       " 'erzeugte',\n",
       " 'erzielte',\n",
       " 'erlitt',\n",
       " 'lösten',\n",
       " 'aufgeben',\n",
       " 'stöhnt',\n",
       " 'überwacht',\n",
       " 'vertraue',\n",
       " 'verbündete',\n",
       " 'erwarb',\n",
       " 'einbringen',\n",
       " 'zogen',\n",
       " 'bitten',\n",
       " 'abzuschiessen',\n",
       " 'versicherte',\n",
       " 'beschert',\n",
       " 'mögen',\n",
       " 'litt',\n",
       " 'verletzte',\n",
       " 'auslöschen',\n",
       " 'entmachten',\n",
       " 'unterlagen',\n",
       " 'verlernt',\n",
       " 'aufgenommen',\n",
       " 'versagt',\n",
       " 'gälten',\n",
       " 'erleidet',\n",
       " 'hüten',\n",
       " 'haust',\n",
       " 'dominierten',\n",
       " 'aufzuheben',\n",
       " 'riskieren',\n",
       " 'jammerten',\n",
       " 'verschleiert',\n",
       " 'wusste',\n",
       " 'nannten',\n",
       " 'einzutreten',\n",
       " 'fand',\n",
       " 'bemüht',\n",
       " 'unternommen',\n",
       " 'abbricht',\n",
       " 'bestechen',\n",
       " 'loswerden',\n",
       " 'einzuschränken',\n",
       " 'aufweisen',\n",
       " 'abzurechnen',\n",
       " 'verfehlte',\n",
       " 'warben',\n",
       " 'aufweist',\n",
       " 'beschwert',\n",
       " 'abschaffen',\n",
       " 'hauen',\n",
       " 'eingeräumt',\n",
       " 'äusserte',\n",
       " 'geborgen',\n",
       " 'verspreche',\n",
       " 'nachgeben',\n",
       " 'zieren',\n",
       " 'beizulegen',\n",
       " 'propagiere',\n",
       " 'täuschen',\n",
       " 'kriecht',\n",
       " 'verspricht',\n",
       " 'verletze',\n",
       " 'finden',\n",
       " 'verschlechtert',\n",
       " 'zögen',\n",
       " 'behauptet',\n",
       " 'überschätzt',\n",
       " 'findet',\n",
       " 'verwarnt',\n",
       " 'abschiessen',\n",
       " 'entlässt',\n",
       " 'lernen',\n",
       " 'nutzt',\n",
       " 'betrogen',\n",
       " 'festgelegt',\n",
       " 'stürzten',\n",
       " 'eingelenkt',\n",
       " 'angerichtet',\n",
       " 'mochte',\n",
       " 'vertuschen',\n",
       " 'aussitzen',\n",
       " 'dienten',\n",
       " 'aufwies',\n",
       " 'glänzte',\n",
       " 'betrog',\n",
       " 'beweisen',\n",
       " 'nominieren',\n",
       " 'verwundet',\n",
       " 'lechzt',\n",
       " 'gewinne',\n",
       " 'ferngehalten',\n",
       " 'sicherstellen',\n",
       " 'erkrankten',\n",
       " 'ausgesprochen',\n",
       " 'unterwerfen',\n",
       " 'erschüttert',\n",
       " 'aufgehoben',\n",
       " 'verschlimmert',\n",
       " 'vorgibt',\n",
       " 'warb',\n",
       " 'reüssierte',\n",
       " 'missfallen',\n",
       " 'stürzt',\n",
       " 'zurückzuhalten',\n",
       " 'stelle',\n",
       " 'einzudämmen',\n",
       " 'enttäuschten',\n",
       " 'verklagten',\n",
       " 'auskommen',\n",
       " 'vorzuschreiben',\n",
       " 'unterstellt',\n",
       " 'verschärfen',\n",
       " 'fürchten',\n",
       " 'beilegen',\n",
       " 'bestreitet',\n",
       " 'geschossen',\n",
       " 'mahnt',\n",
       " 'eingeschränkt',\n",
       " 'entschädigte',\n",
       " 'erregte',\n",
       " 'unterstellen',\n",
       " 'überschätzten',\n",
       " 'aufzunehmen',\n",
       " 'anzupassen',\n",
       " 'zusichern',\n",
       " 'rühmen',\n",
       " 'behinderten',\n",
       " 'erschütterte',\n",
       " 'verbürgt',\n",
       " 'küren',\n",
       " 'beibehält',\n",
       " 'vertraute',\n",
       " 'wirkten',\n",
       " 'hinnehmen',\n",
       " 'aufklären',\n",
       " 'diffamierte',\n",
       " 'reüssieren',\n",
       " 'anzweifelte',\n",
       " 'wegfallen',\n",
       " 'verschärfe',\n",
       " 'lahmlegen',\n",
       " 'verpflichten',\n",
       " 'toben',\n",
       " 'leidet',\n",
       " 'zog',\n",
       " 'fürchtet',\n",
       " 'gewundert',\n",
       " 'wiederbelebt',\n",
       " 'aufhört',\n",
       " 'versperrt',\n",
       " 'stellen',\n",
       " 'anfangen',\n",
       " 'flüchtet',\n",
       " 'brüstet',\n",
       " 'übertrieben',\n",
       " 'spuckte',\n",
       " 'avancierte',\n",
       " 'beschimpfen',\n",
       " 'schwärmte',\n",
       " 'vertrage',\n",
       " 'klaute',\n",
       " 'auszunutzen',\n",
       " 'bewahrt',\n",
       " 'ausgetreten',\n",
       " 'anklagen',\n",
       " 'kriminalisieren',\n",
       " 'beschimpfte',\n",
       " 'vorgaukelt',\n",
       " 'vorgeschlagen',\n",
       " 'erpressen',\n",
       " 'stritt',\n",
       " 'korrigieren',\n",
       " 'aufnehmen',\n",
       " 'austraten',\n",
       " 'brachen',\n",
       " 'vertraut',\n",
       " 'einsetze',\n",
       " 'zurückgewiesen',\n",
       " 'absieht',\n",
       " 'diskriminieren',\n",
       " 'unterdrückte',\n",
       " 'zurückwiesen',\n",
       " 'abzuschaffen',\n",
       " 'ausbügeln',\n",
       " 'verpasste',\n",
       " 'abgesehen',\n",
       " 'verklagt',\n",
       " 'avanciert',\n",
       " 'vertrauen',\n",
       " 'gestand',\n",
       " 'gestanden',\n",
       " 'gewann',\n",
       " 'entstanden',\n",
       " 'nominiert',\n",
       " 'abtun',\n",
       " 'schossen',\n",
       " 'wütete',\n",
       " 'gönnt',\n",
       " 'beschimpften',\n",
       " 'aufpassen',\n",
       " 'verklagen',\n",
       " 'bekennen',\n",
       " 'plädierte',\n",
       " 'aussprechen',\n",
       " 'drängen',\n",
       " 'vertrösten',\n",
       " 'täuscht',\n",
       " 'erzeugt',\n",
       " 'verhaftete',\n",
       " 'mithilft',\n",
       " 'hütet',\n",
       " 'erreicht',\n",
       " 'gerühmt',\n",
       " 'schoss',\n",
       " 'versperren',\n",
       " 'verbündet',\n",
       " 'auszulöschen',\n",
       " 'verfügen',\n",
       " 'appellierte',\n",
       " 'sehnen',\n",
       " 'gönnen',\n",
       " 'genannt',\n",
       " 'verhinderte',\n",
       " 'erleiden',\n",
       " 'schlichten',\n",
       " 'verachte',\n",
       " 'geprägt',\n",
       " 'möchten',\n",
       " 'einschränkt',\n",
       " 'mahnen',\n",
       " 'vertrauten',\n",
       " 'umgehen',\n",
       " 'dominiert',\n",
       " 'erkrankte',\n",
       " 'zugelegt',\n",
       " 'zerbricht',\n",
       " 'ausgegrenzt',\n",
       " 'beizutragen',\n",
       " 'abgerechnet',\n",
       " 'löse',\n",
       " 'nutzten',\n",
       " 'unterlag',\n",
       " 'gefoltert',\n",
       " 'achten',\n",
       " 'pfiff',\n",
       " 'Freut',\n",
       " 'vergibt',\n",
       " 'versagen',\n",
       " 'traut',\n",
       " 'festlegen',\n",
       " 'verpflichtete',\n",
       " 'überlebt',\n",
       " 'belog',\n",
       " 'gilt',\n",
       " 'überrumpelte',\n",
       " 'verletzen',\n",
       " 'Enttäuscht',\n",
       " 'ausgebaut',\n",
       " 'belohnte',\n",
       " 'anzuprangern',\n",
       " 'fliehen',\n",
       " 'angeklagt',\n",
       " 'vortäuschen',\n",
       " 'ziehen',\n",
       " 'sehnt',\n",
       " 'übertreibe',\n",
       " 'gewinnen',\n",
       " 'entgegenkommen',\n",
       " 'eintrat',\n",
       " 'leiden',\n",
       " 'diffamiert',\n",
       " 'angeprangert',\n",
       " 'gelernt',\n",
       " 'floh',\n",
       " 'anprangern',\n",
       " 'entschuldige',\n",
       " 'fehlte',\n",
       " 'profitiert',\n",
       " 'verbrüdern',\n",
       " 'diente',\n",
       " 'durchgemacht',\n",
       " 'zurücktreten',\n",
       " 'verschlimmere',\n",
       " 'nennen',\n",
       " 'sträube',\n",
       " 'absehen',\n",
       " 'befürchten',\n",
       " 'überzeugten',\n",
       " 'sorgen',\n",
       " 'gebeten',\n",
       " 'lahmlegt',\n",
       " 'gemahnt',\n",
       " 'sorgt',\n",
       " 'angepasst',\n",
       " 'Angeklagt',\n",
       " 'einzustehen',\n",
       " 'einzusetzen',\n",
       " 'bewältigen',\n",
       " 'ausgehen',\n",
       " 'entfernt',\n",
       " 'bereiten',\n",
       " 'abgeschossen',\n",
       " 'beigetragen',\n",
       " 'austreten',\n",
       " 'explodierte',\n",
       " 'erregen',\n",
       " 'verlockt',\n",
       " 'wundert',\n",
       " 'anzeigt',\n",
       " 'eskalierte',\n",
       " 'sorgte',\n",
       " 'entgegenkommt',\n",
       " 'verstehen',\n",
       " 'verdienen',\n",
       " 'überzeichnet',\n",
       " 'eskalieren',\n",
       " 'benötigten',\n",
       " 'unternehmen',\n",
       " 'verzweifelten',\n",
       " 'erstickt',\n",
       " 'ermorden',\n",
       " 'verschlimmerte',\n",
       " 'profitieren',\n",
       " 'einräumen',\n",
       " 'verstört',\n",
       " 'erworben',\n",
       " 'geklagt',\n",
       " 'bewies',\n",
       " 'verliebt',\n",
       " 'versagte',\n",
       " 'vertragen',\n",
       " 'gegolten',\n",
       " 'begehen',\n",
       " 'erschwert',\n",
       " 'beharren',\n",
       " 'zerstört',\n",
       " 'geflohen',\n",
       " 'schuften',\n",
       " 'erschweren',\n",
       " 'eintreten',\n",
       " 'scheitern',\n",
       " 'trauen',\n",
       " 'enttäuschte',\n",
       " 'punkten',\n",
       " 'anlastet',\n",
       " 'prägt',\n",
       " 'verfügte',\n",
       " 'raubt',\n",
       " 'beherrsche',\n",
       " 'eroberten',\n",
       " 'nachweist',\n",
       " 'vorrückt',\n",
       " 'gesteht',\n",
       " 'pfeifen',\n",
       " 'einschränken',\n",
       " 'nennt',\n",
       " 'entschuldigt',\n",
       " ...]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overlap /w regards to verbform\n",
    "train_verbs = train.verb_form.to_list()\n",
    "val_test_verbs = val.verb_form.to_list() + test.verb_form.to_list()\n",
    "list(set(train_verbs) & set(val_test_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "11043f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fehlen',\n",
       " 'überschätzen',\n",
       " 'aufhören',\n",
       " 'misslingen',\n",
       " 'versprechen',\n",
       " 'rentieren',\n",
       " 'verlieben',\n",
       " 'glänzen',\n",
       " 'erwerben',\n",
       " 'stöhnen',\n",
       " 'irritieren',\n",
       " 'entheben',\n",
       " 'durchhalten',\n",
       " 'brechen',\n",
       " 'belügen',\n",
       " 'benachteiligen',\n",
       " 'behandeln',\n",
       " 'übergehen',\n",
       " 'bewirken',\n",
       " 'lügen',\n",
       " 'umkommen',\n",
       " 'plädieren',\n",
       " 'infizieren',\n",
       " 'steigern',\n",
       " 'vorschreiben',\n",
       " 'wehren',\n",
       " 'verwechseln',\n",
       " 'reklamieren',\n",
       " 'verantworten',\n",
       " 'ergötzen',\n",
       " 'zittern',\n",
       " 'hinwegsehen',\n",
       " 'entschuldigen',\n",
       " 'erzwingen',\n",
       " 'solidarisieren',\n",
       " 'umsorgen',\n",
       " 'offenbaren',\n",
       " 'triumphieren',\n",
       " 'bestreiten',\n",
       " 'beherrschen',\n",
       " 'avancieren',\n",
       " 'abwählen',\n",
       " 'erzielen',\n",
       " 'klagen',\n",
       " 'besänftigen',\n",
       " 'verhaften',\n",
       " 'darben',\n",
       " 'verschleiern',\n",
       " 'überfallen',\n",
       " 'entschädigen',\n",
       " 'warnen',\n",
       " 'bewahren',\n",
       " 'vorhalten',\n",
       " 'bürgen',\n",
       " 'feuern',\n",
       " 'verwunden',\n",
       " 'verbürgen',\n",
       " 'gängeln',\n",
       " 'deportieren',\n",
       " 'unterliegen',\n",
       " 'heimsuchen',\n",
       " 'wettmachen',\n",
       " 'qualifizieren',\n",
       " 'zurückweisen',\n",
       " 'schlechtmachen',\n",
       " 'belächeln',\n",
       " 'stürzen',\n",
       " 'verpassen',\n",
       " 'dienen',\n",
       " 'foltern',\n",
       " 'jammern',\n",
       " 'abnehmen',\n",
       " 'erschüttern',\n",
       " 'überstrapazieren',\n",
       " 'beitragen',\n",
       " 'abstrafen',\n",
       " 'verüben',\n",
       " 'abdriften',\n",
       " 'erobern',\n",
       " 'zulegen',\n",
       " 'entstehen',\n",
       " 'belangen',\n",
       " 'entlassen',\n",
       " 'anpassen',\n",
       " 'opfern',\n",
       " 'zutrauen',\n",
       " 'wagen',\n",
       " 'zugeben',\n",
       " 'gestatten',\n",
       " 'fingieren',\n",
       " 'diskreditieren',\n",
       " 'anstrengen',\n",
       " 'bedanken',\n",
       " 'enttäuschen',\n",
       " 'überwachen',\n",
       " 'verdammen',\n",
       " 'anzeigen',\n",
       " 'wundern',\n",
       " 'anlasten',\n",
       " 'explodieren',\n",
       " 'behaupten',\n",
       " 'ausnutzen',\n",
       " 'verschweigen',\n",
       " 'vorschlagen',\n",
       " 'überrumpeln',\n",
       " 'verschlimmern',\n",
       " 'verfehlen',\n",
       " 'benutzen',\n",
       " 'diffamieren',\n",
       " 'überleben',\n",
       " 'beeindrucken',\n",
       " 'unterdrücken',\n",
       " 'bergen',\n",
       " 'zurückhalten',\n",
       " 'einstehen',\n",
       " 'einlenken',\n",
       " 'versichern',\n",
       " 'jubeln',\n",
       " 'ergattern',\n",
       " 'verlieren',\n",
       " 'brüsten',\n",
       " 'siegen',\n",
       " 'streiten',\n",
       " 'schiessen',\n",
       " 'quälen',\n",
       " 'überzeugen',\n",
       " 'sträuben',\n",
       " 'vorgeben',\n",
       " 'befrieden',\n",
       " 'einsetzen',\n",
       " 'gestehen',\n",
       " 'nutzen',\n",
       " 'abfertigen',\n",
       " 'vergeben',\n",
       " 'klären',\n",
       " 'töten',\n",
       " 'klauen',\n",
       " 'ausharren',\n",
       " 'bezeichnen',\n",
       " 'lähmen',\n",
       " 'widmen',\n",
       " 'konsternieren',\n",
       " 'erbitten',\n",
       " 'ausspielen',\n",
       " 'unterschätzen',\n",
       " 'prägen',\n",
       " 'anrichten',\n",
       " 'flüchten',\n",
       " 'verachten',\n",
       " 'verlocken',\n",
       " 'beibehalten',\n",
       " 'anzweifeln',\n",
       " 'aufarbeiten',\n",
       " 'zerbrechen',\n",
       " 'anheizen',\n",
       " 'vergessen',\n",
       " 'anherrschen',\n",
       " 'aushöhlen',\n",
       " 'brillieren',\n",
       " 'verwarnen',\n",
       " 'zusetzen',\n",
       " 'lösen',\n",
       " 'gelten',\n",
       " 'benötigen',\n",
       " 'fernhalten',\n",
       " 'verstören',\n",
       " 'einhalten',\n",
       " 'verhindern',\n",
       " 'wissen',\n",
       " 'beschützen',\n",
       " 'vergehen',\n",
       " 'kriechen',\n",
       " 'ausbauen',\n",
       " 'bemühen',\n",
       " 'verzweifeln',\n",
       " 'überwinden',\n",
       " 'kranken',\n",
       " 'aushalten',\n",
       " 'beschweren',\n",
       " 'kümmern',\n",
       " 'inhaftieren',\n",
       " 'totschweigen',\n",
       " 'haften',\n",
       " 'überzeichnen',\n",
       " 'hetzen',\n",
       " 'verkraften',\n",
       " 'wiederbeleben',\n",
       " 'freuen',\n",
       " 'spucken',\n",
       " 'mithelfen',\n",
       " 'einschläfern',\n",
       " 'schwärmen',\n",
       " 'angeben',\n",
       " 'befördern',\n",
       " 'bestaunen',\n",
       " 'schonen',\n",
       " 'kultivieren',\n",
       " 'erfreuen',\n",
       " 'bestrafen',\n",
       " 'rechtfertigen',\n",
       " 'entschärfen',\n",
       " 'aberkennen',\n",
       " 'aufheben',\n",
       " 'erkranken',\n",
       " 'entfernen',\n",
       " 'wüten',\n",
       " 'werben',\n",
       " 'florieren',\n",
       " 'propagieren',\n",
       " 'dominieren',\n",
       " 'austricksen',\n",
       " 'verbünden',\n",
       " 'befriedigen',\n",
       " 'simulieren',\n",
       " 'ausrauben',\n",
       " 'ausgrenzen',\n",
       " 'ertragen',\n",
       " 'verbuchen',\n",
       " 'nachtrauern',\n",
       " 'fremdeln',\n",
       " 'lechzen',\n",
       " 'darstellen',\n",
       " 'aufgeben',\n",
       " 'abzielen',\n",
       " 'einbringen',\n",
       " 'bitten',\n",
       " 'auslöschen',\n",
       " 'mögen',\n",
       " 'bescheren',\n",
       " 'abraten',\n",
       " 'entmachten',\n",
       " 'schießen',\n",
       " 'hüten',\n",
       " 'riskieren',\n",
       " 'zusammenbrechen',\n",
       " 'bestechen',\n",
       " 'loswerden',\n",
       " 'aufweisen',\n",
       " 'einreden',\n",
       " 'abschaffen',\n",
       " 'hauen',\n",
       " 'ausschöpfen',\n",
       " 'zieren',\n",
       " 'nachgeben',\n",
       " 'täuschen',\n",
       " 'finden',\n",
       " 'betrügen',\n",
       " 'lernen',\n",
       " 'amüsieren',\n",
       " 'verdrehen',\n",
       " 'eingestehen',\n",
       " 'vertuschen',\n",
       " 'aussitzen',\n",
       " 'beweisen',\n",
       " 'nominieren',\n",
       " 'sicherstellen',\n",
       " 'unterwerfen',\n",
       " 'missfallen',\n",
       " 'genießen',\n",
       " 'auskommen',\n",
       " 'verschärfen',\n",
       " 'fürchten',\n",
       " 'kuschen',\n",
       " 'verbauen',\n",
       " 'beilegen',\n",
       " 'unterstellen',\n",
       " 'grölen',\n",
       " 'zusichern',\n",
       " 'rühmen',\n",
       " 'küren',\n",
       " 'hinnehmen',\n",
       " 'konfrontieren',\n",
       " 'aufklären',\n",
       " 'reüssieren',\n",
       " 'wegfallen',\n",
       " 'entsetzen',\n",
       " 'lahmlegen',\n",
       " 'verpflichten',\n",
       " 'toben',\n",
       " 'vorgaukeln',\n",
       " 'stellen',\n",
       " 'hinterherhinken',\n",
       " 'anfangen',\n",
       " 'beschimpfen',\n",
       " 'eindämmen',\n",
       " 'überreden',\n",
       " 'anklagen',\n",
       " 'kriminalisieren',\n",
       " 'erpressen',\n",
       " 'korrigieren',\n",
       " 'aufnehmen',\n",
       " 'diskriminieren',\n",
       " 'ernten',\n",
       " 'ausbügeln',\n",
       " 'vertrauen',\n",
       " 'abtun',\n",
       " 'spinnen',\n",
       " 'verklagen',\n",
       " 'aufpassen',\n",
       " 'bekennen',\n",
       " 'aussprechen',\n",
       " 'drängen',\n",
       " 'vertrösten',\n",
       " 'herunterspielen',\n",
       " 'versperren',\n",
       " 'verfügen',\n",
       " 'sehnen',\n",
       " 'gönnen',\n",
       " 'erleiden',\n",
       " 'schlichten',\n",
       " 'umgehen',\n",
       " 'mahnen',\n",
       " 'kollabieren',\n",
       " 'erstarren',\n",
       " 'achten',\n",
       " 'versagen',\n",
       " 'festlegen',\n",
       " 'verletzen',\n",
       " 'fliehen',\n",
       " 'vortäuschen',\n",
       " 'langweilen',\n",
       " 'zurückerobern',\n",
       " 'ziehen',\n",
       " 'gewinnen',\n",
       " 'entgegenkommen',\n",
       " 'leiden',\n",
       " 'anprangern',\n",
       " 'verbrüdern',\n",
       " 'zurücktreten',\n",
       " 'nennen',\n",
       " 'absehen',\n",
       " 'durchmachen',\n",
       " 'befürchten',\n",
       " 'entwischen',\n",
       " 'sorgen',\n",
       " 'bewältigen',\n",
       " 'ausgehen',\n",
       " 'bereiten',\n",
       " 'austreten',\n",
       " 'erregen',\n",
       " 'verstehen',\n",
       " 'verdienen',\n",
       " 'eskalieren',\n",
       " 'entbrennen',\n",
       " 'unternehmen',\n",
       " 'ermorden',\n",
       " 'abschießen',\n",
       " 'profitieren',\n",
       " 'einräumen',\n",
       " 'vertragen',\n",
       " 'beharren',\n",
       " 'begehen',\n",
       " 'erschweren',\n",
       " 'eintreten',\n",
       " 'schuften',\n",
       " 'scheitern',\n",
       " 'trauen',\n",
       " 'punkten',\n",
       " 'übertreiben',\n",
       " 'pfeifen',\n",
       " 'einschränken',\n",
       " 'belohnen',\n",
       " 'vorrücken',\n",
       " 'versuchen',\n",
       " 'gratulieren',\n",
       " 'plagen',\n",
       " 'auffordern',\n",
       " 'suggerieren',\n",
       " 'behindern',\n",
       " 'wirken',\n",
       " 'widersetzen',\n",
       " 'standhalten',\n",
       " 'nachweisen',\n",
       " 'verlernen',\n",
       " 'abbrechen',\n",
       " 'abschirmen',\n",
       " 'tricksen',\n",
       " 'zerstören',\n",
       " 'absichern',\n",
       " 'auszeichnen',\n",
       " 'heulen',\n",
       " 'aufkündigen',\n",
       " 'verschlechtern',\n",
       " 'erzeugen',\n",
       " 'anpreisen',\n",
       " 'äussern',\n",
       " 'erreichen',\n",
       " 'rauben',\n",
       " 'appellieren',\n",
       " 'schocken',\n",
       " 'opponieren',\n",
       " 'sanieren',\n",
       " 'vorspielen',\n",
       " 'ersticken',\n",
       " 'stossen',\n",
       " 'übergeben',\n",
       " 'abrechnen']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overlap /w regards to lemma\n",
    "train_verbs = train.verb_lemma.to_list()\n",
    "val_test_verbs = val.verb_lemma.to_list() + test.verb_lemma.to_list()\n",
    "list(set(train_verbs) & set(val_test_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7d867e93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    verb_lemma  counts\n",
      "317    stellen    2885\n",
      "204     freuen    1194\n",
      "47   aufnehmen    1051\n",
      "206     gelten     828\n",
      "312     sorgen     711\n",
      "..         ...     ...\n",
      "326     tilgen       1\n",
      "322   stänkern       1\n",
      "153   entsagen       1\n",
      "313    spinnen       1\n",
      "52   ausbluten       1\n",
      "\n",
      "[460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "analyse_verb_frequency(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa1827f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      verb_lemma  counts\n",
      "244      stellen     660\n",
      "162       freuen     274\n",
      "40     aufnehmen     225\n",
      "165       gelten     164\n",
      "240       sorgen     158\n",
      "..           ...     ...\n",
      "229    schiessen       1\n",
      "21   anherrschen       1\n",
      "28    anstrengen       1\n",
      "38     aufklären       1\n",
      "273     verenden       1\n",
      "\n",
      "[356 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "analyse_verb_frequency(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d14ca884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      verb_lemma  counts\n",
      "249      stellen     668\n",
      "158       freuen     290\n",
      "33     aufnehmen     221\n",
      "161       gelten     159\n",
      "219    plädieren     136\n",
      "..           ...     ...\n",
      "12     abstrafen       1\n",
      "198   langweilen       1\n",
      "199      lechzen       1\n",
      "286    verhetzen       1\n",
      "178  hinwegsehen       1\n",
      "\n",
      "[356 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "analyse_verb_frequency(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6ae3f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if INCLUDE_MANUAL_ANNOTATION:\n",
    "    df_sample = df.copy(deep=True)\n",
    "    res = df_sample.groupby('rel_type', group_keys=False).apply(lambda x: x.sample(MANUAL_ANNOTATION_SIZE_PER_GROUP))\n",
    "    res.to_csv(MANUAL_ANNOTATION_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "549148f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "con        13386\n",
       "neutral    13386\n",
       "pro        13386\n",
       "Name: rel_type, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rel_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "602e2104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sentences in DS: 39793\n",
      " All multipas sentences: 139\n"
     ]
    }
   ],
   "source": [
    "# how many multi-pas are still sustained?\n",
    "df_occ = df.copy(deep=True)\n",
    "print(f\"All sentences in DS: { len(list(set(df_occ['full_sentence_text'].to_list()))) }\")\n",
    "df_occ = df_occ.merge(df_occ.groupby([\"doc_id\", \"full_sentence_text\"]).size().reset_index(name=\"counts\"), on=[\"doc_id\", \"full_sentence_text\"])\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "s1 = df_occ[df_occ[\"counts\"] >= 2] \\\n",
    "    .sort_values([\"full_sentence_text\"])\n",
    "\n",
    "print(f\" All multipas sentences: { len(list(set(s1['full_sentence_text'].to_list()))) }\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
